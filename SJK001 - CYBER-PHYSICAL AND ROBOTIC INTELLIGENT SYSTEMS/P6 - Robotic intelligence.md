# Visual grasping solved for 2D and simple 3D shapes

- Vision: Wont generally provide enough feedback to position the fingers exactly on some grasping points
- Second sensor modality used: force/tactile sensors to detect collisions with objects. Adjusting the position of the fingers until an adequate grasp is achieved, else it corrects position until good contact in all fingers.
Vision provides first approach which is refined by collision sensors.

>[!reminder] For the exam: Concept of affordance
>#exam <b style="background-color:limegreen; color:white">_Concept of affordance..</b>
>[Presentation about the concept of **affordance** in psychology](https://www.cs.cmu.edu/afs/cs/academic/class/15494-s09/lectures/affordances.pdf)
>[Article about affordances in robotics](obsidian://open?vault=master_SistemasInteligentes_obsidianVault&file=_aula_virtual%2FSJK001%2FTICany%20-%20Affordance%20In%20Robotics.pdf)

![[Pasted image 20241119152908.png]]

- Plan
- Abstract to generic tasks
- Details adapting to each specific task

# Manual robotic intelligence

*The challenge of manual intelligence for **autonomous**, **versatile** and **dependable**(robust) physical interaction calls for a common framework in which tasks are specified, planned, and executed*

![[Pasted image 20241119161415.png]]
- Specification
- Planning
- Sensor-based control

- Exhaustive use of sensor
- Different tasks and environments

*The dependable execution of physical interaction tasks calls for the combination of vision, tactile and force feedback*
![[Pasted image 20241119162659.png]]
*vvs = [Virtual Visual Survey](http://www.virtualvisualsurveys.com)*
