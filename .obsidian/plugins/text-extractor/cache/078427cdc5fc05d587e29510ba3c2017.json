{"path":"_aula_virtual/SJK001/Reading Assessments/[Floreano14] Robotics and Neuroscience Current Biology.pdf","text":"Current Biology 24, R910–R920, September 22, 2014 ª2014 Elsevier Ltd All rights reserved http://dx.doi.org/10.1016/j.cub.2014.07.058 ReviewRobotics and Neuroscience Dario Floreano1,*, Auke Jan Ijspeert2, and Stefan Schaal3 In the attempt to build adaptive and intelligent machines, roboticists have looked at neuroscience for more than half a century as a source of inspiration for perception and control. More recently, neuroscientists have resorted to robots for testing hypotheses and validating models of biological nervous systems. Here, we give an overview of the work at the intersection of robotics and neuroscience and highlight the most promising approaches and areas where interactions between the two ﬁelds have generated signiﬁcant new insights. We articulate the work in three sections, invertebrate, vertebrate and primate neurosci- ence. We argue that robots generate valuable insight into the function of nervous systems, which is intimately linked to behaviour and embodiment, and that brain-inspired algorithms and devices give robots life-like capabilities. Introduction Intelligent robots are behavioural agents that autonomously interact with their environment through sensors, actuators, and a control system producing motor actions from sensory data. Interestingly, what is today considered the ﬁrst auton- omous robot [1] was built in the early 1950s by neurophysiol- ogist William Grey Walter [2], to show that complex, purpose-driven behaviours can be produced by few inter- connected neuron-like analog electronic devices that close the loop between perception and action in a situated and embodied system (see, https://www.youtube.com/watch? v=lLULRlmXkKo). Along this line of thought, thirty years later the neuroanatomist Valentino Braitenberg [3] conceived a series of imaginary vehicles with simple sensors and wirings inspired by universal properties of nervous systems and argued that the resulting behavioural complexity originated from the interaction with the environment rather than from the complexity of the brain, and that traditional analysis of nervous systems can learn from the ‘synthesis’ (construc- tion) of behavioural systems. Indeed, nervous systems cannot be understood in isolation from body and behaviour, because physical properties (mass, springs, temporal de- lays, friction, etc.) signiﬁcantly alter the behavioural effects of neural signals and affect the co-evolution and co-develop- ment of brains and bodies [4]. Consequently, it has been argued that understanding brains requires the joint analysis and synthesis of relevant parts of the body, environment and neural systems [5]. Understanding motor control re- quires understanding a series of speciﬁc transformations from neural signals to musculoskeletal systems to the environment where the complexity of animal bodies may simplify, instead of complicating, control [6]. In this context, robots incorporating the biomechanics of the animal system under study become physical models to test hypotheses. In the following sections we will examine to what extent neuro- science and robotics have resulted in novel insights and devices in the speciﬁc ﬁelds of invertebrates, vertebrates, and primates. Invertebrates Invertebrates produce more stereotyped behaviours and are easier to manipulate than most vertebrates, making them suitable candidates for embodiment of neuronal models in robots [7]. Perception Insect behaviour largely depends on external stimulation of the perceptual apparatus, which triggers basic reactions such as attraction and evasion. Mobile robots have been often used to understand the neural underpinnings of taxis, movement towards or away from a stimulus source. For example, Webb and Scutt [8] resorted to a mobile robot equipped with a bio-mimetic bilateral acoustic apparatus to disambiguate between two different neuronal models of cricket phonotaxis whereby females can discriminate and approach conspeciﬁc males that produce species-speciﬁc songs. The authors showed that two spiking neurons repli- cating the temporal coding properties of identiﬁed auditory neurons were sufﬁcient to reproduce a large variety of pho- notactic behaviours observed in real crickets, supporting the hypothesis that recognition and localization of a singing cricket does not require two separate neuronal mechanisms. Chemotactic behaviour of invertebrates has been studied in a variety of contexts. For example, Grasso et al. [9] used an underwater robot to test and discriminate between different neuroethological hypotheses of how lobsters detect and navigate towards the source of a chemical plume in turbulent water. The robot was designed to accurately model the dimension of the lobster and its chemical sensor layout, while the locomotion system was abstracted as a pair of wheels. Similarly, Pyk et al. [10] used wheeled and ﬂying robots equipped with bio-mimetic chemical sensors to falsify a neuronal hypothesis of moth chemotactic behaviour and propose an alternative hypothesis. Robots have also been used to investigate the neural mechanisms that allow ﬂying insects to navigate in complex environments with a compound eye radically different from vertebrate eyes, featuring coarse spatial resolution, ﬁxed focus, and almost complete lack of stereovision. Models of those neural mechanisms have also led to the development of vision-based control of robot drones ﬂying near the ground or in cluttered environments [11]. Insects rely on image motion generated by their own movement to avoid obstacles, regulate speed and latitude, chase, escape and land [12,13]. There is a mathematical correspondence be- tween the amplitude of image motion, also known as optic ﬂow, and the distance to corresponding objects when the viewer translates on a straight line, but not when it rotates [14]. It has been speculated that freely ﬂying ﬂies follow straight lines interrupted by rapid turns, during which visual signals are suppressed, in order to estimate distances using translational optic ﬂow [15]. This hypothesis was tested by Franceschini, Pichon, Blane` s and Brady [16], using a wheeled robot equipped with a circular array of compound eyes, whose analog electronics mimicked the elementary 1Laboratory of Intelligent Systems, Ecole Polytechnique Fe´ de´ rale de Lausanne, Station 11, Lausanne, CH 1015, Switzerland. 2Biorobotics Laboratory, Ecole Polytechnique Fe´ de´ rale de Lausanne, Station 14, Lausanne, CH 1015, Switzerland. 3Max-Planck-Institute for Intelligent Systems, Spemannstrasse 41, 72076 Tu¨ bingen, Germany, & University of Southern California, Ronald Tutor Hall RTH 401, 3710 S. McClintock Avenue, Los Angeles, CA 90089-2905, USA. *E-mail: Dario.Floreano@epﬂ.ch motion detection circuitry of visual neurons. This robot could perform collision-free navigation in a cluttered environment by moving along straight lines interrupted by sharp avoid- ance rotations during which visual information was ignored. In another study, Srinivasan et al. [17] argued that, as the angular velocity of the image projected on the ventral side of the insect is proportional to the ratio between horizontal speed and height, insects regulate their speed by maintain- ing a constant image motion, which results in graceful deceleration during landing. The hypothesis that a simple mechanism of optic ﬂow regulation could be used to control altitude and landing without explicitly measuring distance to the ground was validated with helicopters equipped with two artiﬁcial ommatidia pointing towards the ground. The same optic ﬂow regulator was then shown to be effective to repro- duce a variety of other behaviours observed in insects, such as terrain following and corridor centering [18]. It has also been shown that optic ﬂow regulation of collision-free navi- gation and altitude control in indoor [19] and outdoor [20] free-ﬂying drones (Figure 1) can be achieved by making roll and pitch angles dependent on two weighted sums of optic ﬂow intensities — a simple operation that could be accomplished by wide-ﬁeld visual neurons in the lobula plata complex of the insect brain. Indeed, Humbert et al. [21] pro- posed the hypothesis that wide-ﬁeld tangential cells in the visual system of insects are not used to estimate self-motion, as previously argued, but to detect discrepancies between desired and observed optic ﬂow, and use these discrep- ancies to correct navigation in a feedback loop. The authors successfully tested this hypothesis on a micro-helicopter using analog very large-scale integration (VLSI) sensors and models of the tangential neurons ﬂying in textured environments. Insect compound eyes have also inspired the develop- ment of novel types of tiny cameras capable of unparalleled ﬁelds of view with no angular distortion. Recently, two different designs of miniature artiﬁcial compound eyes have been proposed. Song et al. [22] described an hemi- spherical compound eye combining elastomeric compound optics with deformable arrays of thin silicon photodetectors that could be shaped into a half sphere to grab wide-ﬁeld images. Floreano et al. [23] instead described a semi-cylin- drical compound eye made of a layer of compound optics, a layer of neuromorphic photodetectors with self-adjusting light sensitivity and a layer of signal processing electronics (Figure 2) that can extract optic ﬂow even faster than the in- sect. A compound eye composed of three ocelli has been added to an insect-size ﬂying robot to validate the hypothe- sis that some insects may use visual information, instead of angular accelerations, to stabilize ﬂight [24]. Locomotion The large variety of locomotion strategies observed in insects inspired several types of locomotion systems in robots, such as peristalsis, jumping, ﬂying and walking on water [25–29],to mention a few. However, most of the research in this area still focuses on the mechanical aspects of the locomotion sys- tem, and relatively few authors have ventured into neurally inspired control of these robots. Izquierdo and Beer [30] investigated a neuronal circuit derived from neuroanatomical constraints of the Caenorhabditis elegans connectome in a simulated worm body and environment, and used artiﬁcial evolution to predict unknown electrophysiological parame- ters of the nervous system necessary to generate worm-like movements of klinotaxis. Evolved individuals revealed con- sistent neurophysiological and behavioural patterns, which prompted the authors to suggest a series of new experi- ments, such as a better study of turning as a function of gradient and ablation of speciﬁc neurons. Some hexapod robots have been developed to under- stand sensory-motor control of legged invertebrates and address, for instance, questions of how rhythms are gener- ated either by central pattern generators [31], i.e. systems of coupled neural oscillators that have been found in many invertebrates [32], or by chains of reﬂexes [33]. These robots range from robots with legs that have only two degrees of freedom to validate theories of basic gait control [31,33],to robots with legs that capture biomechanical properties of real cockroaches [34], all the way to robots with legs equip- ped with pneumatic artiﬁcial muscles that could be directly driven by electrical activity of the neuromuscular system of the insect [35]. Interestingly, each robot was designed to address a speciﬁc question raised by discrepancies be- tween the insect and the previous version of the robot [6], revealing the usefulness of robots in generating new insights into the functioning of the nervous system. Figure 1. Drones with insect-like vision. (A) An indoor vision-based drone developed by Zufferey et al. [19] at EPFL is equipped with linear camera facing forward (d), linear camera facing downward (c), propeller (a), anemometer (e), rudder and ailerons (b), and battery (f). (B) An outdoor vision-based drone developed by Beyeler et al. [20] at EPFL is equipped with seven optic ﬂow sensors pointing left, left-down, down, right-down, and right. (Reproduced from [20] with kind permission from Springer Science and Business Media.) Special Issue R911 Ayers et al. [36] developed a bio-mimetic lobster robot whose legs were activated by artiﬁcial muscles that pro- duced movements similar to those of the animal and used it to propose hypotheses of neuronal control for which neuroscience data are not available. In another study, Spa- gna et al. [37] argued that insects required to rapidly walk over irregular terrain rely on distributed mechanical feedback to stabilize rather than on neuronal feedback (which does not have sufﬁcient bandwidth) and showed that ghost crabs equipped with prosthetic and compliant spines on their legs could actually improve their natural walking abilities. In order to further corroborate the hypothesis that neural control does not play a role in those situations, they modiﬁed the legs of an hexapod robot, but not its control system, to approximate the biomechanics of the modiﬁed crab legs and found that the robot improved its walking capabilities. Navigation Robots have also been used to study higher ‘cognitive capabilities’ of invertebrates, such as spatial memory [38]. Several insects can ﬁnd their nest or foraging area after trav- eling for hundreds of meters or long periods of time. The widely accepted ‘snapshot model’ [39] assumes that insects compute the homing direction by comparing the retinal posi- tions of landmarks in orientation-adjusted snapshots of their visual surrounding taken at different intervals. However, this model requires the nervous system to engage in intensive computation and cannot explain experimental results where portions of the landmarks were removed between outgoing and return ﬂights of insects [40]. A more parsimonious version of the snapshot model, named the ‘average landmark vector (ALV) model’, was recently proposed and tested with mobile robots [41]. This model assumes that the insect represents each visual land- mark as a unit vector and that all landmark vectors detected at a position are averaged to produce an ALV. The insect memorizes only the target ALV and during the return path continuously generates a new homing vector by computing the difference between the currently perceived ALV and the memorized target ALV. As in the snapshot model, the current ALV must be aligned to the target ALV by means of a com- pass before computing the home vector. When tested in a variety of simulated and real robots, including implementations in neural inspired analog electronics [42,43], the ALV model produced trajectories that are com- parable (although not identical) to the original snapshot model and also replicated behavioural patterns that the orig- inal snapshot model could not explain. Other authors have suggested that instead of an ALV the environment can be represented as a connected graph where nodes are panoramic snapshots taken at speciﬁc locations and edges are motor commands that lead the insect or robot to other connected locations by means of path integration [44]. An alternative hypothesis based on image statistics collected by a mobile robot suggests that insects may memorize a snapshot of the target location and chose movements in the direction that minimizes the root mean square error between the current image and the image taken at the target location, which has been shown to be a monotonically decreasing function of distance from the target [45]. Vertebrates Vertebrates possess some unique learning abilities and rich motor skills that have attracted the attention of neuroscien- tists and roboticists alike. Locomotion Similarly to invertebrates, vertebrates have conquered multi- ple ecological niches. From ﬁsh to mammals, they exhibit multiple types of morphology and different modes of loco- motion in water, on ground and in the air. Interestingly, despite the large variation of morphology, the organization of the underlying motor control systems is quite well conserved [46]. Similarly to the ganglions of invertebrates, the spinal cord contains oscillatory circuits called central pattern generators (CPGs) that can generate complex peri- odic motor patterns while being activated and modulated by relatively simple descending drive signals. The lamprey is probably one of the vertebrates whose spi- nal locomotor circuit is best known [47]. Because of its rela- tively simple eel-like shape it has also served as inspiration for the construction of swimming robots [48,49]. The lamprey swims using an anguilliform swimming gait in which a lateral undulation of increasing amplitude is propagated from head to tail. The underlying CPG is composed of multiple coupled oscillatory networks distributed along the spinal cord. The coupling between the CPG circuits, the body, and the environment have ﬁrst been studied with neuromechanical simulations [50], then with real robots [48,49]. Wilbur and col- leagues [48] built a lamprey-like robot actuated with ﬁve pairs of artiﬁcial muscles made of shape-memory alloys (Figure 3). They carefully analysed different motor behav- iours exhibited by freely moving lamprey such as forward swimming, burrowing, crawling, turning and withdrawal. Based on those analyses, they constructed a CPG as a look-up table that could replay similar activation patterns of the artiﬁcial muscles. The robot could successfully swim forward, turn and burrow. Another lamprey robot with an original actuation system based on permanent magnets was constructed to test hypotheses about visually-guided goal-directed behaviour [49], speciﬁcally how head stabiliza- tion (obtained by generating neck movements in opposite phase to those of the trunk) affected tracking performance of a moving target. Two swimming strategies were com- pared, with and without head stabilization, and it was found that using head stabilization largely improved keeping track Figure 2. Curved artiﬁcial compound eye. Developed by a European team lead by Dario Floreano [23], the cylin- drical array of 670 neuromorphic ommatidia are glued on a green scaf- fold enclosing electronics capable of extracting optic ﬂow at 300 Hz with neurally plausible algorithms. Current Biology Vol 24 No 18 R912 Current Biology Stereo vision system Compliant skin Stretch sensors Artificial CPG Muscle-like actuation Hydrodynamic tail Figure 3. A lamprey-like swimming robot. The robot was constructed by Manfredi et al. [49] to explore the mechanisms of visually- guided swimming in the lamprey. (Repro- duced from [49] with kind permission from Springer Science and Business Media.) of the target with only a small decrease of swimming speed. The authors also observed that the CPG patterns re- sulted in lamprey-like swimming and could generate sharp turning resem- bling that of a real lamprey. Salamanders use an anguilliform swimming gait like lampreys, and a walking trot gait also observed in liz- ards. Ijspeert and colleagues [51] developed an amphibious salaman- der-like robot driven by a CPG model to test hypotheses about the evolution from swimming to walking and the mechanisms of gait tran- sition (Figure 4). Their main working hypothesis was that the salamander has kept a lamprey-like swimming circuit for its axial musculature, and that, during evolution, specialized and slower oscillatory centres have emerged to control the limbs. The CPG model could replicate gait transitions induced by electric stimulation of the mesencephalic loco- motor region in a decerebrated animal [52], with the genera- tion of a slow walking mode at low stimulation, and a faster swimming mode with traveling waves along the body at high stimulation (when the limb CPGs were saturated). The model furthermore provided an explanation of why walking gaits have systematically lower frequencies than swimming gaits in salamander, by demonstrating how the slower limb oscillators could slow down the frequencies of the whole lo- comotor network during walking. The concept of CPGs is now being used and tested in many types of robots, from snake to octopods [32]. In particular, quadruped cat- and dog-like robots have been useful to bet- ter understand the interactions between gait generation and balance control. For instance, Kimura and colleagues [53,54] built a series of light-weight compliant quadruped robots to investigate the interplay between CPGs, reﬂexes and balance control. In particular, two different options were explored: one in which sensory feedback (from tendon force, ground contact, and body orientation) acts independently of the CPG (i.e. directly on the motors) and, and one in which sen- sory feedback is fed through the CPG network. They found that the most stable locomotion in uneven terrains was ob- tained when sensory feedback is fed through the CPG network compared to when feedback does not affect CPG activity. This interplay between sensory feedback and the CPG is thus important for allowing variations of the cycle duration depending on the conditions and for allowing sen- sory feedback that is phase-dependent (e.g. reﬂexes that have different effects on limbs during swing or stance phases) similarly to what is known in the cat [55]. More recently, quadruped robots were also used to explore the mechanisms of coordination between limbs, and the respective role of neural coupling versus mechanical coupling [56]. Interestingly, it was found that direct neural coupling between limb oscillators was not necessary for generating stable gaits, something that was known from research on invertebrates, such as the stick insect [33]. Indeed stable gaits could be obtained by using decoupled oscillators that only interact through sensory feedback and mechanical coupling (as opposed to neural coupling). Different gaits could be obtained depending on the mass dis- tribution in the robot, with more weight on the back or in front, replicating gaits observed in monkeys (centre of mass more to the back) and camels (centre of mass more to the front). Here, the robot was key to demonstrate these phenomena. Sensorimotor Coordination Vertebrates are capable of sophisticated movements that require complex sensorimotor coordination. Proper sensori- motor coordination is essential for animals and robots: any motor action needs to be guided by perception, and percep- tion is often an active process that involves motor actions [57,58]. More than 50 years ago, Held and Hein [59] devised an ingenious experiment showing the importance of motor actions on development of the nervous system: they raised two kittens in a textured arena where the gross movement of a freely moving kitten was transmitted to a second kitten carried on a gondola preventing contact between feet and ground, so that they were both exposed to the same visual environment, but only one kitten received visual stimulation directly generated by its own motion. When tested outside the gondola, the freely moving kitten displayed normal be- haviours in several visually guided tasks, whereas the other kitten failed or performed poorly. The authors concluded that correlated perception and motor actions are necessary for normal behavioural development, but could not precisely explain the mechanical cause. Suzuki, Floreano and Di Paolo [60] replicated those experiments with wheeled robots equipped with a pan-tilt camera and a neural network with Hebbian plasticity (a type of learning that involves strength- ening synapses between co-activated neurons) linking the visual input to the motor commands of the camera and of the wheels. Constraints on body movements affected the development of visual receptive ﬁelds, which became responsive to sensory features that were correlated with the constrained behaviour and interfered with production Special Issue R913 of normal behaviour. This provides an explanation for the be- havioural deﬁciencies of the suspended kitten. Another interesting example of sensorimotor coordination is offered by electric ﬁshes, which actively emit electric pulses and which can sense objects and living beings by measuring changes in the electric ﬁelds surrounding their electrosensitive skins [61]. The black ghost knifeﬁsh, for instance, uses electric sense together with a ribbon ﬁn that offers high manoeuvrability. Using simulations and a robotic ribbon ﬁn prototype that can propel itself in a ﬂow tank, MacIver and colleagues [57] provided evidence that the sensing and locomotion abilities are well matched. In partic- ular, using optimal control theory they showed that typical swimming manoeuvres observed in the ﬁsh are very similar to those generated by the model when minimizing a cost function that approximates metabolic effort, and that they are well adjusted to the sensory abilities of the ﬁsh by increasing the quantity and resolution of sensory inﬂow [57]. Related work using planar or swimming robots has since successfully used electrolocation for localizing objects and avoiding obstacles [62,63]. The sense of touch is another sensory modality that has been explored with robots. A sophisticated tactile system found in mammals is one using whiskers, as found in rats and mice [64]. Whiskers allow animals to determine the shape, texture, position and motion of encountered objects. Typically whiskers are actively moved, making rhythmic sweeping movements that are continuously adjusted de- pending on the situation. The ‘Whiskerbot’ [58] and its successor ‘ScratchBot’ [64] explored the underlying sensori- motor mechanism using a mobile robot equipped with an articulated head and active whiskers (Figure 5). These pro- jects involved replicating the morphology and mechanics of large whiskers and a neural network model of different brain areas underlying the sensorimotor coordination of the whiskers, including a model of a CPG for generating the periodic motion of the whiskers. Whiskerbot could replicate typical whisker response and orientation behaviours ob- served in rats in response to whisker stimulation [58].In particular, the robot exhibited variations of amplitude of whisker oscillations, with a decrease of amplitude when there is a contact, as well as body and head movements to bring the nose of robot towards the point of contact. d dMLR Brainstem CPG model (spinal cord) 17 18 2019PD controller 1 9 2 10 11 12 13 1 2 3 4 5 6 7 8 9 10 14 15 16 3 4 5 6 7 8 ϕ∼ ι . ι .ϕ ι . Λ Current Biology AB Figure 4. A salamander robot driven by a spi- nal cord model. (A) Numerical model of the salamander central pattern generator for swimming and walking. (B) An amphibious salamander robot [51]. The CPG and robot could replicate the typical swimming and walking gaits of the salaman- der, and induce a gait transition between the two depending on the level of stimulation coming from the simulated mesencephalic lo- comotor region (MLR). In related work, Schroeder and Hart- mann [65] explored analogies between optical ﬂow and the dynamical aspects of tactile sensing with whiskers. They demonstrated that, similarly to optical ﬂow, the signals provided by whiskers when moving over an object could pro- vide rich information about the object, such as its radial distance and its curvature. That informa- tion could be used to predict future contact points. While interesting from a neurobiological and neuroethological point of view, these projects are clearly useful for robotics to design artiﬁcial tactile systems that, like their biological counterparts, can complement vision (e.g. when in the dark) and that can serve not only to detect objects but also to recognize their motion and their properties. Navigation Some of the earliest interactions between neuroscience and robotics investigated the mechanisms of vertebrate naviga- tion. Following the discovery of place cells in the hippocam- pus of rats [66], several projects have been launched to test models of vertebrate navigation using robots (for instance [67,68]). Place cells are neurons in the hippocampus that ﬁre at a high rate when the rat is in a particular location and that are strongly dependent on visual cues [69]. Burgess and colleagues [68] have implemented a navigational sys- tem based on place cells on a small wheeled robot with a camera and a series of infrared proximity sensors. Learning rules were implemented that change the synaptic connec- tions from in the network to gradually learn the place cell mapping when exploring the environment and that update a population vector towards speciﬁc goal/reward locations when these are visited. The robot and model correctly repli- cated several observations from real rats. For instance, the robot was capable of rapidly returning to goal locations, and was able to generalize when starting from new loca- tions. Interestingly, when the environment was modiﬁed, and increased in size along one axis, the PC in the model showed the same type of adaptation as in real rats [66]. In related work, Touretzky and colleagues [67] showed that a neural model of place cells with path integration could not only explain awareness of position and orientation in space but was also sufﬁcient for replicating results from various behavioural experiments, such as navigation in the dark and in environments that are geometrically ambiguous. Also related and going further than navigation is the ambi- tious concept of a ‘brain-based device’ [70] that aims at con- trolling a robot with a neuronal architecture composed of multiple brain areas, and to gradually endow robots with increasingly mammal-like learning abilities. Current Biology Vol 24 No 18 R914 Primates The behavioural repertoire of primates is vast, from bipedal locomotion to sophisticated manipulation and complex social interactions. These behaviours are controlled by a powerful nervous system, and reverse engineering of the pri- mate brain has been put forward both in Europe and in the U.S. as one of the grand challenges for the 21st century. The behavioural neuroscience of primates requires rather reductionist methods, where the ﬁring of single neurons, arrays of neurons, or activity of entire brain regions (as re- vealed by imaging studies) is correlated with well-controlled minimal behaviours. Given the many layers of information processing in the primate nervous system, it is almost impossible to obtain a clear understanding of the underlying computations without a systems level view. It was primarily in the wake of David Marr’s [71] seminal work on the compu- tational neuroscience of vision in the 1970s and 80s that a computational approach to motor control was developed [72] — indeed, Marr himself proposed an inﬂuential model of motor learning for the primate cerebellum [73–75]. From a physics point of view, primates are inertia-dominated sys- tems (i.e., Reynolds number >> 1), and such systems have been well studied in robotics, in particular in manipulator ro- botics, i.e., robots with arms and legs (as opposed to mobile robots on wheels). It thus makes sense to compare theory and experiments of manipulator robotics with primate behaviour and neuroscience. Early Inﬂuence of Robotics on Primate Neuroscience In the early days of computational motor control in the 1980s, there was primarily a ﬂow of knowledge from robotics and control theory towards an understanding of phenomena of primate behaviour and neuroscience, for instance, analysing how movement generation with muscles can control how strongly the end effector resists external force perturbations, i.e., achieve impedance control [76]. Impedance control is critical for stable force control when in contact with objects, and sophisticated impedance control can be found in human behaviour. In another line of research, optimal control approaches became popular for models of human arm movement [77], emphasizing simple organizing principles, such as the maximization of smoothness, minimum torque- change, minimum muscle command change approach, min- imum task variance and others. Based on rigid-body dynamics modelling from robotics, neuroscientists discovered in the 1980s that the popular experimental paradigm examining single degree-of-freedom movements was too simplistic to reveal the complexity of motor control and planning. The two-joint arm paradigm, i.e., an arm composed of one shoulder and one elbow joint, became the prominent model of neuromotor control, which could be tested in behavioural and neurophysiological ex- periments in humans and monkeys. The transition from an essentially linear one degree-of-freedom movement model to a nonlinear two degree-of-freedom model sparked an interesting discussion: does the nervous system need an in- ternal representation of the dynamics of the body for control, or can it get away without, also discussed as direct vs. indi- rect control [78]. Up to this time, the ‘equilibrium point hypothesis’, a popular model-free theory of biological move- ment control [79], postulated that the nervous system simply codes the muscle lengths that realize the target posture of a movement, while the movement to the target posture is created by the spring properties and attractor dynamics of the neuromuscular system, including spinal cord circuits. Detailed biomechanical impedance measurements of human arm movement demonstrated that equilibrium point control was an implausible model of human motor control [80],as it could not easily explain the transient characteristics of movement to the target point. Thus, model-based control became a leading hypothesis, often discussed as the internal model hypothesis [81,82]. Model-Based Control Model-based robot control, i.e., the use of internal represen- tations to predict kinematics and/or dynamics of a control system and its environment, has been a topic in robotics for many years, but it was primarily at the end of the 1980s that some torque-controlled compliant robots became available to perform experimental evaluations — position- controlled robots do not easily allow compliant control. Models can be used to predict the dynamics and kinematics of a movement system or its environment (called ‘forward modelling’), or they can be used to compute the appro- priate motor command for a desired state (called ‘inverse Figure 5. Robots equipped with whiskers. (A) Whiskerbot. (Reproduced from [58] by permission of SAGE.) (B) Scratchbot (courtesy of Bristol Robotics Laboratory [58]). The robots are equipped with differential wheels for navigation, and with an artic- ulated head and active whiskers. They were used to explore the neural mechanisms underlying active whiskering. Special Issue R915 modelling’). An et al. [83] explored issues of model-based control in an advance torque controlled robot and laid the foundations of model-based control. Based on insights into cerebellar learning, Kawato [84] developed feedback-error learning as a model for biological learning, picked up in several robotics approaches for learning control [85,86]. Given the mathematical complexity of dynamics models of primate movement, several researchers investigated machine learning techniques to acquire such models from data. Grossberg and Kuperstein [87], for instance, developed neural networks of motor development that employed various forms of internal models. Modular control modules specialized for different tasks became of interest, based on an architecture inspired by the cerebellum, and they found veriﬁcations in human functional brain activity [88] and robotics approaches for object manipulation [89]. Atkeson et al. [90] developed an internal model learning approach based on local linearization, which successfully demon- strated internal model learning in various complex tasks with anthropomorphic robots [91–93] (Figure 6). Mehta and Schaal [94] examined the existence of an internal model for control in the task of pole-balancing (Figure 6A), and con- cluded from behavioural and robotic studies that there is evidence of predictive forward models in human control. The success of neuroscientiﬁc and robotic studies on learning and control with internal models has made the internal model hypothesis of primate control a largely accepted theory. Movement Planning and Imitation In both animals and robots, the question arises of how move- ments are planned. For a particular movement goal, there is usually an inﬁnite number of ways to recruit a highly redun- dant motor system in space and time to achieve the goal, i.e., the possible combinations of muscles and the variety of trajectories to achieve a goal is countless. Nevertheless, as noted in early work on computational motor control [95,96], human and non-human primates use rather stereo- typical ways to move, indicating that there are some funda- mental and common principles of movement generation. As mentioned above, optimization principles were one approach to look for an organizing principle [97], and optimi- zation is still a popular topic in computational motor control. Stochastic optimal control, i.e., optimal control that takes random effects into account, became a prominent theory of movement generation at the turn of the century, where the movement plan and the time-dependent appropriate feedback controller were computed together, which can also address impedance control [76]. While complex to compute, optimal control provided interesting explanations of experimental data [98,99] and inspired many other inves- tigations [99,100]. The renewed success of optimal control as a neuroscientiﬁc model of primate movement also impacted the robotics literature, where many new results of full-body human motor control were derived from related optimal control theories [101–103]. It should be noted that the ability to solve complex optimization problems on normal desktop computers contributed signiﬁcantly to the renewed success of optimal control theories, besides several algo- rithmic advances. In a recent robot competition (DARPA Robotics Challenge), where human-like robots had to solve several problems of a disaster scenario, optimal control approaches to full-body motion generation were the stan- dard rather than the exception. Another window into movement planning has been the search for general movement primitives. Movement primi- tives are sequences of action that accomplish a complete goal-directed behaviour [104], such as ‘grasping a cup’, ‘walking’, ‘a tennis serve’, etc. This coding results in a compact state-action representation where only a few parameters need to be adjusted for a speciﬁc goal. For instance, in reaching movements, the target state and move- ment duration are such parameters, or in a rhythmic move- ment, frequency and amplitude need to be speciﬁed [105]. Using such primitives dramatically reduces the number of parameters that need to be learned for a particular move- ment. The drawback is that the possible movement reper- toire becomes more restricted. Many different approaches to movement primitives have been suggested in the past. For instance, planar trajectories in the end effector space have been suggested for human motor control, but some robotic experiments and theoretical analyses discounted this idea as an artefact of the human arm kinematics [106]. A similar robot analysis discounted the proposal that in human arm movement, movement veloc- ity is coupled by a power law to movement curvature [107]. Ijspeert et al. [105] advanced the theory of dynamic move- ment primitives, i.e. the use of nonlinear attractor systems to generate movement plans, similar as in central pattern generators. In essence, a dynamic movement primitive pre- scribes the next motor command to get to the goal with some differential equations, and, due to the attractor dy- namics, it can robustly realize the movement plan even Figure 6. Anthropomorphic torque-controlled robots. These robots were developed for com- putational neuroscience in a collaboration be- tween the ATR Computational Neuroscience Labs (Japan), Sarcos Inc. (Salt-Lake City, Utah), the University of Southern California (Los Angeles, CA), and Carnegie Mellon Uni- versity (Pittsburgh, PA). (A) A Sarcos Dexterous Arm robot that was used in various behavioural experiments for neuroscientiﬁc studies. (B) The Sarcos Humanoid DB, used for internal model learning experiments. (C) A Sarcos Humanoid, used for locomotion experiments. Current Biology Vol 24 No 18 R916 when there are disturbances from the environment (such ideas are also discussed as ‘next-state-planners’, e.g., [99,108]). Dynamic movement primitives can account for data from primate motor control [109], they inspired imaging studies to look into the difference between discrete and period movement in the human brain based on the difference between point attractors and limit cycle attractors [110], and, with variations, became popular in robotic studies (Figure 7) [105,111,112]. Dynamic movement primitives may be an example where theories from neuroscience, behavioural sci- ences, and robotics managed to reciprocally inﬂuence each other and advance all the associated ﬁelds. It is also interesting to view the idea of movement primi- tives in the light of imitation learning [104,111] and the ‘mirror neuron’ hypothesis. The work of Rizzolatti et al. [113–115] suggested that observing the movement of others involved the brain system that is also able to generate the same motor act, a hypothesis formed with the discovery of so-called mirror neurons in premotor cortex of primates. Such an idea requires that complete motor acts, i.e., movement prim- itives, have a speciﬁc representation in the brain, and these primitives can also be recognized in the behaviour of others. Using such a coupling between movement recognition and movement generation, particularly when combined with a particular theory of movement primitives, became a rather popular topic in computational motor control [116] and various robotic studies [117,118]. Locomotion It should be noted that robotics and neuroscience for pri- mates has been mostly conducted in the context of reach and grasp movements [99,119]. For primate locomotion, the interaction of neuroscience and robotics is less devel- oped. One reason may be that neuroscientiﬁc investigations of primate walking are hard to conduct, as they involve the spinal cord, which is notoriously difﬁcult to measure from. Another reason may be that bipedal locomotion is inherently high dimensional in its actuation systems, actually involving the entire body, such that it is hard to use a reductionist experimental methodology as typical in arm movements, where mostly only two degrees of freedom are considered. One branch of neuroscience that has inspired researchers in bipedal locomotion involves control strategies of central pattern generators. Central pattern generators combine motion planning and stability, and biological realizations of bipedal locomotion have, so far, been far superior to robotic controllers. A rather complex and seminal project by Taga [120,121] modelled biped locomotion in simulation by a large network of coupled oscillators. Related projects, including robotics, can be found in [122–124] (Figure 6C). This line of research often connects to the ﬁeld of ‘passive dynamic walking’, which investigates how far mechanics and neuro- muscular anatomy can account for stable bipedal balance control, walking, and running [125–127]. Energy efﬁciency, minimal control, mechanical design, and stability are among the governing topics of this branch of research. Minimal ro- botic platforms were developed to demonstrate these princi- ples [127]. The seminal work of Raibert [128,129] on legged hopping robots similarly demonstrated simple control princi- ples that could achieve very robust biped (and monoped) locomotion. In contrast, humanoid robotics research employs rather complex robots that, so far, have not been easily reconciled with ideas from passive dynamic walking. Balance and locomotion control based on stability criteria derived from the centre of gravity and the zero moment point have been prominent [130]. However, one component from simpler ro- botic and biomechanical studies did have an interesting impact on humanoid robotics, namely the use of simpliﬁed reference dynamics from models like the inverted linear pendulum [131], which directly connects to Raibert’s seminal work. These simpliﬁed models reduce the control system to the most essential parts, e.g., a centre of gravity connected by rigid rods to the ﬂoor, and, subsequently, allow easier planning and stability considerations [132–134]. Simpliﬁed models have been suggested as a key to understanding the real control systems in legged locomotion [135], although the right level of simpliﬁcation remains disputed. From a Figure 7. Research on movement primitives. (A) Dual arm (Barrett Inc.) robotic test bed to study manipulation with (dynamic) motor primitives. (B) Results of fMRI study on distinguishing rhythmic and discrete movement primitives in the human brain (blue areas are primarily involved in discrete movements, green areas are primarily involved in rhythmic movement). Special Issue R917 behavioural and biomechanical point of view, control theo- retic models of biped locomotion are frequently criticized to be rather far way from known characteristics in primates. It may well be that our scientiﬁc quest for analysable models and algorithms will need to be replaced in the future by a more empirical, i.e., data and learning driven approach, as our mathematical manipulation tools of nonlinear movement systems in contact with complex environments are too limited. Conclusions Brains have co-evolved with bodies to produce tangible effects in the physical world by mediating the continuous loop between sensing and action that deﬁnes the success or failure of intelligent life. Understanding the brain thus re- quires understanding the behavioural effects of its circuits and processes when they interact with the environment through a physical body. In this review, we have shown that robots and robotic theories have been used in neuro- science to assess an hypothesis by translating it into an operational mechanism in a robot and observing its behaviour (validate or reject knowledge); compare alterna- tive hypotheses against their behavioural outcome (reﬁne knowledge); and propose a novel hypothesis that builds on embodiment or situatedness of the system (generate new knowledge). Similarly, robots that must autonomously operate in partially unknown and changing environments, as living sys- tems do, can beneﬁt from incorporating principles of neuro- science because it is impossible to pre-program such robots for all possible sensory-motor patterns that they will encounter during their operational life. In this review, we have shown that neuroscience can help robotics to devise novel sensing and actuation devices that simplify the control problem by increasing robustness, ﬂexibility, and adaptability. It can further help develop simple and yet robust algorithms that effectively map sensory in- formation into motor commands in a wide variety of environ- mental situations and add learning capabilities to adapt to changing situations or incorporate new sensory-motor knowledge. However, just ‘blindly’ implementing biologically inspired behaviour in a robot may not provide any insights into biology nor novel ideas for robotics. Similarly, applying theo- retical and algorithmic knowledge from robotics to biological modelling may not have any valid application to understand- ing brains. Most successful projects had prudent iterations between neuroscience and robotics until the right questions were asked, good methods were devised, and ﬁnally com- pelling results could be obtained. David Marr’s [71] strategic thinking in terms of theory, algorithms and implementation may remain a useful guiding principle: theory could be shared between neuroscience and robotics, algorithms may be similar, while implementations are usually quite dif- ferent due to different hardware. Richard Feynman’s quote of ‘‘What I cannot build, I cannot understand.’’ is at the essence of the interaction of neuroscience and robotics, as, in the end, biological and robotic systems have to deal with largely similar physics and similar environments. Acknowledgments This work was supported in parts by the Swiss National Center of Competence in Research (NCCR) Robotics, the Max-Planck-Society, and the U.S. National Science Foundation. References 1. Freeman, W.J. (2001). Biographical Essay on W. Grey Walter (Encyclopedia of Cognitive Science). 2. Walter, W.G. (1950). An imitation of life. Sci. Am. 182, 42–45. 3. Braitenberg, V. (1986). Vehicles: Experiments in Synthetic Psychology (MIT press). 4. Chiel, H.J., and Beer, R.D. (1997). The brain has a body: adaptive behavior emerges from interactions of nervous system, body and environment. Trends Neurosci. 20, 553–557. 5. Cliff, D. (1991). Computational neuroethology: a provisional manifesto. In J.A. Meyer and S.W. Wilson (eds) from Animals to Animats 3: Proceeding of the First International Conference on the simulation of Adaptive Behav- iour. pp. 29–39. 6. Nishikawa, K., Biewener, A.A., Aerts, P., Ahn, A.N., Chiel, H.J., Daley, M.A., Daniel, T.L., Full, R.J., Hale, M.E., Hedrick, T.L., et al. (2007). Neurome- chanics: an integrative approach for understanding motor control. Integr. Comparative Biol. 47, 16–54. 7. Webb, B. (2002). Robots in invertebrate neuroscience. Nature 417, 359–363. 8. Webb, B., and Scutt, T. (2000). A simple latency-dependent spiking-neuron model of cricket phonotaxis. Biol. Cybern. 82, 247–269. 9. Grasso, F.W., Consi, T.R., Mountain, D.C., and Atema, J. (2000). Biomimetic robot lobster performs chemo-orientation in turbulence using a pair of spatially separated sensors: Progress and challenges. Robotics Autono- mous Systems 30, 115–131. 10. Pyk, P., i Badia, S.B., Bernardet, U., Knu¨ sel, P., Carlsson, M., Gu, J., Chanie, E., Hansson, B.S., Pearce, T.C., and Verschure, P.F. (2006). An artiﬁcial moth: Chemical source localization using a robot based neuronal model of moth optomotor anemotactic search. Auton. Robot 20, 197–213. 11. Floreano, D., Zufferey, J.-C., Srinivasan, M.V., and Ellington, C. (2009). Flying Insects and Robots (Springer). 12. Horridge, G.A., and Longuet-Higgins, H.C. (1992). What can engineers learn from insect vision?[and Discussion]. Philos. Trans. R. Soc. Lond. B. Biol. Sci. 337, 271–282. 13. Borst, A., and Haag, J. (2002). Neural networks in the cockpit of the ﬂy. J. Comp. Physiol. A 188, 419–437. 14. Koenderink, J.J. (1986). Optic ﬂow. Vision Res. 26, 161–179. 15. Wagner, H. (1986). Flight performance and visual control of ﬂight of the free-ﬂying houseﬂy (Musca domestica L.) I. Organization of the ﬂight motor. Philos. Trans. R. Soc. Lond. B. Biol. Sci. 312, 527–551. 16. Franceschini, N., Pichon, J.-M., Blanes, C., and Brady, J.M. (1992). From in- sect vision to robot vision [and discussion]. Philos. Trans. R. Soc. Lond. B. Biol. Sci. 337, 283–294. 17. Srinivasan, M.V. (2011). Honeybees as a model for the study of visually guided ﬂight, navigation, and biologically inspired robotics. Physiol. Rev. 91, 389–411. 18. Franceschini, N., Rufﬁer, F., and Serres, J. (2007). A bio-inspired ﬂying robot sheds light on insect piloting abilities. Curr. Biol. 17, 329–335. 19. Zufferey, J.-C., Klaptocz, A., Beyeler, A., Nicoud, J.-D., and Floreano, D. (2007). A 10-gram vision-based ﬂying robot. Advanced Robotics 21, 1671–1684. 20. Beyeler, A., Zufferey, J.-C., and Floreano, D. (2009). Vision-based control of near-obstacle ﬂight. Auton. Robot 27, 201–219. 21. Humbert, J.S., Conroy, J.K., Neely, C.W., and Barrows, G. (2010). Wide-ﬁeld integration methods for visuomotor control. In Flying Insects and Robots (Springer), pp. 63–71. 22. Song, Y.M., Xie, Y., Malyarchuk, V., Xiao, J., Jung, I., Choi, K.-J., Liu, Z., Park, H., Lu, C., Kim, R.-H., et al. (2013). Digital cameras with designs inspired by the arthropod eye. Nature 497, 95–99. 23. Floreano, D., Pericet-Camara, R., Viollet, S., Rufﬁer, F., Bru¨ ckner, A., Leitel, R., Buss, W., Menouni, M., Expert, F., Juston, R., et al. (2013). Miniature curved artiﬁcial compound eyes. Proc. Natl. Acad. Sci. USA 110, 9267– 9272. 24. Fuller, S.B., Karpelson, M., Censi, A., Ma, K.Y., and Wood, R.J. (2014). Con- trolling free ﬂight of a robotic ﬂy using an onboard vision sensor inspired by insect ocelli. J. R. Soc. Interface 11, 20140281. 25. Daltorio, K.A., Boxerbaum, A.S., Horchler, A.D., Shaw, K.M., Chiel, H.J., and Quinn, R.D. (2013). Efﬁcient worm-like locomotion: slip and control of soft- bodied peristaltic robots. Bioinspiration Biomimetics 8, 035003. 26. Kovac, M., Fuchs, M., Guignard, A., Zufferey, J.-C., and Floreano, D. (2008). A miniature 7g jumping robot. IEEE International Conference on Robotics and Automation. pp. 373–378. 27. Ma, K.Y., Chirarattananon, P., Fuller, S.B., and Wood, R.J. (2013). Controlled ﬂight of a biologically inspired, insect-scale robot. Science 340, 603–607. 28. Hu, D.L., Chan, B., and Bush, J.W. (2003). The hydrodynamics of water strider locomotion. Nature 424, 663–666. 29. Song, Y.S., and Sitti, M. (2007). Surface-tension-driven biologically inspired water strider robots: Theory and experiments. Robotics IEEE Trans. 23, 578–589. Current Biology Vol 24 No 18 R918 30. Izquierdo, E.J., and Beer, R.D. (2013). Connecting a connectome to behavior: an ensemble of neuroanatomical models of C. elegans klinotaxis. PLoS Comput. Biol. 9, e1002890. 31. Beer, R.D., Chiel, H.J., Quinn, R.D., Espenschied, K.S., and Larsson, P. (1992). A distributed neural network architecture for hexapod robot loco- motion. Neural. Comput. 4, 356–365. 32. Ijspeert, A.J. (2008). Central pattern generators for locomotion control in animals and robots: a review. Neural. Netw. 21, 642–653. 33. Cruse, H. (1990). What mechanisms coordinate leg movement in walking arthropods? Trends Neurosci. 13, 15–21. 34. Nelson, G.M., Quinn, R.D., Bachmann, R.J., Flannigan, W.C., Ritzmann, R.E., and Watson, J.T. (1997). Design and simulation of a cockroach-like hexapod robot. In Proc. of the 1997 Intl. Conf. on Robotics and Automation. pp. 1106–1111. 35. Kingsley, D.A., Quinn, R.D., and Ritzmann, R.E. (2006). A cockroach inspired robot with artiﬁcial muscles. In Intelligent Robots and Systems 2006 IEEE/RSJ International Conference. pp. 1837–1842. 36. Ayers, J., and Witting, J. (2007). Biomimetic approaches to the control of underwater walking machines. Phil. Trans. R. Soc. A Mathematical Phys. Eng. Sci. 365, 273–295. 37. Spagna, J.C., Goldman, D.I., Lin, P.-C., Koditschek, D.E., and Full, R.J. (2007). Distributed mechanical feedback in arthropods and robots sim- pliﬁes control of rapid running on challenging terrain. Bioinspiration Biomi- metics 2,9. 38. Zeil, J., Boeddeker, N., and Stu¨ rzl, W. (2010). Visual homing in insects and robots. In Flying Insects and Robots (Springer), pp. 87–100. 39. Cartwright, B.A., and Collett, T.S. (1983). Landmark learning in bees. J. Comp. Physiol. 151, 521–543. 40. Anderson, A.M. (1977). A model for landmark learning in the honey- bee. J. Comp. Physiol. A 114, 335–355. 41. Lambrinos, D., Mo¨ ller, R., Labhart, T., Pfeifer, R., and Wehner, R. (2000). A mobile robot employing insect strategies for navigation. Robot. Auton. Sys. 30, 39–64. 42. Mo¨ ller, R. (2000). Insect visual homing strategies in a robot with analog pro- cessing. Biol. Cybern. 83, 231–243. 43. Mo¨ ller, R. (2009). Local visual homing by warping of two-dimensional images. Robot. Auton. Sys. 57, 87–101. 44. Franz, M.O., Scho¨ lkopf, B., Mallot, H.A., and Bu¨ lthoff, H.H. (1998). Learning view graphs for robot navigation. Autonomous Robots 5, 111–125. 45. Zeil, J., Hofmann, M.I., and Chahl, J.S. (2003). Catchment areas of pano- ramic snapshots in outdoor scenes. JOSA A 20, 450–469. 46. Grillner, S., Robertson, B., and Stephenson-Jones, M. (2013). The evolu- tionary origin of the vertebrate basal ganglia and its role in action selection. J. Physiol. 591, 5425–5431. 47. Grillner, S., Deliagina, T., Manira El, A., Hill, R.H., Orlovsky, G.N., Walle´ n, P., Ekeberg, O., and Lansner, A. (1995). Neural networks that co-ordinate locomotion and body orientation in lamprey. Trends Neurosci. 18, 270–279. 48. Wilbur, C., Vorus, W., Cao, Y., and Currie, S.N. (2002). A Lamprey-based Undulatory Vehicle (Cambridge, MA: MIT Press). 49. Manfredi, L., Assaf, T., Mintchev, S., Marrazza, S., Capantini, L., Oroﬁno, S., Ascari, L., Grillner, S., Walle´ n, P., Ekeberg, O¨ ., et al. (2013). A bioinspired autonomous swimming robot as a tool for studying goal-directed locomo- tion. Biol. Cybern. 107, 513–527. 50. Ekeberg, O¨ . (1993). A combined neuronal and mechanical model of ﬁsh swimming. Biol. Cybern. 69, 363–374. 51. Ijspeert, A.J., Crespi, A., Ryczko, D., and Cabelguen, J.M. (2007). From swimming to walking with a salamander robot driven by a spinal cord model. Science 315, 1416–1420. 52. Cabelguen, J.-M., Bourcier-Lucas, C., and Dubuc, R. (2003). Bimodal loco- motion elicited by electrical stimulation of the midbrain in the salamander Notophthalmus viridescens. J. Neurosci. 23, 2434–2439. 53. Kimura, H., Fukuoka, Y., and Konaga, K. (2001). Adaptive dynamic walking of a quadruped robot using a neural system model. Advanced Robotics 15, 859–878. 54. Kimura, H., Fukuoka, Y., and Cohen, A.H. (2007). Adaptive dynamic walking of a quadruped robot on natural ground based on biological concepts. Int. J. Robot Res. 26, 475–490. 55. Pearson, K.G. (2004). Generating the walking gait: role of sensory feedback. Prog. Brain Res. 143, 123–129. 56. Owaki, D., Kano, T., Nagasawa, K., Tero, A., and Ishiguro, A. (2013). Simple robot suggests physical interlimb communication is essential for quad- ruped walking. J. R. Soc. Interface 10, 20120669. 57. MacIver, M.A., Fontaine, E., and Burdick, J.W. (2004). Designing future un- derwater vehicles: principles and mechanisms of the weakly electric ﬁsh. IEEE J. Oceanic Eng. 29, 651–659. 58. Pearson, M.J., Pipe, A.G., Melhuish, C., Mitchinson, B., and Prescott, T.J. (2007). Whiskerbot: a robotic active touch system modeled on the rat whisker sensory system. Adaptive Behavior 15, 223–240. 59. Held, R., and Hein, A. (1963). Movement-produced stimulation in the devel- opment of visually guided behavior. J. Comp. Physiol. Psychol. 56, 872. 60. Suzuki, M., Floreano, D., and Di Paolo, E. (2005). The contribution of active body movement to visual development in evolutionary robots. Neural Networks, 656–665. 61. Neveln, I.D., Bai, Y., Snyder, J.B., Solberg, J.R., Curet, O.M., Lynch, K.M., and MacIver, M.A. (2013). Biomimetic and bio-inspired robotics in electric ﬁsh research. J. Exp. Biol. 216, 2501–2514. 62. Solberg, J.R., Lynch, K.M., and MacIver, M.A. (2008). Active electrolocation for underwater target localization. Inter. J. Robot. Res. 27, 529–548. 63. Boyer, F., Gossiaux, P.B., Jawad, B., Lebastard, V., and Porez, M. (2012). Model for a sensor inspired by electric ﬁsh. IEEE Trans. Robotics 28, 492–505. 64. Prescot, T.J., Pearson, M.J., and Mitchinson, B. (2009). Whisking with ro- bots. IEEE Robotics and Automation Magazine, September, 42–50. 65. Schroeder, C.L., and Hartmann, M.J. (2012). Sensory prediction on a whiskered robot: a tactile analogy to ‘‘optical ﬂow’’. Front. Neurorobotics (6). 66. O’Keefe, J., and Burgess, N. (1996). Geometric determinants of the place ﬁelds of hippocampal neurons. Nature 381, 425–428. 67. Touretzky, D.S., Wan, H.S., and Redish, A.D. (1994). Neural representa- tion of space in rats and robots. Computational Intelligence Imitating Life, 57–68. 68. Burgess, N., Donnett, J.G., Jeffery, K.J., and John, O. (1997). Robotic and neuronal simulation of the hippocampus and rat navigation. Philos. Trans. R. Soc. Lond. B. Biol. Sci. 352, 1535–1543. 69. O’Keefe, J. (1979). A review of the hippocampal place cells. Prog. Neurobiol. 13, 419–439. 70. Fleischer, J.G., Gally, J.A., Edelman, G.M., and Krichmar, J.L. (2007). Retro- spective and prospective responses arising in a modeled hippocampus during maze navigation by a brain-based device. Proc. Natl. Acad. Sci. USA 104, 3556–3561. 71. Marr, D. (1982). Vision - A Computational Investigation into the Human Rep- resentation and Processing of Visual Information (San Francisco, CA: W.H. Freeman and Company). 72. Hildreth, E.C., and Hollerbach, J.M. (1985). The Computational Approach to Vision and Motor Control (A.I. Memo 846, Massachusetts Intitute of Technology). 73. Marr, D. (1968). A theory of cerebellar cortex. J. Physiol. 202, 437–470. 74. Albus, J.S. (1975). A new approach to manipulator control: The Cerebellar Model Articulation Controller (CMAC). ASME J. Dynamic Systems Mea- surements Control 97, 228–233. 75. Ito, M. (1982). Cerebellar control of the vestibulo-ocular reﬂex - Around the ﬂocculus hypothesis. Annu. Rev. Neurosci., 275–296. 76. Hogan, N. (1984). Adaptive control of mechanical impedance by coactiva- tion of antagonist muscles. IEEE Trans. Automatic Control 29, 681–690. 77. Flash, T., and Hogan, N. (1985). The coordination of arm movements: An experimentally conﬁrmed mathematical model. J. Neurosci. 5, 1688–1703. 78. Slotine, J.J.E., and Li, W. (1991). Applied Nonlinear Control (Englewood Cliffs, NJ: Prentice Hall). 79. Latash, M.L. (1993). Control of Human Movement (Champaign, IL: Human Kinetics Publisher). 80. Gomi, H., and Kawato, M. (1996). Equilibrium-point control hypothesis examined by measured arm stiffness during multijoint movement. Science 272, 117–220. 81. Wolpert, D.M., Miall, R.C., and Kawato, M. (1998). Internal models in the cerebellum. Trends Cogn. Sci. 2, 338–347. 82. Kawato, M. (1999). Internal models for motor control and trajectory plan- ning. Curr. Opin. Neurobiol. 9, 718–727. 83. An, C.H., Atkeson, C.G., and Hollerbach, J.M. (1987). Model-Based Control of a Robot Manipulator (MIT Press (MA)). 84. Kawato, M. (1990). Feedback-error learning neural network for supervised motor learning. In Advances in Neural Computation (North-Holland: Elsev- ier), pp. 365–372. 85. Shibata, T., and Schaal, S. (2001). Biomimetic gaze stabilization based on feedback-error-learning with nonparametric regression networks. Neural Netw. 14, 201–216. 86. Nakanishi, J., and Schaal, S. (2004). Feedback error learning and nonlinear adaptive control. Neural Networks 17, 1453–1465. 87. Grossberg, S., and Kuperstein, M. (1989). Neural Dynamics of Adaptive Sensory-motor Control (Cambridge Univ. Press). 88. Imamizu, H., Kuroda, T., Miyauchi, S., Yoshioka, T., and Kawato, M. (2003). Modular organization of internal models of tools in the human cerebellum. Proc. Natl. Acad. Sci. USA 100, 5461–5466. 89. Gomi, H., and Kawato, M. (1993). Recognition of manipulated objects by motor learning with modular architecture networks. Neural Networks 6, 485–497. 90. Atkeson, C.G., Moore, A.W., and Schaal, S. (1997). Locally weighted learning for control. Artif. Intell. Rev. 11, 75–113. 91. Schaal, S., and Atkeson, C.G. (1994). Robot juggling: implementation of memory-based learning. IEEE Control Systems Magazine 14, 57–71. Special Issue R919 92. Schaal, S., and Atkeson, C.G. (1998). Constructive incremental learning from only local information. Neural Comput. 10, 2047–2084. 93. Vijayakumar, S., D’Souza, A., and Schaal, S. (2005). Incremental online learning in high dimensions. Neural Comput. 17, 2602–2634. 94. Mehta, B., and Schaal, S. (2002). Forward models in visuomotor control. J. Neurophysiol. 88, 942–953. 95. Morasso, P. (1981). Spatial control of arm movements. Exp. Brain Res. 42, 223–227. 96. Morasso, P. (1983). Three dimensional arm trajectories. Biol Cybern. 48, 187–194. 97. Stein, R.B., Oguszto¨ reli, M.N., and Capaday, C. (1986). What is optimized in muscular movements? In Human Muscle Power, N.L. Jones, N. McCartney, and A.J. McComas, eds. (Champaign, Illinois: Human Kinetics Publisher), pp. 131–150. 98. Todorov, E. (2004). Optimality principles in sensorimotor control. Nat. Neurosci. 7, 907–915. 99. Shadmehr, R., and Wise, S.P. (2005). The Computational Neurobiology of Reaching and Pointing: a Foundation for Motor Learning (Cambridge, Mass.: MIT Press). 100. Scott, S.H. (2004). Optimal feedback control and the neural basis of voli- tional motor control. Nature 5, 532–546. 101. Todorov, E. (2009). Efﬁcient computation of optimal actions. Proc. Natl. Acad. Sci. USA 106, 11478–11483. 102. Theodorou, E.A., Buchli, J., and Schaal, S. (2010). A generalized path inte- gral control approach to reinforcement learning. J. Mach. Learn Res. 11, 3137–3181. 103. Stulp, F., Buchli, J., Ellmer, A., Mistry, M., Theodorou, E., and Schaal, S. (2012). Model-free reinforcement learning of impedance control in stochastic environments. IEEE Trans. Autonomous Mental Development, 1. 104. Schaal, S. (1999). Is imitation learning the route to humanoid robots? Trends Cogn. Sci. 3, 233–242. 105. Ijspeert, A.J., Nakanishi, J., Hoffmann, H., Pastor, P., and Schaal, S. (2013). Dynamical movement primitives: learning attractor models for motor behaviors. Neural. Comput. 25, 328–373. 106. Sternad, D., and Schaal, D. (1999). Segmentation of endpoint trajectories does not imply segmented control. Exp. Brain Res. 124, 118–136. 107. Schaal, S., and Sternad, D. (2001). Origins and violations of the 2/3 power law in rhythmic 3D movements. Exp. Brain Res. 136, 60–72. 108. Bullock, D., and Grossberg, S. (1988). Neural dynamics of planned arm movements: Emergent invariants and speed-accuracy properties during trajectory formation. Psychol. Rev. 95, 49–90. 109. Schaal, S., Mohajerian, P., and Ijspeert, A. (2007). Dynamics systems vs. optimal control–a unifying view. Prog. Brain Res. 165, 425–445. 110. Schaal, S., Sternad, D., Osu, R., and Kawato, M. (2004). Rhythmic move- ment is not discrete. Nat. Neurosci. 7, 1137–1144. 111. Billard, A., Calinon, S., Dillmann, R., and Schaal, S. (2008). Robot programming by demonstration. In Handbook of Robotics, B. Siciliano and O. Khatib, eds. (MIT Press). 112. Pastor, P., Kalakrishnan, M., Meier, F., Stulp, F., Buchli, J., Theodorou, E., and Schaal, S. (2013). From dynamic movement primitives to associative skill memories. Robot. Auton. Sys. 61, 351–361. 113. Rizzolatti, G., Fadiga, L., Gallese, V., and Fogassi, L. (1996). Premotor cortex and the recognition of motor actions. Cogn. Brain Res. 3, 131–141. 114. Rizzolatti, G., and Arbib, M.A. (1998). Language within our grasp. Trends Neurosci. 21, 188–194. 115. Arbib, M.A. (2010). Action to Language via the Mirror Neuron System M. Arbib, ed. (Cambridge University Press). 116. Oztop, E., Kawato, M., and Arbib, M. (2006). Mirror neurons and imitation: A computationally guided review. Neural Netw. 19, 254–271. 117. Demiris, Y., and Khadhouri, B. (2006). Hierarchical attentive multiple models for execution and recognition of actions. Robot. Auton. Sys. 54, 361–369. 118. Billard, A., and Schaal, S. (2006). Special issue on the brain mechanisms of imitation learning. Neural. Networks 19, 251–253. 119. Burdet, E., Franklin, D.W., and Milner, T.E. (2013). Human Robotics (MIT Press). 120. Taga, G., Yamaguchi, Y., and Shimizu, H. (1991). Self-organized control of bipedal locomotion by neural oscillators in unpredictable environment. Biol. Cybern. 65, 147–159. 121. Taga, G.G. (1998). A model of the neuro-musculo-skeletal system for antic- ipatory adjustment of human locomotion during obstacle avoidance. Biol. Cybern. 78, 9–17. 122. Endo, G., Morimoto, J., Matsubara, T., Nakanish, J., and Cheng, G. (2008). Learning CPG-based biped locomotion with a policy gradient method: Application to a humanoid robot. Int. J. Robot. Res. 27, 213–228. 123. Matsubara, T., Morimoto, J., Nakanishi, J., Sato, M.A., and Doya, K. (2006). Learning CPG-based biped locomotion with a policy gradient method. Robot. Auton. Sys. 54, 911–920. 124. Aoi, S., and Tsuchiya, K. (2005). Locomotion control of a biped robot using nonlinear oscillators. Auton. Robot. 19, 219–232. 125. Geng, T., Porr, B., and Worgotter, F. (2006). A reﬂexive neural network for dynamic biped walking control. Neural Comput. 18, 1156–1196. 126. Geng, T., Porr, B., and Worgotter, F. (2006). Fast biped walking with a sensor-driven neuronal controller and real- time online learning. Int. J. Robot Res. 25, 243–259. 127. Collins, S., Ruina, A., Tedrake, R., and Wisse, M. (2005). Efﬁcient bipedal ro- bots based on passive-dynamic walkers. Science 307, 1082–1085. 128. Hodgins, J.K., and Raibert, M.H. (1989). Biped gymnastics. Int. J. Robot Res., 249–252. 129. Raibert, M. (1986). Legged Robots that Balance (Cambridge, MA: MIT Press). 130. Kajita, S., and Espiau, B. (2008). Legged robots. In Handbook of Robotics, B. Sicilian and O. Khatib, eds. (Springer). 131. Kajita, S., and Espiau, B. (2008). Legged Robots. In Handbook of robotics (Springer). 132. Pratt, J., Carff, J., Drakunov, S., and Goswami, A. (2006). Capture point: A step toward humanoid push recovery. In 2006 6th IEEE-RAS International Conference on Humanoid Robots. pp. 1976–1983. 133. Koolen, T., de Boer, T., Rebula, J., Goswami, A., and Pratt, J. (2012). Cap- turability-based analysis and control of legged locomotion, Part 1: Theory and application to three simple gait models. Inter. J. Robot. Res. 31, 1094–1113. 134. Yun, S.-K., and Goswami, A. (2011). Momentum-based reactive stepping controller on level and non-level ground for humanoid robot push recovery. IROS. pp. 3943–3950. 135. Full, R.J.R., and Koditschek, D.E.D. (1999). Templates and anchors: neuro- mechanical hypotheses of legged locomotion on land. J. Exp. Biol. 202, 3325–3332. Current Biology Vol 24 No 18 R920","libVersion":"0.3.2","langs":""}