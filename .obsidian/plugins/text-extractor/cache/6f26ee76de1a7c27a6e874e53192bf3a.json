{"path":"_aula_virtual/SJK001/T1C9b  - A motivating case study.pdf","text":"Manual\tRobotic\tIntelligence\t\t \t \t \t Angel\tP.\tdel\tPobil\t\t \t Professor,\tComputer\tScience\t&\tEngineering\tDept.,\tJaume-I\tUniversity,\tSpain\t Director,\tUJI\tRobotic\tIntelligence\tLaboratory,\tSpain\t \t \t The\tChallenge\tof\tManual\tIntelligence\t 2\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t The\tchallenge\tof\tmanual\tintelligence*\tfor\t autonomous,\tversatile\tand\tdependable\t physical\tinteraction\tcalls\tfor\ta\tcommon\t framework\tin\twhich\ttasks\tare\tspecified,\t planned,\tand\texecuted.\t \t 1st\tchallenge\t *\tHelge\tRitter\tet\tal.,\t\"Manual\tIntelligence\tas\ta\tRosetta\tStone\tfor\tRobot\tCognition\",\tRobotics\tResearch,\t\tSpringer,\t2011,\tVol.\t66,\t135-146\t Methodology:\tA\tframework\tfor\tphysical\tinteraction\t We\tvalidated\tit\tin\tfour\tdifferent\tenvironments:\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 3\t General\tmethod\tfor\tthe\tspecification\tof\ttask- oriented\tgrasps\tand\treliable\tmultisensor\t execution\tof\tdisparate\teveryday\ttasks\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 4\t Talk\tavailable\tat\thttps://vimeo.com\t Methodology:\tA\tframework\tfor\tphysical\tinteraction\t Concept\tof\tphysical\tinteraction\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 5\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 6\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 7\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 8\t9\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t The\tdependable\texecution\tof\tphysical\t interaction\ttasks\tcalls\tfor\tthe\t combination\tof\tvision,\ttactile\tand\tforce\t feedback\t 3rd\tchallenge\t The\tChallenge\tof\tManual\tIntelligence\tFPI\tExecution\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 10\t Taking\ta\tbook\tfrom\ta\tbookshelf\t Tactile-force\tcombination\tfor\tobject-to-hand\t estimation\tand\tdependable\tgrasping\tof\tbooks\t Control\tbased\ton\t tactile\tsensors\tlooks\tfor\t a\tgood\tcontact\t Force\tcontrol\tallows\tto\t push\tagainst\tthe\tbook\t and\tavoid\tsliding.\t Motion\tis\tautomatically\t adapted\tto\tthe\t particular\tbook\tsize\t Vision\tprovides\ta\t coarse\tinitial\tposition\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 11\t Vision–Force–Tactile\tIntegration\tfor\topening\ta\tdoor\t A\tcontrol\talgorithm\twhere\tvision,\tforce\tand\t tactile\tinformation\tis\tintegrated\taccording\tto\t a\tpriority\tapproach:\t \t • \tAny\td.o.f\tis\tcontrolled\tby\ttactile\t information\twhenever\tpossible,\tbecause\tit's\t the\tmost\taccurate\tand\trobust\tsensor.\t • \tThose\td.o.f's\tfor\twhich\ttactile\tsensors\t doesn't\tprovide\tenough\tevidence,\tare\t controlled\tby\tvisual\tinformation.\t • \tAll\tof\tthem\tare\tenclosed\tin\tan\timpedance- based\tforce\tcontrol\tloop\t A.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 13\tA.P.\tdel\tPobil\t–\tCambridge\tMarch\t2018\t 14","libVersion":"0.3.2","langs":""}