{"path":"_aula_virtual/SJK001/Reading Assessments/[Liu18] CPS-Based SmartWarehouse for Industry 4.0-A Survey of the Underlying Technologies.pdf","text":"computers Article CPS-Based Smart Warehouse for Industry 4.0: A Survey of the Underlying Technologies Xiulong Liu ID , Jiannong Cao *, Yanni Yang and Shan Jiang ID Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; xiulong.liu@polyu.edu.hk (X.L.); yan-ni.yang@connect.polyu.hk (Y.Y.); cssjiang@comp.polyu.edu.hk (S.J.) * Correspondence: jiannong.cao@polyu.edu.hk; Tel.: +852-2766-7275 Received: 16 November 2017; Accepted: 29 January 2018; Published: 2 February 2018 Abstract: This paper discusses how the state-of-the-art techniques in cyber-physical systems facilitate building smart warehouses to achieve the promising vision of industry 4.0. We focus on four signiﬁcant issues when applying CPS techniques in smart warehouses. First, efﬁcient CPS data collection: when limited communication bandwidth meets numerous CPS devices, we need to make more effort to study efﬁcient wireless communication scheduling strategies. Second, accurate and robust localization: localization is the basis for many fundamental operations in smart warehouses, but still needs to be improved from various aspects like accuracy and robustness. Third, human activity recognition: human activity recognition can be applied in human–computer interaction for remote machine operations. Fourth, multi-robot collaboration: smart robots will take the place of humans to accomplish most tasks particularly in a harsh environment, and smart and fully-distributed robot collaborating algorithms should be investigated. Finally, we point out some challenging issues in the future CPS-based smart warehouse, which could open some new research directions. Keywords: cyber-physical systems; smart warehouse; Industry 4.0; RFID; Wi-Fi; multi-robot systems 1. Introduction The human history has witnessed three times industrial revolutions. Nowadays, we come to the fourth industrial revolution, i.e., Industry 4.0. As shown in Figure 1a, the research community has been developing a variety of technologies for Industry 4.0, such as Radio-Frequency IDentiﬁcation (RFID), NarrowBand IoT (NB-IoT), Wi-Fi, Near-Field Communication (NFC), 5th Generation mobile networks (5G), Global Positioning System (GPS), Wireless Sensor Network (WSN), robotics, etc. In this paper, we focus on the technologies towards building smart warehouses [1]. In a traditional warehouse, the operations of pickup, delivery, and bookkeeping are accomplished by storekeepers. There are several drawbacks of conventional warehouses. First, it is time-consuming to store/fetch inventories into/from them. Second, the usage of storekeepers is a waste of human resources. Finally, it is not environmentally friendly to record the stocks using account books. Therefore, it is profoundly essential to make traditional warehouse smart. A smart warehouse is an automated, unmanned, and paperless warehouse when conducting the operations of pickup, delivery, and bookkeeping. The insight to make traditional warehouses smart lies in using Cyber-Physical System (CPS) [2]. A CPS can monitor and create a virtual copy of the real-world industry processes, and thus we can know the status of each industry process, control and make proper decisions in a real-time manner. In other words, CPS can bring the virtual and physical worlds together to construct an entirely networked world, where smart objects communicate and interact with each other. At that time, time-efﬁciency, energy-efﬁciency, and accuracy will be signiﬁcantly improved while cost, error rate, and waste will be substantially decreased. Although CPS has the potential to bring revolution to traditional warehouses, it is not easy to integrate CPS techniques into smart warehouses for Industry 4.0. Computers 2018, 7, 13; doi:10.3390/computers7010013 www.mdpi.com/journal/computers Computers 2018, 7, 13 2 of 17 a) Popular Technologies for Industry 4.0 Efficient Communication Scheduling Accurate and Robust Localization Human Activity Recognition b) Research Topics for Smart Warehouse Application Figure 1. Popular techniques for Industry 4.0 and research topics in the context of smart warehouse. In a CPS-based smart warehouse, each inventory is afﬁxed with one or more low-cost devices such as RFID tags and NFC tags; various CPS devices, such as Wi-Fi APs (Access Points), BLE (Bluetooth Low Energy) beacons, and cameras are deployed in the environment; multiple robots are navigating in the environment for speciﬁc purposes; and human beings are only responsible for sending required instructions to the warehouse and monitoring the warehouse if wanted. As stated above, a CPS-based smart warehouse contains four main components: CPS devices, inventories, robots, and human beings. For CPS devices, there can be thousands of CPS devices working together. Thus, we need to schedule the communication among the CPS devices efﬁciently. For inventories, we want to timely know their status and location context according to the data reported by the attached devices. For robots, they are required to collaboratively accomplish some tasks that are repetitive and harmful to human beings. For human beings, we need to recognize their gestures or other activities to do warehouse operation. The gestures and other activities may be extracted using the CPS devices deployed in the environment. Hence, we survey four issues towards building CPS-based smart warehouses. As shown in Figure 1b, the four research topics are efﬁcient communication scheduling, accurate and robust localization, human activity recognition, and multi-robot collaboration: • Efﬁcient Communication Scheduling: In a CPS-based smart warehouse, there can be thousands of CPS devices, e.g., various sensors, RFID readers and tags, BLE beacons, and Wi-Fi APs. The CPS devices form a dense Local Area Network (LAN). In the LAN, some of the data are required to be collected timely, e.g., the data to recognize human activities. However, the limited wireless communication bandwidth may not support real-time data collection from such large number of CPS devices. Therefore, it is signiﬁcant to investigate time-efﬁcient communication scheduling mechanisms. In addition, the communication scheduling mechanism is supposed to be energy-efﬁcient for eco-friendly purposes. • Accurate and Robust Localization: For the basic operations of a warehouse such as inventory fetching and tracking, we need to know the location of the concerned objects. Localization is a classical and important problem, and various techniques such as GPS, Wi-Fi, Bluetooth, and RFID have been developed for localization. However, different localization approaches have different drawbacks. For example, GPS suffers from low accuracy for indoor localization; Wi-Fi can only track the objects equipped with smartphones; BLE beacons have a short lifetime due to the limited battery volume [3]; and RFID has relatively short communication range (usually less than 10 m). Hence, we need to make efforts to develop suitable localization techniques for the smart Computers 2018, 7, 13 3 of 17 warehouse scenario. By saying suitable, the localization approach should be accurate, robust, fast, and wide-coverage. • Multi-Robot Collaboration: A smart robot consists of various sensors, accurate actuators, and powerful processors. These components enable a robot to sense extensively, to decide intelligently, and to behave precisely. The industries have been using smart robots in tasks which are difﬁcult, time-consuming, or harmful to human beings. Traditional applications are for manufacturing such as forging, die casting, heat treatment, etc. Nowadays, we enter the age of industry 4.0. Smart robots provide great potential for the smart warehouse. For example, in early 2012, Amazon spent $775 million to build Kiva system, in which smart robots are used to carry and arrange goods in the warehouse. We can see the promising future to use multi-robot system (MRS) in Industry 4.0. To better utilize MRSs, the technologies of task scheduling and local coordination for MRS are required. • Human Activity Recognition: In a warehouse, human beings, as the main operators, play a dominating role in managing various kinds of objects, good, tools, etc. Human activity recognition can be applied in human–computer interaction for remote warehouse operations. If the physical and emotional activities could be recognized, we have more comprehensive inputs to control the warehouse. Therefore, to achieve automated and elaborate industrial manufacturing, transportation, and management, human activity recognition can be quite helpful for the realization and development of Industrial 4.0. The contributions of this paper are as follows: • We give a formal deﬁnition of smart warehouse. That is, a smart warehouse is an automated, unmanned, and paperless warehouse when conducting the operations of pickup, delivery, and bookkeeping. Furthermore, we analyze the underlying technologies towards building a smart warehouse. • We survey the underlying technologies to build a smart warehouse from the aspects of efﬁcient communication scheduling, accurate and robust localization, multi-robot collaboration, and human activity recognition. • We give insights on the future directions towards building smart warehouses. The integration of blockchain, big data analytics, and machine learning technologies with smart warehouse are discussed. The remainder of this paper is organized as follows. From Section 2 to Section 5, we summarize and discuss the existing CPS methodologies from the four perspectives above, and explain how they can facilitate building smart warehouses in future Industry 4.0. In Section 6, we ﬁgure out some future directions and challenges towards building smart warehouses. The integration of smart warehouse with recent technologies, e.g., blockchain, big data analytics, reinforcement learning, and deep learning are introduced. Finally, Section 7 concludes the paper. 2. Efﬁcient Communication Scheduling In the future smart warehouse, each screw, tool, or product may be afﬁxed with a sensor or RFID tag for inventory. Due to the contradiction between the large number of sensing devices and the limited communication resources, it is non-trivial to investigate efﬁcient communication scheduling strategies when collecting sensing data from large-scale CPS devices. By saying large-scale, it means thousands of CPS devices working together. For example, in a smart warehouse, there can be tens of thousands of CPS devices such as RFID tags and readers, BLE beacons, Wi-Fi APs, robots, etc. Compared with the existing automatic identiﬁcation techniques such as barcode, sensor, and Bluetooth, RFID has promising advantages of no requirements on line-of-sight (multiple objects can be identiﬁed simultaneously), battery-free (passive tags have almost inﬁnite service time), and small-size (as thin as a paper), which make RFID more suitable for large-scale deployment in future smart industry. Computers 2018, 7, 13 4 of 17 Therefore, we discuss RFID communication scheduling in this paper. A general solution is to identify all tags’ IDs for inventory. There are two types of tag identiﬁcation protocols: Aloha-based protocols and tree-based protocols. The Aloha-based protocol is a kind of Time Division Multiple Access (TDMA) mechanism. Multiple tags contend for multiple time slots, and a tag can be successfully identiﬁed in a slot when only one tag responds in the selected slot. In tree-based protocols, the RFID reader broadcasts a 0/1 string to query the tags. A tag will respond with its ID once it ﬁnds that the queried string is the preﬁx of its ID. If multiple tags respond, the reader attaches a bit of 0/1 to the end of the previous string. A longer queried string entails the smaller probability of tag collisions. A reader identiﬁes a tag ID when only one tag responds. Although we can gather the most comprehensive data via tag identiﬁcation protocols, it leads to much overhead regarding time efﬁciency or energy efﬁciency. A general solution may not be optimal for a speciﬁc problem, e.g., missing tag detection/identiﬁcation, unknown tag detection/identiﬁcation, RFID tag cardinality estimation, etc. This is because we only want to know which tags are missing or unknown, and the tag cardinality instead of the exact tag IDs. Hence, plenty of attention had been paid to detection/identiﬁcation of missing/unknown tags and the tag cardinality estimation. Missing tags mean the tags that should be present in the warehouse but are absent now, which may be caused by theft. In contrary, unknown tags mean the tags that should not be in the warehouse but present now, which may be caused by misplacement. Detection is to judge whether there is anomaly tag or not; identiﬁcation is to discover all the anomaly tags accurately. The literature [4] has conducted a comprehensive survey of the existing anomaly tag (missing [5,6] or unknown [7–9]) pinpointing protocols, particularly emphasizing the evolution road of the related protocol development. After that, the authors also conduct taxonomy of the existing protocols and summarized their pros and cons, respectively. Hence, this paper will not discuss the details of the protocols that deal with missing/unknown tags again. In this paper, we pay more attention to the existing RFID cardinality estimation protocols. Although RFID identiﬁcation protocols can be used to obtain the exact tag IDs and obviously get the tag cardinality, the involved execution time is extremely high particularly when the number of tags is large (proportional to the number of tags). In the scenarios when we just want to know the approximate number of tags instead of exact tag IDs, it is not efﬁcient to execute the tag identiﬁcation protocols. Hence, a great deal of effort was also made by academic communities to study the tag cardinality estimation problem, which is deﬁned as follows. Given a set of RIFD tags whose cardinality is n, a conﬁdence interval α, a reliability β, we want to obtain the estimation result ˆn such that Pr{| ˆn − n| < n × α} > β. Kodialam et al. took the ﬁrst step to study this problem and proposed the cardinality estimation schemes called Uniﬁed Simple Estimator (USE) and Uniﬁed Probabilistic Estimation (UPE), which use the number of empty or collision slots to estimate population sizes [10]. USE and UPE are used for the RFID systems that use Aloha-based protocols as the MAC (media access control layer communication mechanisms. The basic working principle of these two protocols is as follows. The reader announces a frame size for all tags and then initializes a time-slotted frame. All the tags randomly select time slots in the forthcoming time frame to respond. The reader records the number of empty slots (no tag response), singleton slots (just one tag response), and collision slots (two or more responses). Intuitively, the more tags there are in the vicinity of the reader, the reader observes more collision slots and less empty slots. Moreover, the authors built a functional relationship between the number of tags and the number of empty/collision slots. Then, the number of observed empty/collision slots can be used to calculate the number of tags. The estimation result from one-time frame may not be accurate due to estimation deviation. Hence, multiple frames of estimation are repeated to achieve ﬁne-grained estimation result. Currently, there are a bunch of RFID estimation protocols. Their performance differs because they use the observed slot status differently. Shahzad et al. used the average run length of non-empty slots (i.e., the average length of continuous non-empty slots) for cardinality estimation, and thus proposed the Average Run-based Tag estimation (ART) protocol [11]. ART is faster for obtaining the ﬁne-grained estimation result because the used estimator Computers 2018, 7, 13 5 of 17 has smaller variance. Li et al. revisited the problem of cardinality estimation from the new view of energy-efﬁciency and proposed the Maximum Likelihood Estimator (MLE) [12]. The above RFID estimation protocols are all designed for RFID systems that run the Aloha-based MAC communication mechanisms. Zheng et al. studied this problem for RFID systems that run tree-based communication mechanisms, and proposed Probabilistic Estimation Tree (PET) protocols [13]. The above estimation protocols can only estimate the number of tags that are currently present in the systems. However, some RFID systems are dynamic because some tags are moved out of the system, and some new tags are added to the system. Moreover, the above methods cannot tell how many tags are absent and how many tags are new. For such dynamic scenarios, Xiao et al. compared the observed frame status and the expected frame status, and used the slot status changes to estimate the number of absent/remaining/new tags [14]. Liu et al. found that the estimation protocol in [14] requires the reader to monitor the whole long time frame even if the time frame is quite long. To this end, they proposed the Sampling-based Key tag Tracking (S-KT) protocol, in which an RFID reader only needs to observe the status change of expected singleton slots corresponding to key tags instead of the whole time frame. In fact, the ratio of key tags to all current tags is small because key members are usually rare. As a result, even when the whole time frame is long, the number of expected singleton slots could be still, which makes S-KT faster than the protocol in [14]. Gong et al. focused on the RFID tag cardinality estimation in the context of anti-counterfeiting, and wanted to estimate the number of counterfeit tags whose IDs are not stored in a database, and ﬁnally proposed the INformative Counting (INC) protocol [15]. Liu et al. [16] concerned with the privacy issue of RFID that when an RFID reader queries a tag; no matter whether the reader is authorized or not, it immediately answers with its ID and other information in a broadcast manner. Although a bunch of cryptography-based authentication protocols have been proposed to tackle with malicious scanning, no one is compliant with the C1G2 standard. Furthermore, these protocols often require computational resources that exceed the capability of commercial C1G2-compliant passive RFID tags. If such additional computational capability is indeed implemented, the cost of such tags will be much more expensive than the C1G2-compliant passive tags. Then, the concept of blocker tag was proposed to protect RFID privacy with almost zero-cost on RFID tags. Its basic principle is that the blocker tag could intentionally create signal collisions to prevent malicious attackers from reading information from the privacy-sensitive RFID tags. However, with the presence of blocker tag, none of the existing RFID tag estimation protocols could correctly estimate the number of genuine tags. Then, Liu et al. proposed the RFID estimation scheme with blocker tags (REB), which ﬁrst executes the protocol on the genuine tags and the blocker tag, and then virtually executes the protocol on the known blocking IDs using the same Aloha protocol parameters. Liu et al. also conducted statistical analysis on the two frame status obtained from these two Aloha processes to estimate the number of genuine tags. Liu et al. then considered the energy-efﬁciency for the active RFID systems and studied how to optimize REB protocol for saving energy in [17]. A common assumption of the above RFID cardinality estimation protocols is that all tags belong to the same category. However, in practical scenarios, the items are usually categorized according to types, manufacturing countries, brands, etc. Each RFID tag ID contains two ﬁelds: category ID that describes the category of the tagged items; and member ID that identiﬁes the individual tagged item within the same category. Hence, the tags also belong to different categories. Traditional tag cardinality estimation protocols can only tell the total tag number instead of the tag number in each category. We naturally desire to know the number of tags in each category. To this end, Liu et al. proposed the estimation protocol called Simultaneous Estimation for Multi-category RFID systems (SEM) [18], which exploits the Single-one Manchester coding string and could know which categories of tags responded in a collision slot. Thus, it can make full use of the information in each type of slot and even the corrupted information in the collision slots, which makes it quite time-efﬁcient. Computers 2018, 7, 13 6 of 17 3. Accurate and Robust Localization Accurate object localization beneﬁts various context-aware applications in the era of Industry 4.0, e.g., automatic product tracking and sorting. Currently, there are various localization techniques such as GPS, Wi-Fi, Bluetooth, and RFID. For large-scale warehouse in future Industry 4.0, RFID has attractive advantages over the other techniques. GPS can work well for the outdoor environment (Google Maps, driving navigation) but does not work for the indoor environment. Wi-Fi can pinpoint the location of the human that takes a smartphone. However, it will be nearly impossible to afﬁx each product with a phone. Bluetooth requires each product has a battery-powered beacon device. The limited battery volume severely shortens the lifetime of the localization services. Some other technologies are rising for localization and human activity recognition such as 5G. However, 5G is still on its way and cannot be accessed ubiquitously. Therefore, the relating technology for localization and human activity recognition are not well developed. Compared with the above techniques, passive RFID tags are low-cost (ﬁve cents for each tag), small-size (as thin as a paper), and battery-free (almost inﬁnite lifetime), which make RFID more suitable for localization in Industry 4.0. The existing RFID localization approaches can be classiﬁed into two types: RSS-based approaches (received signal strength), and phase-based approaches. In the infancy of the RFID localization study, Ni et al. exploited the RSS value of RFID tags to implement a localization system called LANDMARC [19]. The basic working principle of LANDMARC is as follows. The manager of a warehouse deploys many reference tags in the surveillance region in prior. As a matter of fact, RSS value closely depends on the distance between tag and reader antenna. Thus, RSS values of the nearby tags should also be similar. The RFID readers keep interrogating the concerned tags as well as the reference tags. For each tag reading, we can obtain not only the tag IDs but also the RSS. Then, we ﬁnd out k reference tags whose RSS values are the closest to that of the concerned tag and use the weighted average of the locations of these k reference tags as the location of the target tag. However, RSS is an unreliable location indicator, especially for UHF tags [20]. Recently, the researchers shifted attention to use RF phase information when addressing the problem of RFID localization. The Angle of Arrival (AOA) based methods make use of multiple reader antenna arrays [21]. For one antenna array, the phase difference is used to measure the angle between the target tag and this antenna array plane. Using two antenna arrays, we can draw two lines based on the measured angles, and the intersection point is expected to be the tag location. Wang et al. implemented a localization system called PinIt [22], which is based on comparing the multi-path effects instead of RSS. Speciﬁcally, they use a moving antenna to measure the multi-path proﬁles of the reference tags at known positions in advance. Then, PinIt locates the target tag according to the insight that nearby tags have similar multi-path effects. For the anonymous RFID system, PinIt is hard to use because we know nothing about the reference tags. Yang et al. proposed the location tracking system called Differential Augmented Hologram (DAH) [23], which exploits the target tag’s mobility to construct a virtual antenna array by using readings from a few physical antennas over time. They further proposed a comprehensive solution to accurately recover the tag’s moving trajectories and its locations, relaxing the assumption of knowing tag’s track function in advance. DAH partitions the monitoring region into grids, and use the collected phase proﬁle to calculate the probability that the target tag locates in each grid. The grid with the highest probability is treated as the location of the target tag. The experimental results reveal that DAH can achieve cm-level accuracy. However, DAH requires precise calibration of the reader antennas. More seriously, for the large surveillance region, DAH needs to deploy multiple sets of reader antennas, which costs a lot. However, RF-Scanner begets high overhead regarding computational complexity, and thus cannot satisfy the real-time requirement for tag-dense RFID systems. To evaluate the existing RFID localization systems, we need to concern with four metrics. Availability: whether the localization system only consists of the Commercial Off-The-Shelf (COTS) devices, and the proposed localization algorithms are only installed as software modules. Mobility: whether a single localization system could be able to cover a vast region in a mobile manner to save cost. Computers 2018, 7, 13 7 of 17 Reliability: whether the system could provide ﬁne-grained localization accuracy (i.e., cm-level) with high conﬁdence. Scalability: whether the computational complexity of the RFID localization algorithms is quite low so that it is scalable to a large number of tags. In Table 1, we have summarized the pros and cons of the existing RFID localization systems. In terms computational complexity, we have to explain the involved notations. x represents the number of tag replies received by the reader; ξ is the number of reference reader antennas; and γ is a factor that is determined by localization granularity. From this table, we can easily ﬁnd that the DAH and RF-Scanner can provide the most accurate localization results. Compared with DAH, RF-Scanner is more suitable for the large-scale environment. Table 1. Comparing the existing RFID (Radio-Frequency IDentiﬁcation) localization protocols. System Availability Mobility Reliability Scalability LANDMARC [19] COTS devices Stationary readers Mean error ∼60 cm Complexity O(ξx) BackPos [24] COTS devices Stationary readers Mean error ∼12 cm Complexity O(x) AoA [21] Self-designed antennas Stationary readers Mean error ∼20 cm Complexity O(x) PinIt [22] USRP Stationary readers Mean error ∼12 cm Complexity O(x) DAH [23] COTS devices Stationary readers Mean error <2 cm Complexity O(γx) RF-Scanner [25] COTS devices Mobile readers Mean error <2 cm Complexity O(γx) USRP: Universal Software Radio Peripheral. 4. Multi-Robot Collaboration No matter what the multi-robot applications are, one of the fundamental problems is to integrate global task scheduling and local coordination. Consider a multi-robot application and a user-deﬁned task assigned to it using some programming model or middleware [26]. The task may consist of multiple subtasks, and the technique of task scheduling is needed. After the subtasks are assigned to each robot, the robots are supposed to execute the subtasks with local coordination. In the following subsections, we introduce the techniques towards solving the problems of task scheduling and local coordination in multi-robot system, respectively. 4.1. Multi-Robot Task Scheduling Many multi-robot tasks involve multiple jobs executed on different robots with speciﬁed end-to-end deadline requirements. These tasks may be deployed to an MRS at any time and on any robot during run-time. For example, a new package delivery task may be deployed on an MRS while a persistent monitoring task is in process. As a result, resource competitions among these tasks can happen on any robot and is unpredictable. Furthermore, an individual robot often does not have full information about the working status of the other robots since the robots form a distributed system. Therefore, scheduling decisions made by individual robots about their local job execution orders may not be optimal for the tasks to which the jobs belong concerning meeting the tasks’ end-to-end deadlines. Task scheduling in distributed systems has been proven to be NP-hard (non-deterministic polynomial-time hard) [27], and the research community has been developing various heuristic strategies to schedule tasks for MRS. We categorize the existing approaches according to three metrics, namely criticality, resource management, and technique as shown in Figure 2. The dimension of “scheduler” represents the member who carries out scheduling. The scheduling can be performed in a centralized, semi-distributed, or fully-distributed way. The scheduling is performed in a “centralized” fashion if a central platform decomposes the task into multiple subtasks and allocate the subtasks to the robots. In this approach, the robots are only responsible for receiving the result subtasks from the central platform and performs them. “Fully-distributed” scheduler means the robots themselves serve as the scheduler. In this fashion, all the robots negotiate with each other and play equal roles. The “semi-distributed” scheduling approach combines the centralized and fully-distributed approaches. The whole MRS is divided into several clusters. Each cluster of robots schedule its tasks independently, and a central platform is responsible for assigning tasks to the clusters. Computers 2018, 7, 13 8 of 17 Hard Real-time Soft Real-time Centralized Fully Distributed Scheduler Criticality TechniqueMarket-based Bio-inspired Hybrid ... Figure 2. A taxonomy of multi-robot task scheduling. Concerning criticality, different multi-robot applications have a different degree of criticality. According to the criticality of the applications, multi-robot task scheduling can be divided into soft real-time (SRT) task scheduling and hard real-time (HRT) task scheduling. For those safety-critical applications, e.g., human-assisted robotic manipulation and operating medical equipment, HRT is required since human beings are involved, and safety issues pop up. For other applications, such as package delivery, missing deadlines can be tolerated, and soft real-time (SRT) is preferred. SRT task scheduling is performed in a best-effort way. There are various techniques for multi-robot task scheduling such as market-based [28,29], bio-inspired [30,31], and hybrid approaches [32]. In the market-based approach, the task is divided into a set of subtasks and the robots bid to carry out these subtasks. Since the robots are assigned limited amounts of money, they have to negotiate with each other to maximize their self-interests. The market-based approach is widely used for multi-robot searching [33] and patrolling [34]. Bio-inspired task scheduling approaches apply the observed rules from nature to solving scheduling problems. For example, mimicking the birds ﬂock for multi-robot pattern formation has been a success story [35]. Generally speaking, market-based and bio-inspired approaches are used for SRT multi-robot task scheduling. When it comes to HRT task scheduling, hybrid methods are always employed. The hybrid approaches utilize design-time computations to identify a timing constraint satisfying allocation at runtime [36,37]. 4.2. Local Coordination in Multi-Robot Systems Local Coordination is critical for multi-robot applications. It is also a research hotspot in the ﬁeld of distributed computing. In literature, the researchers have established various theoretical models for MRS. Based on those models, the fundamental coordination problems are studied. Speciﬁcally, the theoretical models are divided into fully-synchronous, semi-synchronous, and asynchronous [38] and fundamental coordination problems include gathering [39], pattern formation [35,40], ﬂocking [41], and so on. We categorize the local coordination in MRS according to three criteria, namely, system model, and robot ability, the problem as shown in Figure 3. Concerning coordination in MRS, a single robot is often modeled as a loop to perform the three stages of the Look–Compute–Move [38]. In the phase of “Look”, the robot acquires data from itself, surrounding robots and the environment. In the “Compute” phase, the robot runs a deterministic program designed to calculate the action to be taken with the data collected in the “Sense phase. Finally, in the “Move” phase, the robot performs the actions generated by the “Look” phase. Based on the model of “Look–Compute–Move”, there are three theoretical models, namely fully-synchronous, semi-synchronous and asynchronous. For a fully-synchronous multi-robot system, all robots must be in the same phase at the same time. In other words, if there is a robot in the “Compute” phase, then it Computers 2018, 7, 13 9 of 17 can be asserted that all other robots are in the “Compute” phase. For a semi-synchronous multi-robot system, all robots that are active must be in the same phase. For an asynchronous multi-robot system, the robots do not have any relationship concerning the phases. Pattern Formation Gathering Fully-Sync ASync System Model Problem Robot Ability Visibility Memory Geometric agreement ... Flocking ... Figure 3. A taxonomy of local coordination in multi-robot system. The research community always wants to achieve local coordination with the weakest robot ability. By saying robot ability, it includes visibility, memory, geometric agreement, and so on. Concerning visibility, the robots can have unlimited or limited visibility range and can be solid or transparent. With unlimited visibility range, all the robots can see each other while the system always employs unit disk graph as the visibility graph when limited visibility range is considered. The robots are solid if the robots cannot be looked through while transparent robots can. Concerning memory, three models are considered, namely oblivious, unbounded memory, and ﬁnite-state. In the oblivious model, the robots forget everything once a cycle is ﬁnished. In the unbounded memory model, the robots can memorize all the past information and computation for usage while ﬁnite-state model means that the robots have a constant persistent memory. As for the ability of geometric agreement, three models consistent compass, chirality, and disorientation are often considered. In the model of consistent compass, all the robots share the same coordinate system; in the model of chirality, the robots agree on only the direction of one axis; and, in the model of disorientation, the robots have no common sense on the coordinate system. The gathering problem refers to congregating a set of robots, which are initially placed at arbitrary positions, to a single location within a ﬁnite time. The gathering problem is the ﬁrst problem studied in multi-robot coordination and is still a research hotspot. In addition, it has been studied in fully synchronous, semi-synchronous and asynchronous models [42,43]. The pattern formation problem refers to arrange a set of robots to form a given pattern. In literature, some research works are focusing on some speciﬁc patterns, such as circular [44], regular polygonal [45,46], etc. In addition, some research works are focusing on arbitrary patterns [47,48]. The ﬂocking problem is a more complicated task than pattern formation. It studies how a group of robots move while maintaining a given pattern. In nature, the ﬂocking behavior exhibits in many living beings such as ﬁsh and birds. According to whether there are leaders (such as the bellwethers in a group of wild geese), the ﬂocking problem is divided into guided ﬂocking [49] and homogeneous ﬂocking [50]. 5. Human Activity Recognition Many areas in the industry can beneﬁt from human activity recognition. For manufacturing, human activity recognition can be applied for the convenience of workers, like remote operations between human and machines. In addition, it can also be used for monitoring the tiredness of workers in the case of getting sick or injured. For transportation, human activities related to the sorting and Computers 2018, 7, 13 10 of 17 delivering of goods can be detected and monitored to avoid mistakes on the products classiﬁcation. In terms of management, abnormal behavior of speciﬁc or unlicensed individuals can be recognized if they are going to perform damages to anything in a smart warehouse. In the past few decades, different kinds of technologies have been brought up for human activity recognition. Most of the existing work on human activity recognition can be classiﬁed into the following categories: (1) vision-based human activity recognition; (2) sensor-based human activity recognition; and (3) RF-based human activity recognition. Some of them have already been applied in some industries. Next, we will mainly introduce and give a thorough summary of the above three approaches. 5.1. Vision-Based Human Activity Recognition For vision-based human activity recognition, there are mainly three steps: (1) Human Segmentation; (2) Feature Extraction; and (3) Activity Recognition. These three procedures are the basis for vision-based human activity recognition. There are higher level scenarios and applications that require specific setting and modeling, for instance, single-person or multi-person scenario, gesture recognition, human identification, etc. The ﬁrst step, human segmentation, is to segment the human object from the images or a sequence of video screen-shoots. Common methods for human segmentation is to apply background segmentation [51,52] on the images and foreground human objects are extracted. Then, feature extraction is performed to describe the characteristics and movements of the segmented human objects. Different categories of features can be leveraged as features, including space-time volume [53,54], frequency [55], local descriptors [56] and body modeling [57,58]. The last step relies on the activity recognition and classiﬁcation algorithms to recognize different kinds of human activities based on the features extracted above. Traditional, Dynamic Time Warping [59], Hidden Markov Model [60] and some machine learning algorithms, e.g., SVM (Support Vector Machine) and ANN (Artiﬁcial Neural Network), are applied for activity recognition. In recent years, with the development of deep learning technologies, activity recognition has been realized with greater results. For example, Recurrent Neural Network [61] and Convolutional Neural Network [62] have been applied in pose recognition. 5.2. Sensor-Based Human Activity Recognition Sensor-based human activity recognition is to directly attach some sensors on human’s body for activity recognition. Wearable sensors, such as, accelerometer, gyroscope, thermometer and heart monitor, are attached to the body to obtain the information of human motion [63], temperature [64] and health condition [65], etc. Some sensors have been encapsulated into the mobile phone or smartwatches, so people can just use those devices for activity recognition, which can be quite convenient. The general workﬂow of sensor-based human activity recognition is as follows: (1) Data Collection; (2) Data Preprocessing; (3) Feature Extraction; and (4) Activity Recognition. Sensors and attributes are selected to collect data during data collection. Since there are some noises or redundancy in the raw data of the collected data, we need to calibrate the sensor data for further use. Concerning the step of feature extraction, many works tend to extract the features deﬁned by themselves in which features can be extracted and selected one by one statistically and analytically, while people are now using the deep learning algorithm to learn the features automatically without giving too much interpretation or explanation of the properties of the extracted features [66]. However, there is a trade-off between the recognition performance and computation resources when applied different learning algorithms on activity recognition. For example, if mobile phones are used for activity recognition by applying deep learning algorithm, since the computation costs a lot, although the result is decent, the battery will soon run out. Computers 2018, 7, 13 11 of 17 5.3. RF-Based Human Activity Recognition RF-based Human Activity Recognition is to leverage the RF signals, e.g., WiFi, RFID, and Radar signals to recognize a set of activities performed within the detection range of RF signals. The key insight that RF signals can be applied for human activity recognition is that the human presence could affect the propagation of the wireless signal from the transmitter to receiver. In addition, different activities can have different effects on the RF signals so that the pattern in the received signals could be distinctive for different activities. Compared with vision-based and sensor-based approaches, people do not need to wear any sensors on the body, and no pictures will be taken that protect people’s privacy to some degree. RF-based human activity recognition can be classiﬁed into two categories, namely data-based approaches and model-based approaches. Data-based approaches mainly rely on the discovering of the pattern from the data or extracted features of the RF signals based on the machine learning algorithms [67–71]. Some of the extracted features can be interpreted by the behavior while some of them may be hard to explain, e.g., those apply deep learning to extracted features. We do not need to build complex models to describe the behavior; we can learn from the data, so it has broad application scenarios. However, large amounts of training data sets are required to be collected, which is quite labor-intensive. In addition, the wireless signals are sensitive to the environmental changes. So, the training sets will lose its effectiveness when the environment changes. Model-based approaches are proposed to address the limitations of data-based approaches [72–74]. For human activities, some physical quantities of the behavior will be extracted through the wireless communication models, such as angle of arrival (AoA), time of ﬂight (ToF), and speed. Human activities can be interpreted by the physical quantities and then be recognized. However, many commercial devices do not support extracting the precise physical quantities directly from the devices. Therefore, people either need to pay a lot for expensive and specialized devices or perform calibration on the RF signals. Meanwhile, since some activities could be too complicated to be modeled, model-based approaches have limited application scenarios. The general architecture for human activity recognition can be summarized as shown in Figure 4. In the future, not only the object monitoring but also the physical and physiological information of human will be the focus of cyber-physical systems, and, for the industry 4.0, human activity recognition will be integrated to each part of the smart warehouse to provide more intelligent services. Data Collection & Pre-processing Feature/Quantity Extraction Learning/ Modeling Activity Recognition Figure 4. General architecture for human activity recognition. To summarize, the above three approaches for human activity recognition all have their advantages and limitations, as listed in Table 2. Vision-based approaches show encouraging performance for human activity recognition. However, there are still many challenging problems for real-world deployment. Using wearable sensors is a straightforward way for human activity recognition. Ever since the person is performing any activity, there will be a signal reflecting the behavior. However, since people have to wear different kinds of sensors on their body, it could be intrusive for the users. RF-based human activity recognition has attracted much attention since our environment has been covered by wireless signals. Thus, we need to leverage the RF signals around expanding its applications. However, there are still many challenging issues for RF-based human activity recognition. There is still a long way to make it deployed for daily and industrial use. Computers 2018, 7, 13 12 of 17 Table 2. Comparison of different human activity recognition approaches. Devices Advantages Limitation Vision-based Camera, e.g., Kinect and web Precise capture of human Vulnerable to bad lighting camera behavior conditions Sensor-based On-body sensors, e.g., accelerometer and gyroscope Wide popularity of smart devices Intrusive to wear sensors RF-based RF transceivers, e.g, WiFi router and RFID Do not need to wear sensors (non-intrusive) Vulnerable to environmental changes 6. Future Directions and Challenges 6.1. Blockchain-Based Bookkeeping Subsystem Recently, Blockchain technology has been widely employed in many areas such as digital currency [75], transportation [76], government [77], and education [78] due to its features of security, privacy, decentralization, and immutability. A Blockchain is a distributed append-only ledger to store a growing list of transactions. In a smart warehouse, a ledger is needed for bookkeeping. A traditional digital ledger is unsafe concerning malicious modifications. A Blockchain-based bookkeeping subsystem can be the solution to such issue. However, there remain challenges towards building a Blockchain-based bookkeeping subsystem in a smart warehouse. First, Blockchain is publicly accessible by default, which triggers privacy issues for a private warehouse. Second, the current Blockchain-based system only supports low throughput while numerous data can be generated by a smart warehouse. 6.2. Shelf Life Prediction with Multi-Source Data Fusion The shelf life of the products has been a longstanding problem in warehouses [79]. With the development of big data technology, it becomes possible to predict the shelf life of the products. To achieve this, multi-source data, e.g., transportation, weather condition, and warehouse environment should be taken into consideration. Based on the multi-source data, the association or correlation between those data and the shelf life of the products may be mined. However, how to build the model remains open. First, there are too many factors to be taken into consideration at the same time. Second, the collected data can be time- and spatial-dependent. For example, the transportation data must happen before the warehouse environment data. 6.3. Multi-Robot Collaboration via Reinforcement Learning Traditionally, multi-robot collaboration is achieved using distributed algorithms as mentioned in Section 4. The researchers have been trying to ﬁnd elegant solutions for multiple weak robots to perform cooperative tasks. However, the tasks in a real smart warehouse are far more complicated than the formulated ones. It becomes a trend to employ reinforcement learning techniques for robotic tasks [80]. However, it becomes difﬁcult when multiple robots are considered. First, the state space and the action space of the whole system becomes extremely high-dimensional since the number of robots can be very large. Second, it is nontrivial to represent the required cooperation into the rewards in reinforcement learning algorithms. 6.4. High-Level Activity Recognition with Deep Learning As mentioned in Section 5, most of the current systems for human activity recognition can only interpret a limited number of speciﬁc activities. However, in a smart warehouse scenario, the activities to be recognized and evaluated are far more complicated. In addition, the human activity recognition systems are testiﬁed in experimental setup only, while an industrial warehouse requires a robust enough system. The deep learning technology brings opportunities for robust human Computers 2018, 7, 13 13 of 17 activity recognition. However, how to integrate machine learning techniques with computer vision, signal processing, and time series analysis for better inference of human activities remains open. 7. Conclusions In this paper, we proposed a CPS-based smart warehouse in the era of Industry 4.0. We analyzed the drawbacks of traditional warehouses and summarized four underlying technologies towards building smart warehouses, i.e., efﬁcient communication scheduling, accurate and robust localization, multi-robot coordination, and human activity recognition. Furthermore, we did a comprehensive survey for each of the technologies. Finally, we pointed out some challenging issues that may appear in CPS-based smart warehouses and the possible solutions. Acknowledgments: This work is supported by the HK RGC Collaborative Research Fund (CRF) with Project No. CityU C1008-16G and NSFC Key Grant with Project No. 61332004. Author Contributions: Jiannong Cao proposed the overall picture, the four underlying technologies, and the future directions; Xiulong Liu wrote Sections 2 and 3; Shan Jiang wrote Section 4; Yanni Yang wrote Section 5. All the authors have read and approved the ﬁnal manuscript. Conﬂicts of Interest: The authors declare no conﬂict of interest. References 1. Jabbar, S.; Khan, M.; Silva, B.N.; Han, K. A REST-based industrial web of things’ framework for smart warehousing. J. Supercomput. 2016, 1–15, doi:10.1007/s11227-016-1937-y. 2. Lee, J.; Bagheri, B.; Kao, H. A cyber-physical systems architecture for industry 4.0-based manufacturing systems. Manuf. Lett. 2015, 3, 18–23. 3. Gomez, C.; Oller, J.; Paradells, J. Overview and Evaluation of Bluetooth Low Energy: An Emerging Low-Power Wireless Technology. Sensors 2012, 12, 11734–11753. 4. Liu, X.; Xie, X.; Wang, K.; Qi, H.; Cao, J.; Guo, S.; Li, K. Pinpointing Anomaly RFID Tags: Situation and Opportunities. IEEE Netw. 2017, 31, 40–47. 5. Liu, X.; Li, K.; Min, G.; Shen, Y.; Liu, A.X.; Qu, W. Completely Pinpointing the Missing RFID Tags in a Time-Efﬁcient Way. IEEE Trans. Comput. 2015, 64, 87–96. 6. Liu, X.; Li, K.; Min, G.; Shen, Y.; Liu, A.X.; Qu, W. A Multiple Hashing Approach to Complete Identiﬁcation of Missing RFID Tags. IEEE Trans. Commun. 2014, 62, 1046–1057. 7. Liu, X.; Zhang, S.; Bu, K.; Xiao, B. Complete and fast unknown tag identiﬁcation in large RFID systems. In Proceedings of the 2012 IEEE 9th International Conference on Mobile Adhoc and Sensor Systems (MASS), Las Vegas, NV, USA, 8–11 October 2012; pp. 47–55. 8. Liu, X.; Qi, H.; Li, K.; Stojmenovic, I.; Liu, A.X.; Shen, Y.; Qu, W.; Xue, W. Sampling Bloom Filter-Based Detection of Unknown RFID Tags. IEEE Trans. Commun. 2015, 63, 1432–1442. 9. Liu, X.; Li, K.; Min, G.; Lin, K.; Xiao, B.; Shen, Y.; Qu, W. Efﬁcient Unknown Tag Identiﬁcation Protocols in Large-Scale RFID Systems. IEEE Trans. Parallel Distrib. Syst. 2014, 25, 3145–3155. 10. Kodialam, M.S.; Nandagopal, T. Fast and reliable estimation schemes in RFID systems. In Proceedings of the 12th Annual International Conference on Mobile Computing and Networking, Los Angeles, CA, USA, 23–29 September 2006; pp. 322–333. 11. Shahzad, M.; Liu, A.X. Fast and Accurate Estimation of RFID Tags. IEEE/ACM Trans. Netw. 2015, 23, 241–254. 12. Li, T.; Wu, S.S.; Chen, S.; Yang, M.C.K. Energy Efﬁcient Algorithms for the RFID Estimation Problem. In Proceedings of the 2010 IEEE INFOCOM, San Diego, CA, USA, 14–19 March 2010; pp. 1019–1027. 13. Zheng, Y.; Li, M. PET: Probabilistic Estimating Tree for Large-Scale RFID Estimation. IEEE Trans. Mob. Comput. 2012, 11, 1763–1774. 14. Xiao, Q.; Xiao, B.; Chen, S. Differential estimation in dynamic RFID systems. In Proceedings of the 2013 IEEE INFOCOM, Turin, Italy, 14–19 April 2013; pp. 295–299. 15. Gong, W.; Liu, K.; Miao, X.; Ma, Q.; Yang, Z.; Liu, Y. Informative counting: Fine-grained batch authentication for large-scale RFID systems. In Proceedings of the Fourteenth ACM International Symposium on Mobile Ad Hoc Networking and Computing, Bangalore, India, 29 July–1 August 2013; pp. 21–30. Computers 2018, 7, 13 14 of 17 16. Liu, X.; Xiao, B.; Li, K.; Wu, J.; Liu, A.X.; Qi, H.; Xie, X. RFID cardinality estimation with blocker tags. In Proceedings of the 2015 IEEE Conference on Computer Communications (INFOCOM), Hong Kong, China, 26 April–1 May 2015; pp. 1679–1687. 17. Liu, X.; Xiao, B.; Li, K.; Liu, A.X.; Wu, J.; Xie, X.; Qi, H. RFID Estimation With Blocker Tags. IEEE/ACM Trans. Netw. 2017, 25, 224–237. 18. Liu, X.; Li, K.; Liu, A.X.; Guo, S.; Shahzad, M.; Wang, A.L.; Wu, J. Multi-Category RFID Estimation. IEEE/ACM Trans. Netw. 2017, 25, 264–277. 19. Ni, L.M.; Liu, Y.; Lau, Y.C.; Patil, A.P. LANDMARC: Indoor Location Sensing Using Active RFID. Wirel. Netw. 2004, 10, 701–710. 20. Shangguan, L.; Yang, Z.; Liu, A.X.; Zhou, Z.; Liu, Y. Relative Localization of RFID Tags using Spatial-Temporal Phase Proﬁling. In Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI’15), Oakland, CA, USA, 4–6 May 2015; pp. 251–263. 21. Azzouzi, S.; Cremer, M.; Dettmar, U.; Kronberger, R.; Knie, T. New Measurement Results for the Localization of UHF RFID Transponders Using an Angle of Arrival (AoA) Approach. In Proceedings of the IEEE International Conference on RFID, Orlando, FL, USA, 12–14 April 2011; pp. 91–97. 22. Wang, J.; Katabi, D. Dude, where’s my card? RFID positioning that works with multipath and non-line of sight. In Proceedings of the ACM SIGCOMM 2013, Hong Kong, China, 12–16 August 2013; pp. 51–62. 23. Yang, L.; Chen, Y.; Li, X.; Xiao, C.; Li, M.; Liu, Y. Tagoram: Real-time tracking of mobile RFID tags to high precision using COTS devices. In Proceedings of the 20th Annual International Conference on Mobile Computing and Networking, Maui, HI, USA, 7–11 September 2014; pp. 237–248. 24. Liu, T.; Yang, L.; Lin, Q.; Guo, Y.; Liu, Y. Anchor-free backscatter positioning for RFID tags with high accuracy. In Proceedings of the IEEE INFOCOM, Toronto, ON, Canada, 27 April–2 May 2014; pp. 379–387. 25. Liu, J.; Zhu, F.; Wang, Y.; Wang, X.; Pan, Q.; Chen, L. RF-scanner: Shelf scanning with robot-assisted RFID systems. In Proceedings of the IEEE INFOCOM, Atlanta, GA, USA, 1–4 May 2017; pp. 1–9. 26. Jiang, S.; Cao, J.; Liu, Y.; Chen, J.; Liu, X. Programming Large-Scale Multi-Robot System with Timing Constraints. In Proceedings of the 25th International Conference on Computer Communication and Networks (ICCCN), Waikoloa, HI, USA, 1–4 August 2016; pp. 1–9. 27. Garey, M.R.; Johnson, D.S. Computers and Intractability: A Guide to the Theory of NP-Completeness; W.H. Freeman and Company: San Francisco, CA, USA, 1979, ISBN 0-7167-1044-7. 28. Liu, L.; Shell, D.A. Optimal Market-based Multi-Robot Task Allocation via Strategic Pricing. In Proceedings of the Robotics: Science and Systems, Berlin, Germany, 24–28 June 2013. 29. Schneider, E.; Balas, O.; Ozgelen, A.T.; Sklar, E.I.; Parsons, S. An empirical evaluation of auction-based task allocation in multi-robot teams. In Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems, Paris, France, 5–9 May 2014; pp. 1443–1444. 30. Yi, X.; Zhu, A.; Yang, S.X.; Luo, C. A Bio-Inspired Approach to Task Assignment of Swarm Robots in 3-D Dynamic Environments. IEEE Trans. Cybern. 2017, 47, 974–983. 31. Sarker, M.O.F.; Dahl, T.S.; Arcaute, E.; Christensen, K. Local interactions over global broadcasts for improved task allocation in self-organized multi-robot systems. Robot. Auton. Syst. 2014, 62, 1453–1462. 32. Gombolay, M.C.; Wilcox, R.; Shah, J.A. Fast Scheduling of Multi-Robot Teams with Temporospatial Constraints. In Proceedings of the Robotics: Science and Systems IX, Berlin, Germany, 24 June–28 June 2013. 33. Riccio, F.; Borzi, E.; Gemignani, G.; Nardi, D. Multi-robot search for a moving target: Integrating world modeling, task assignment and context. In Proceedings of the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea, 9–14 October 2016; pp. 1879–1886. 34. Farinelli, A.; Iocchi, L.; Nardi, D. Distributed on-line dynamic task assignment for multi-robot patrolling. Auton. Robot. 2017, 41, 1321–1345. 35. Oh, H.; Shirazi, A.R.; Sun, C.; Jin, Y. Bio-inspired self-organising multi-robot pattern formation: A review. Robot. Auton. Syst. 2017, 91, 83–100. 36. Singh, A.K.; Dziurzanski, P.; Mendis, H.R.; Indrusiak, L.S. A Survey and Comparative Study of Hard and Soft Real-Time Dynamic Resource Allocation Strategies for Multi-/Many-Core Systems. ACM Comput. Surv. 2017, 50, 24. 37. Nägeli, T.; Alonso-Mora, J.; Domahidi, A.; Rus, D.; Hilliges, O. Real-Time Motion Planning for Aerial Videography With Real-Time With Dynamic Obstacle Avoidance and Viewpoint Optimization. IEEE Robot. Autom. Lett. 2017, 2, 1696–1703. Computers 2018, 7, 13 15 of 17 38. Flocchini, P.; Prencipe, G.; Santoro, N. Distributed Computing by Oblivious Mobile Robots. In Synthesis Lectures on Distributed Computing Theory; Morgan & Claypool Publishers: San Rafael, CA, USA, 2012. 39. Bhagat, S.; Chaudhuri, S.G.; Mukhopadhyaya, K. Fault-tolerant gathering of asynchronous oblivious mobile robots under one-axis agreement. J. Discret. Algorithms 2016, 36, 50–62. 40. Fujinaga, N.; Yamauchi, Y.; Ono, H.; Kijima, S.; Yamashita, M. Pattern Formation by Oblivious Asynchronous Mobile Robots. SIAM J. Comput. 2015, 44, 740–785. 41. Canepa, D.; Défago, X.; Izumi, T.; Potop-Butucaru, M. Flocking with Oblivious Robots. In Proceedings of the 8th International Symposium, SSS 2016, Lyon, France, 7–10 November 2016; pp. 94–108. 42. Di Stefano, G.; Navarra, A. Gathering of oblivious robots on inﬁnite grids with minimum traveled distance. Inf. Comput. 2017, 254, 377–391. 43. D’Angelo, G.; di Stefano, G.; Klasing, R.; Navarra, A. Gathering of robots on anonymous grids and trees without multiplicity detection. Theor. Comput. Sci. 2016, 610, 158–168. 44. Datta, S.; Dutta, A.; Chaudhuri, S.G.; Mukhopadhyaya, K. Circle Formation by Asynchronous Transparent Fat Robots. In Proceedings of the 9th International Conference, ICDCIT 2013, Bhubaneswar, India, 5–8 February 2013; pp. 195–207. 45. Flocchini, P.; Prencipe, G.; Santoro, N.; Viglietta, G. Distributed computing by mobile robots: Uniform circle formation. Distrib. Comput. 2017, 30, 413–457. 46. Jiang, S.; Cao, J.; Wang, J.; Stojmenovic, M.; Bourgeois, J. Uniform Circle Formation by Asynchronous Robots: A Fully-Distributed Approach. In Proceedings of the 2017 26th International Conference on Computer Communication and Networks (ICCCN), Vancouver, BC, Canada, 31 July–3 August 2017; pp. 1–9. 47. Das, S.; Flocchini, P.; Santoro, N.; Yamashita, M. Forming sequences of geometric patterns with oblivious mobile robots. Distrib. Comput. 2015, 28, 131–145. 48. Yamauchi, Y.; Yamashita, M. Randomized Pattern Formation Algorithm for Asynchronous Oblivious Mobile Robots. In Proceedings of the 28th International Symposium, DISC 2014, Austin, TX, USA, 12–15 October 2014; pp. 137–151. 49. Gervasi, V.; Prencipe, G. Coordination without communication: The case of the ﬂocking problem. Discret. Appl. Math. 2004, 144, 324–344. 50. Canepa, D.; Potop-Butucaru, M.G. Stabilizing Flocking via Leader Election in Robot Networks. In Proceedings of the 9th International Symposium (SSS 2007), Paris, France, 14–16 November 2007; pp. 52–66. 51. Cucchiara, R.; Grana, C.; Piccardi, M.; Prati, A. Detecting Moving Objects, Ghosts, Shadows in Video Streams. IEEE Trans. Pattern Anal. Mach. Intell. 2003, 25, 1337–1342. 52. Seki, M.; Fujiwara, H.; Sumi, K. A robust background subtraction method for changing background. In Proceedings of the Fifth IEEE Workshop on Applications of Computer Vision, Palm Springs, CA, USA, 4–6 December 2000; pp. 207–213. 53. Ke, Y.; Sukthankar, R.; Hebert, M. Spatio-temporal Shape and Flow Correlation for Action Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Minneapolis, MN, USA, 17–22 June 2007. 54. Shechtman, E.; Irani, M. Space-Time Behavior Based Correlation. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, San Diego, CA, USA, 20–25 June 2005; pp. 405–412. 55. Kumari, S.; Mitra, S.K. Human action recognition using DFT. In Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG), Hubli, India, 15–17 December 2011; pp. 239–242. 56. Sedai, S.; Bennamoun, M.; Huynh, D.Q. Context-Based Appearance Descriptor for 3D Human Pose Estimation from Monocular Images. In Proceedings of the Digital Image Computing: Techniques and Applications, Melbourne, Australia, 1–3 December 2009; pp. 484–491. 57. Dargazany, A.; Nicolescu, M. Human Body Parts Tracking Using Torso Tracking: Applications to Activity Recognition. In Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), Las Vegas, NV, USA, 16–18 April 2012; pp. 646–651. 58. Lee, M.W.; Nevatia, R. Human Pose Tracking in Monocular Sequence Using Multilevel Structured Models. IEEE Trans. Pattern Anal. Mach. Intell. 2009, 31, 27–38. Computers 2018, 7, 13 16 of 17 59. Sempena, S.; Maulidevi, N.U.; Aryan, P.R. Human action recognition using Dynamic Time Warping. In Proceedings of the 2011 International Conference on Electrical Engineering and Informatics (ICEEI), Bandung, Indonesia, 17–19 July 2011; pp. 1–5. 60. Thuc, H.L.; Ke, S.; Hwang, J.; van Tuan, P.; Chau, T.N. Quasi-periodic action recognition from monocular videos via 3D human models and cyclic HMMs. In Proceedings of the 2012 International Conference on Advanced Technologies for Communications (ATC), Hanoi, Vietnam, 10–12 October 2012; pp. 110–113. 61. Du, Y.; Wang, W.; Wang, L. Hierarchical recurrent neural network for skeleton based action recognition. In Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA, 7–12 June 2015; pp. 1110–1118. 62. Chéron, G.; Laptev, I.; Schmid, C. P-CNN: Pose-Based CNN Features for Action Recognition. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), Santiago, Chile, 7–13 December 2015; pp. 3218–3226. 63. Iglesias, J.; Cano, J.; Bernardos, A.M.; Casar, J.R. A ubiquitous activity-monitor to prevent sedentariness. In Proceedings of the 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), Seattle, WA, USA, 21–25 March 2011; pp. 319–321. 64. Pärkkä, J.; Ermes, M.; Korpipää, P.; Mäntyjärvi, J.; Peltola, J.; Korhonen, I. Activity Classiﬁcation Using Realistic Data From Wearable Sensors. IEEE Trans. Inf. Technol. Biomed. 2006, 10, 119–128. 65. Jatoba, L.C.; Grossmann, U.; Kunze, C.; Ottenbacher, J.; Stork, W. Context-aware mobile health monitoring: Evaluation of different pattern recognition methods for classiﬁcation of physical activity. In Proceedings of the 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vancouver, BC, Canada, 20–25 August 2008; pp. 5250–5253. 66. Zhou, B.; Lapedriza, À.; Xiao, J.; Torralba, A.; Oliva, A. Learning Deep Features for Scene Recognition using Places Database. In Proceedings of the 27th International Conference on Neural Information Processing Systems, Montreal, QC, Canada, 8–13 December 2014; pp. 487–495. 67. Wang, Y.; Liu, J.; Chen, Y.; Gruteser, M.; Yang, J.; Liu, H. E-eyes: Device-free location-oriented activity identiﬁcation using ﬁne-grained WiFi signatures. In Proceedings of the 20th Annual International Conference on Mobile Computing and Networking, Maui, HI, USA, 7–11 September 2014; pp. 617–628. 68. Wang, Y.; Wu, K.; Ni, L.M. WiFall: Device-Free Fall Detection by Wireless Networks. IEEE Trans. Mob. Comput. 2017, 16, 581–594. 69. Liu, X.; Cao, J.; Tang, S.; Wen, J. Wi-Sleep: Contactless Sleep Monitoring via WiFi Signals. In Proceedings of the 35th Real-Time Systems Symposium, Rome, Italy, 2–5 December 2014; pp. 346–355. 70. Hong, F.; Wang, X.; Yang, Y.; Zong, Y.; Zhang, Y.; Guo, Z. WFID: Passive Device-free Human Identiﬁcation Using WiFi Signal. In Proceedings of the 13th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, Chennai, India, 28 November–1 December 2016; pp. 47–56. 71. Shi, C.; Liu, J.; Liu, H.; Chen, Y. Smart User Authentication through Actuation of Daily Activities Leveraging WiFi-enabled IoT. In Proceedings of the 18th ACM International Symposium on Mobile Ad Hoc Networking and Computing, Chennai, India, 10–14 July 2017; pp. 5:1–5:10. 72. Li, X.; Li, S.; Zhang, D.; Xiong, J.; Wang, Y.; Mei, H. Dynamic-MUSIC: Accurate device-free indoor localization. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, Heidelberg, Germany, 12–16 September 2016; pp. 196–207. 73. Wang, W.; Liu, A.X.; Shahzad, M.; Ling, K.; Lu, S. Understanding and Modeling of WiFi Signal Based Human Activity Recognition. In Proceedings of the 21st Annual International Conference on Mobile Computing and Networking, Paris, France, 7–11 September 2015; pp. 65–76. 74. Wang, H.; Zhang, D.; Ma, J.; Wang, Y.; Wang, Y.; Wu, D.; Gu, T.; Xie, B. Human respiration detection with commodity wiﬁ devices: Do user location and body orientation matter? In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, Heidelberg, Germany, 12–16 September 2016; pp. 25–36. 75. Satoshi, N. Bitcoin: A Peer-to-Peer Electronic Cash System. 2008. Available online: https://bitcoin.org/ bitcoin.pdf (accessed on 30 January 2018). 76. Lei, A.; Cruickshank, H.S.; Cao, Y.; Asuquo, P.M.; Ogah, C.P.A.; Sun, Z. Blockchain-Based Dynamic Key Management for Heterogeneous Intelligent Transportation Systems. IEEE Internet Things J. 2017, 4, 1832–1843. Computers 2018, 7, 13 17 of 17 77. Hou, H. The Application of Blockchain Technology in E-Government in China. In Proceedings of the 26th International Conference on Computer Communication and Networks (ICCCN), Vancouver, BC, Canada, 31 July–3 August 2017; pp. 1–4. 78. Turkanovic, M.; Hölbl, M.; Kosic, K.; Hericko, M.; Kamisalic, A. EduCTX: A blockchain-based higher education credit platform. IEEE Access 2018, doi:10.1109/ACCESS.2018.2789929. 79. Sciortino, R.; Micale, R.; Enea, M.; La Scalia, G. A webGIS-based system for real time shelf life prediction. Comput. Electron. Agric. 2016, 127, 451–459. 80. Kober, J.; Bagnell, J.A.; Peter, P. Reinforcement learning in robotics: A survey. Int. J. Robot. Res. 2013, 32, 1238–1274. c⃝ 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","libVersion":"0.3.2","langs":""}