{"path":"_aula_virtual/SJK001/Reading Assessments/[Floreano15] autonomous drones.pdf","text":"1Laboratory of Intelligent Systems, Ecole Polytechnique Fédérale de Lausanne, Station 11, Lausanne, CH 1015, Switzerland. 2Microrobotics Lab, Harvard University, 149 Maxwell Dworkin Building, Cambridge, Massachusetts 02138, USA. D rones, a popular nickname for unmanned aerial vehicles and micro aerial vehicles, often conjure up images of unmanned aer- oplanes that fly thousands of miles for espionage and to deploy munitions. However, over the past few years, an increasing number of public and private research laboratories have been working on small, human-friendly drones that one day may autonomously fly in confined spaces and in close proximity to people. The development of these small drones, which is the main focus of this Review, has been supported by the miniaturization and cost reduction of electronic components (micro- processors, sensors, batteries and wireless communication units), largely driven by the portable electronic device industry. These improvements have enabled the prototyping and commercialization of small (typically less than 1 kg) drones at smartphone prices. Small drones will have important socio-economic impacts (Fig. 1). Images from drones that are capable of flying a few metres above the ground will fill a gap between expensive, weather-dependent and low- resolution images provided by satellites and car-based images limited to human-level perspectives and the availability of accessible roads. Special- ized flying cameras and cloud-based data analytics will allow farmers to continuously monitor the quality of crop growth. Such platforms will enable construction companies to measure work progress in real time. Drones will let mining companies obtain precise volumetric data of exca- vations. Energy and infrastructure companies will be able to exhaustively survey pipelines, roads and cables. Humanitarian organizations could immediately assess and adapt aid efforts in continuously changing refugee camps. Transportation drones that are capable of safely taking off and landing in the proximity of buildings and humans will allow developing countries — without a suitable road network — to rapidly deliver goods and to finally unleash the full potential of their e-commerce telecommu- nication infrastructure. Transportation drones will also help developed countries to improve the quality of service in congested or remote areas, and will enable rescue organizations to quickly deliver medical supplies in the field and on demand. Inspection drones that are capable of flying in confined spaces will help fire-fighting and emergency units to assess dan- gers faster and more safely, logistic companies to detect cracks in the inner and outer shells of ships, road maintenance companies to measure signs of wear and tear in bridges and tunnels, security companies to improve building safety by monitoring areas outside the range of surveillance cameras, and disaster mitigation agencies to inspect partially collapsed buildings where ground clutter is an obstacle for terrestrial robots. Coor- dinated teams of autonomous drones will enable missions that last longer than the flight time of a single drone by allowing some drones to tempo- rarily leave the team for battery replacement. Drone teams will permit res- cue organizations to quickly deploy dedicated communication networks for ground operators. Telecommunication companies can also leverage drone networks to temporarily supplement or replace points of service. Realizing this vision will require new mechatronic solutions and new levels of control autonomy (Box 1) to safely complete missions in con- fined spaces and near the ground, where absolute positioning signals and remote control are not available or sufficiently precise. None of today’s commercial drones has sufficient control autonomy to complete any of the missions described without skilled human supervision, which makes those operations slow, dangerous and not scalable. We identify the most promising scientific and technological advances that could lead to a new generation of small autonomous drones and offer a tentative road map of capability deployment within suitable regulatory frameworks. Design and manufacturing challenges Flight is energetically expensive, particularly when the size of the device is reduced. This is often due to practical issues that arise when scal- ing a vehicle down, such as reduced power density of electromagnetic motors, decreased transmission efficiency owing to increased domi- nance of friction from gears and bearings, and greater viscous losses because of reduced Reynolds numbers. Certain flight modes are also challenging — for example, hovering — either owing to energetics or control; these also become increasingly difficult as size is reduced. Scaling issues create problems at the most basic level of autonomy: they limit the ability to simply sustain flight for an adequate amount of time to perform higher-level mission functions. To overcome these challenges, developers of drones must consider system-level design choices that balance trade- offs that arise when selecting the constituent components to power the vehicle. The most common morphologies for flying robots include more conventional fixed-wing and rotary-wing aircraft (rotorcraft) designs as well as bio-inspired designs based on flapping wings. Each of these plat- form types has pros and cons. For example, fixed-wing aircraft (Fig. 2a) are capable of fast and efficient flight, but typically cannot hover. Rotorcraft (Fig. 2b) can hover and are highly manoeuvrable, but are generally less efficient in forward flight than fixed-wing vehicles. Neither fixed-wing We are witnessing the advent of a new era of robots — drones — that can autonomously fly in natural and man-made environments. These robots, often associated with defence applications, could have a major impact on civilian tasks, including transportation, communication, agriculture, disaster mitigation and environment preservation. Autonomous flight in confined spaces presents great scientific and technical challenges owing to the energetic cost of staying airborne and to the perceptual intelligence required to negotiate complex environments. We identify scientific and technological advances that are expected to translate, within appropriate regulatory frameworks, into pervasive use of autonomous drones for civilian applications. Science, technology and the future of small autonomous drones Dario Floreano 1 & Robert J. Wood 2 460 | N A T U R E | V O L 521 | 28 M A Y 2015 REVIEW doi:10.1038/nature14542 © 2015 Macmillan Publishers Limited. All rights reserved craft nor rotorcraft scale down well — both in terms of the aerodynamics that govern flight and in the performance of the components that are nec- essary to generate propulsion. Bio-inspired flapping-wing flight (Fig. 2c) offers an alternative paradigm that can be scaled down in size, but brings fluid-mechanics-modelling and control challenges. Propulsion and manoeuvrability considerations Small-scale aerial vehicles are predominantly fixed-wing propeller-driven aircraft or rotorcraft. The latter can be further broken down into con- ventional primary and tail rotor configurations, coaxial dual rotors 1, or quadcopter designs, which have recently become popular. For each of these configurations, and for propeller-driven aircraft at larger scales, there have been only small incremental improvements to propeller design over the past several decades, since the advent of standards and tools to generate airfoil shapes by the National Advisory Committee for Aeronaut- ics 2. Propulsive efficiencies for rotorcraft degrade as the vehicle size is reduced; an indicator of the energetic challenges for flight at small scales. Smaller size typically implies lower Reynolds numbers, which in turn suggests an increased dominance of viscous forces, causing greater drag coefficients and reduced lift coefficients compared with larger aircraft. To put this into perspective, this means that a scaled-down fixed-wing aircraft would be subject to a lower lift-to-drag ratio and thereby require greater relative forward velocity to maintain flight, with the associated drag and power penalty reducing the overall energetic efficiency. The impacts of scaling challenges (Fig. 3) are that smaller drones have less endurance, and that the overall flight times range from tens of seconds to tens of minutes — unfavourable compared with human-scale vehicles. There are, however, manoeuvrability benefits that arise from decreased vehicle size. For example, the moment of inertia is a strong function of the vehicle’s characteristic dimension — a measure of a critical length of the vehicle, such as the chord length of a wing or length of a propeller in a similar manner as used in Reynolds number scaling. Because the moment of inertia of the vehicle scales with the characteristic dimension, L, raised to the fifth power, a decrease in size from a 11 m wingspan, four- seat aircraft such as the Cessna 172 to a 0.05 m rotor-to-rotor separation Blade Pico QX quadcopter implies that the Cessna has about 5 × 10 11 the inertia of the quadcopter (with respect to roll). Depending on the scaling law used for torque generated by the quadcopter, this leads to angular acceleration that scales either by L −1 or L −2, both cases indicating that the quadcopter will be much more manoeuvrable 3. This has resulted in remarkable demonstrations of aerobatic manoeuvres in rooms equipped with real-time tracking and control by external computers, including fly- ing through windows at high speeds 4 and manipulating objects in flight 5. This enhanced agility, often achieved at the expense of open-loop stability, requires increased emphasis on control — a challenge also exacerbated by the size, weight and power constraints of these small vehicles. Imple- menting these behaviours in autonomous drones (with on-board sensing and computation) is a significant challenge, but one that is beginning to have promising results 6,7 — even for aggressive flight manoeuvres. The challenges for further scaling down these sensing and control systems are discussed in the final section of this Review. Actuation, power and manufacturing Beyond autonomy considerations, the size and type of the flying robot also engender associated challenges with actuation and manufacturing. For actuation, rotorcraft and propeller-driven fixed-wing drones gener- ally use electromagnetic motors. Some flapping-wing aircraft 8,9 also use electromagnetic motors, but require a linkage mechanism to convert the rotary motion of the motor to the flapping motion of the wings. However, as the scale is reduced, conventional motors become inefficient, require substantial gearing to achieve a desired wing or propeller velocity, and are extremely difficult to manufacture. Therefore, for vehicles below a few grams, alternative methods of actuation are required. Similarly, ‘macro size’ flying robots (tens to hundreds of grams and larger) may be con- structed using conventional methods such as additive and subtractive machining and ‘nuts-and-bolts’ assembly. However, for ‘micro size’ fly- ing robots (less than a few grams), manufacturing needs to be rethought and novel methods applied. To give a perspective on the challenges for actuation, we need to consider how the physics of scaling 10 affects the performance of electromagnetic motors. At macroscopic scales, motors used in electric cars can achieve an efficiency of nearly 90% with a power density of several kilowatts per kilogram whereas at millimetre scales, existing motors produce a few tens of watts per kilogram of power at less than 50% efficiency 11. This reduction in performance and the energetic expense of flight at small scales means that both power source and power distribution are important considerations 12. For vehicles for which the pri- mary propulsion system is also responsible for generating control torques, this does not apply (for example, quadcopters). However, for fixed-wing aircraft and some flapping-wing vehicles, it is essential that most of the power budget must be allocated to staying aloft with a proportionately smaller power for actuating control surfaces. For example, nearly 90% of the power budget of the RoboBee (Fig. 2c) is dedicated to the primary power actuators that generate lift to stay in the air 13. As already discussed, for power actuators, the typical choice is electromagnetic motors. There are alternatives, including electroactive materials such as piezoelectric actuators 14 or ultrasonic motors 15, however, these are most appropriate for the smaller end of the size spectrum. Control actuators have more options at most scales, including voice coils, shape memory alloys 16 and electroactive polymers 17. Given the challenges for small-scale propulsion, an unsteady approach to force production is potentially a viable option for small vehicles. Unlike fixed-wing aircraft and rotorcraft that produce lift and thrust in a quasi-steady way (either directly in the case of rotorcraft or indirectly by the movement of air over the wings of a fixed-wing drone), the aerodynamics of flapping-wing drones is complex and involves the generation and manipulation of vortical structures in the air18. As is obvious from its existence in nature, flapping-wing pro- pulsion is an effective form of locomotion, but translating this into a b c d e Figure 1 | Autonomous drones in rescue situations. a, Fixed-wing drones with a long flight time could provide bird’s-eye-view images and a communication network for rescuers on the ground. b, Rotorcrafts with hovering capabilities could inspect structures for cracks and leaks; and c, transport medical supplies from nearby hospitals. d, Swarms of dispensable drones with flapping wings could enter buildings to search for chemical hazards. e, Multi-modal caged robots could fly and roll into complex structures to safely search for signs of life. 28 M A Y 2015 | V O L 521 | N A T U R E | 461 REVIEW INSIGHT © 2015 Macmillan Publishers Limited. All rights reserved functional designs is not a trivial exercise given the morphological diversity of the flight apparatus of insects, bats and birds. Nonetheless, drone researchers have effectively reproduced natural flight in many different ways. Examples include robotic insects such as RoboBee19 and the four-winged DelFly8, and bird-sized drones such as the Nano Hummingbird 9 (Fig. 2c). As size is reduced, in addition to the challenges for actuator selection and manufacturing, there are also considerations of how to manufacture the entire vehicle. At scales for which electromagnetic actuation and bearing-based rotary joints are feasible, more conventional manufactur- ing methods are used, such as subtractive machining, additive printing and moulding of composite materials. At small scales — for example, for aircraft of comparable size to insects and small birds — some of these techniques fail, typically owing to limited resolution. Alternative meth- ods have been developed; for example, those based on folding (an inher- ently scalable technique) have been used to create insect-sized robots, avoiding the challenges that are inherent to macro-scale nuts-and-bolts approaches 20. Multi-modal drones In many situations, such as search and rescue, parcel delivery in con- fined spaces and environmental monitoring, it may be advantageous to combine aerial and terrestrial capabilities. Perching mechanisms could allow drones to land on walls 21 and power lines 22 in order to monitor the environment from a high vantage point while saving energy. Agile drones could move on the ground by using legs in conjunction with retractable 23 or flapping wings 24. In an effort to minimize the total cost of transport 25, which will be increased by the additional locomotion mode, these future drones may benefit from using the same actuation system for flight con- trol and ground locomotion. The different speed and torque requirements of these two locomotion modes could be reconciled by adapting the wing morphology to the specific situation 26, similar to the way vampire bats (Desmodus rotundus) use their powerful front limbs when flying or walk- ing 27. Alternatively, multi-modal locomotion could be obtained by adding large wheels to the sides of hovering drones 28, by embedding the propul- sion system in a rolling cage 29, or by completely decoupling the spherical cage from the inner rotors by means of a gimbal system 30 (Fig. 2b); the lat- ter design allows the drone not only to roll on the ground in any direction, but, because the rotors are protected by a cage, also to safely collide with obstacles or humans without attitude perturbations. Conversely, wings could be added to ground-based robots travelling on rough terrain to extend their jumping distances, stabilize the landing phase and reduce the impact with the ground 31. In this case as well, the total cost of transport could be reduced by sharing the same actuation system between jumping and wing-deployment mechanisms 32. Alternatively, one could use pivot- ing wings, which minimize drag at take-off, improve the transition from ballistic jump to gliding and maximize the gliding ratio 33. In the future, we may also deploy drones in semi-aquatic environments by using design principles inspired by aquatic birds, such as folding wings for plunge div- ing or hydrophobic surfaces for dry flight, or by flying squid, which use water-jet propulsion for take off 34. Sensing and control Conventional unmanned drones that fly at high altitudes regulate their attitude (roll, pitch and yaw) and their position (x, y and z) (Fig. 2d) by continuously monitoring and merging data from an inertial measurement unit (IMU), which contains three-axis accelerometers and gyroscopes, and from a global positioning system (GPS). This technology, which is necessary for sensory-motor autonomy, is now also available in small drones for recreational or professional use. However, GPS information is not sufficiently precise for altitude regulation when flying a few metres above the ground and is not always available or reliable in confined areas, such as cities, forests and buildings. Even if reliable GPS information were available, it would need to be combined with a precise map of the drone’s surroundings in order to identify obstacle-free trajectories. However, digital maps, such as those used in car navigation systems, are restricted to traversable roads, do not include three-dimensional information (the height of natural structures, buildings, and bridges, and the presence of cables, poles, and so on) and are not refreshed frequently enough to cap- ture landscape modification. Therefore, small autonomous drones flying at low altitude will need more complex levels of control autonomy and additional sensors to detect distances from the surrounding environment and perform safe and stable trajectories. Vision is a promising sensor modality for small drones because compared with other distance sensors such as sonar, infrared and laser range finders used in terrestrial vehicles, it does not require energy to interrogate the environment, and for compa- rable mass it can gather richer information and span wider fields of view. Reactive autonomy Most efforts in small autonomous drones have focused on achieving reac- tive autonomy (Box 1) by translating decades worth of neuroethological research on vision-based insect flight into simple control algorithms and lightweight sensors 35, with many also serving as validation of biological models. Insect vision relies on compound eyes, which are dense arrays of facets pointing in different directions and spanning large fields of view 36. According to the definition by the International Organization for Standardization, robot autonomy is the ability to perform intended tasks based on current state and sensing, without human intervention 98. This definition encompasses a wide range of situations, which demand different levels of autonomy depending on the type of robot and the intended use. For example, although autonomy in tethered robots does not concern energy management, mobile robots with long-range travel may require the capability to decide when to abort the current mission and locate a recharging station. In the case of the small drones discussed here, we can identify three levels of increasing autonomy (Table 1). ●● Sensory-motor autonomy: translate high-level human commands (such as to reach a given altitude, perform circular trajectory, move to global positioning system (GPS) coordinates or maintain position) into combinations of platform-dependent control signals (such as pitch, roll, yaw angles or speed); follow pre-programmed trajectory using GPS waypoints. ●● Reactive autonomy (requires sensory-motor autonomy): maintain current position or trajectory in the presence of external perturbations, such as wind or electro-mechanical failure; avoid obstacles; maintain a safe or predefined distance from ground; coordinate with moving objects, including other drones; take off and land. ●● Cognitive autonomy (requires reactive autonomy): perform simultaneous localization and mapping; resolve conflicting information; plan (for battery recharge for example); recognize objects or persons; learn. BOX 1 Control autonomy Table 1 | Levels of autonomy: requirements, availability and readiness for market Exteroceptive sensors Computational load Supervision required Readiness level Validated on drone type Sensory- motor autonomy None or few Little Yes Deployed All types Reactive autonomy Few and sparse Medium Little Partly deployed Fixed wing, rotorcraft and flapping wing Cognitive autonomy Several and high density High None Not yet deployed Mostly rotorcraft 462 | N A T U R E | V O L 521 | 28 M A Y 2015 REVIEWINSIGHT © 2015 Macmillan Publishers Limited. All rights reserved Compound eyes have fixed focus, lower resolution and smaller binocular overlap than human eyes and therefore do not use stereo vision for dis- tance estimation, except for very short ranges 37. To safely fly in cluttered environments, insects instead rely on image motion, also known as optic flow 38,39, generated by their own displacement relative to the surround- ings 40. It has been experimentally shown that their neural system reacts to optic flow patterns 41,42 to produce a large variety of flight capabilities, such as obstacle avoidance 40,43, speed maintenance 44, odometry estimation 45, wall following and corridor centring 46, altitude regulation 47,48, orientation control 49 and landing 50,51. Optic flow intensity is proportional to the dis- tance from objects only during translational movements, but not during rotational movements when it is proportional to the rotational veloc- ity of the agent. Furthermore, optic flow intensities also depend on the speed-to-distance ratio, which raises the issue of how insects can estimate ground speed and distance from obstacles at the same time 52. Many vision-based insect capabilities have been replicated with small drones. For example, it has been shown that small fixed-wing drones 53 and helicopters 54 can regulate their distance from the ground using ventral optic flow while a GPS was used to maintain constant speed and an IMU was used to regulate roll angle. The addition of lateral optic flow sensors also allowed a fixed-wing drone to detect near-ground obstacles 55. Optic flow has also been used to perform both collision-free navigation and altitude control of indoor 56 and outdoor 57 fixed-wing drones without a GPS. In these drones, the roll angle was regulated by optic flow in the horizontal direction and the pitch angle was regulated by optic flow in the vertical direction, while the ground speed was measured and main- tained by wind-speed sensors. In this case, the rotational optic flow was minimized by flying along straight lines interrupted by short turns or was estimated with on-board gyroscopes and subtracted from the total optic flow, as suggested by biological models 58,59. Other authors have even proposed bio-inspired control methods that do not require absolute speed measurement with dedicated sensors, thus eliminating a potential source of error. These methods consist of continuously adjusting flight speed and altitude to maintain constant optic flow signals, which has also been sug- gested by biological models 60. For example, altitude control and landing was achieved by adding negative feedback from ventral optic flow, either to the control surfaces that regulate pitch angle 53 or to those that regulate thrust 61. The latter method has also been shown to be effective for altitude control and landing on mobile platforms 62 and, when used in conjunction with lateral optic flow and lateral thrust, also for replicating flight trajec- tories of honeybees during indoor flight 62. However, so far this method has been validated only on tethered drones. An error correction method has also been demonstrated on a quadcopter equipped with omnidirec- tional vision to fly in corridors by continuously making corrections aimed at reducing the difference between measured optic flow and optic flow expected from flight at the desired altitude, attitude, speed, heading and distance from walls 63. Quadcopter and flapping-wing drones are intrinsi- cally unstable and must compensate for positional drift generated by noise in gyroscope and accelerometer signals to hover in place and maintain attitude. It has been shown that the direction of optic flow can be used to reduce uncertainty in inertial sensor signals 64. Wide-field optical sensors inspired by the simple eyes of insects, called ocelli 65, have been used for attitude stabilization of flapping-wing drones 66 and quadcopters 67. The need to detect optic flow over wide fields of view at high temporal frequency in a small package has also driven the development of insect- inspired vision sensors that are smaller, lighter and faster than single-lens conventional cameras. For example, some authors 55–57 have resorted to using the multiple optic flow sensors found in computer optical mice. Whereas others 68,69 have developed neuromorphic chips that not only extract optic flow, but also adapt to the large variety of light intensities that can be experienced when flying in confined spaces. Similarly, specialized micro optic flow sensors have been used for altitude regulation in sub-1 g flying robots 70. Miniature, curved, artificial compound eyes with a high density of photoreceptors, wide fields of view and computational proper- ties similar to insect eyes have been recently described 71,72, but have not yet been used in drones. Coordinated flight of multiple drones is another instance of reactive autonomy, but raises it additional challenges in sensing, communication and control 73. Although very little is known about the sensing and con- trol that underlies coordinated flight in insects, it has been shown that Roll x Yaw Pitch 1 cm z y a b c d Figure 2 | Drone types with examples. a, Fixed-wing drones. A 10 g robot with rudder and flap on the tail is equipped with insect-inspired cameras to avoid obstacles and regulate altitude (left); the 690 g eBee (right) with elevons on the trailing edge of the wings, is equipped with high- resolution cameras for imaging and ventral optic flow sensor for landing. b, Rotorcraft. The 380 g AR.Drone 2.0 (left) is a quadcopter equipped with a high-resolution camera for imaging and a ventral optic flow sensor for maintaining position; the 380 g Gimball robot (right) is composed of a coaxial dual propeller core protected by a decoupled and freely rotating spherical cage. c, Flapping-wing drones. The 19 g Nano Hummingbird (left) has a camera for live video streaming; the 80 mg RoboBee (right) can fly tethered to an external power source. d, Coordinate system of a generic drone. The drone position is defined in the x, y and z coordinates and the attitude in the yaw, roll and pitch angles. The control algorithms to maintain position and attitude can vary according to drone type, configuration of the actuators and size. 28 M A Y 2015 | V O L 521 | N A T U R E | 463 REVIEW INSIGHT © 2015 Macmillan Publishers Limited. All rights reserved cohesion in flocks of starlings is the result of individual birds aligning their trajectories with a small number of their nearest neighbours defined in topological — not metric — space 74. Evidence from pigeon flocks also suggests that in some conditions, such as homing, a hierarchical organi- zation emerges whereby the trajectories of more experienced birds are tracked and copied by other birds 75. Computational models of bird flock- ing build on the combination of three simple behavioural rules, namely repulsion from near individuals, movement towards far neighbours and alignment with average velocities of neighbours 76. Remarkably, these rules can also account for hierarchical flocking without explicit signalling of experienced agents 77. However, perceiving the position of other flying drones is still very challenging. Infrared-based bidirectional communica- tion has been used for detecting the range and bearing of neighbouring drones in indoor environments 78, but the relatively short range of a few metres prevents its use in outdoor environments. Consequently, recent demonstrations of outdoor flocking of ten fixed-wing drones 79 and ten hovering drones 80 relied on radio communication of GPS coordinates between neighbouring drones. An alternative approach to perception of neighbours consists of exploiting the direction and intensity of the sound emitted by neighbouring drone engines 81, which may complement or replace visual cues at night or in foggy conditions. Cognitive autonomy A different approach is pursued to endow small drones with cognitive autonomy (Box 1). This involves leveraging decades of research in statis- tical methods for vision-based navigation of terrestrial vehicles, such as visual odometry 82,83 and simultaneous localization and mapping 84. For example, monocular vision has been successfully used for simultaneous localization and mapping of quadcopters in indoor 85 and outdoor envi- ronments 86. However, these drones could not avoid obstacles that had not been previously detected and mapped. Stereo vision can provide depth information and has been used in a 4 g flapping-wing vehicle to reac- tively avoid obstacles 87 and in larger quadcopters to perform simultaneous localization and mapping 88. Furthermore, both simultaneous localization and mapping and altitude control have been demonstrated in quadcop- ters with two sets of stereo cameras, one set pointing forwards and one set pointing downwards 89. Simultaneous localization and mapping algo- rithms have also been combined with optic flow methods to estimate distances from the surrounding environment and stabilize the drone 90. The statistical approach to cognitive autonomy builds on high-resolu- tion digital cameras that can provide dense clouds of data points and on computationally expensive algorithms for reducing uncertainties. Conse- quently, cognitive autonomy requires heavier sensory payloads and more powerful computational units, which may explain why, so far, progress has been slower for small drones. Although various forms of reactive auton- omy have been demonstrated in several types of drones with a wide range of mass and flight endurance (Fig. 3), simultaneous localization, mapping, and path planning have so far been demonstrated mostly in hovering platforms with a relatively large total mass and restricted flight endurance. Regulatory issues Unleashing the socio-economic potential of small drones will require not only translating the scientific and technological advances described above into reliable products, but also creating a regulatory framework that will enable public and private entities to operate in full respect of safety, privacy and security concerns. The rapid development of com- mercial drones and potential benefits prompted the US Federal Aviation Administration (FAA) to define, in 2013, a road map for the gradual integration in the national airspace system of civil unmanned drones that can fly beyond the operator’s line of sight by 2028 (ref. 91). In a first “accommodation” stage, which has already started, the FAA allows operation of unmanned aerial vehicles for specific services by issuing airworthiness certificates on request and by defining a set of standards and procedures. In the second “integration” stage, the FAA aims to imple- ment the standards and procedures for operation of civil unmanned aircrafts while retaining on-demand certification for cases that do not fit in the civil unmanned category, and to establish six test sites with diverse geographical and climate conditions to study safety and privacy issues. In the final “evolution” stage, the FAA aims to continuously refine and update regulations, policies and standards on the basis of evolving technological developments and experiences. The FAA has identified sense-and-avoid and communication-and-control as research priorities for full integration of unmanned drones, but for the foreseeable future it will continue to require continuous supervision by a human operator with certified training. In the European Union the legislation is more fragmented because aircraft below 150 kg are separately regulated by individual member states. Some countries, including the Czech Republic, France, Ireland, Italy, Sweden, Switzerland and the United Kingdom, have national regulations for unmanned aircraft; although these reg- ulations differ between countries. For example, the United Kingdom allows operation of drones of less than 20 kg within the line of sight over congested areas on request to the UK Civil Aviation Authority 92; France allows remotely operated aircraft to operate beyond the line of sight and near cities under specific conditions 93; and Switzerland allows autonomous operation of drones within the line of sight as long as the operator can regain control 94 if, for example, the drone loses altitude or is about to collide with something. In 2013, the European Commission defined a road map 95 for the integration of remotely operated aircraft in the European aviation system using a staged approach, the aims, timeline and research priorities of which are similar to those defined in the US road map. However, the first stage of the European road map consists of extending European regulations for large unmanned aircraft systems to those below 150 kg by adapting to national regulations, which may result in more liberal regulations than those in the United States. Furthermore, Vehicle mass (g) 100 101 102 103Flight time (min) 10–1 100 101 102 1 2 3 4 56 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 2728 Flapping wing Rotorcraft Fixed wing 1. Nano Hummingbird 2. DelFly Explorer 3. DelFly Micro 4. H2Bird 5. MicroBat 6. Bionic Bird 7. Avitron V2.0 8. 36 cm Ornithopter 9. 28 cm Ornithopter 10. 15 cm Ornithopter 11. 10 cm Ornithopter 12. Parrot Bebop drone 13. PD-100 Black Hornet PRS 14. DJI Phantom 2 15. Seiko-Epson uFR-II 16. Ladybird V2 17. Mini X6 18. 350.QX2 19. AR.Drone 2.0 20. QR Y100 21. QR W100S 22. eBee 23. Black Widow 24. Wasp III 25. Univ. Florida MAV 26. H301S 27. Diamond 600 EP 28. EPFL MC2 Figure 3 | Flight time against mass of small (less than 1 kg) drones. Examples include each of the drone types shown in Fig. 2 (fixed wing, rotary and flapping wing). Regardless of the type, there is a clear trend in how flight time scales with mass. Smaller drones have significantly reduced flight times (tens of seconds compared with tens of minutes for larger drones). This is due to actuation limitations and the physics of flight at small scales, as discussed in this Review, and brings about challenges for all levels of autonomy described in Box 1. 464 | N A T U R E | V O L 521 | 28 M A Y 2015 REVIEWINSIGHT © 2015 Macmillan Publishers Limited. All rights reserved the European Commission explicitly aims to improve the public percep- tion of drones and to promote widespread use of these technologies for public and commercial use 96. The future of small drones Scaling up the use of small drones from a niche market to widespread use in civilian applications depends on two related prerequisites: the capabil- ity to autonomously and safely manoeuvre in confined spaces and the removal of the legal requirement of supervised operation within the line of sight. We do not foresee major scientific or technological roadblocks to achieving higher levels of autonomous control in research and com- mercial drones within the next five years. However, the legal requirement of a certified human operator within the line of sight of every single drone is a roadblock that will almost certainly stay for the next five years in the United States and Europe, and removing it will depend on the reliability and safety of small drones. Assuming that the legal roadblock will gradually be lifted, we expect that reactive forms of control autonomy (Box 1) will become widely available within the next 5–10 years for small commercial drones for long-range operation. We also anticipate that bio-inspired approaches will dominate because they require relatively simple computation and sensors. For example, some commercial drones (such as the eBee and the AR.Drone 2.0 in Fig. 2) already use ventral optic flow for outdoor landing and for indoor position stabilization. In this context, an interest- ing scientific challenge will be to understand how different navigation capabilities can be integrated into a coherent control system akin to the nervous system of a flying insect. In parallel, an important engineering challenge will be to define test conditions and performance standards in cooperation with governmental institutions and industrial associations to assess the capabilities and reliability of drone technologies. We also expect rapid progress in cognitive autonomy, which will con- tinue to be driven by the development of artificial intelligence for smart- phones capable of identifying human users, learning their behaviours and creating representations of their environment (http://www.google. com/atap). On the one hand, face recognition and gesture-based interac- tion without wearable devices will become widely available for hobby and toy drones within the next five years; for example, by equipping small drones with human-motion-sensing devices developed by the gaming industry. On the other hand, mapping and path planning for autono- mous flight in partially unknown and changing environments will rep- resent a challenge for small drones for at least the next ten years and will continue to be illegal in the United States and Europe until at least 2028. Despite these legal roadblocks, we expect an increasing demand for small drones in civilian use because of their intrinsic safety. Kinetic energy — one measure of the potential of a drone to cause physical harm to a human 97 — is linearly proportional to the drone’s mass and is quadratic in velocity. Thus smaller drones are likely to cause pro- portionally less harm as the size is reduced, but more subtly, small drones typically operate at lower speeds, dramatically decreasing the potential for harm. For example, a 500 g drone flying at 5 m s−1 has 6.5 J of kinetic energy, which is equivalent to the potential energy of a large apple dropped from about 2 m. As the mobile computing indus- try continues along the path of miniaturization, drone developers will continue to reap the benefits in the form of smaller, lower power sensor packages (for example, the IMUs used in cell phones and video game controllers) and the slow, but steady increase in battery energy density. Another hardware advance that will inevitably affect future drones is the movement away from general-purpose computation in favour of more specialized high-performance and low-power hardware accel- erators tuned for the various functions needed by autonomous drones (both reactive and cognitive autonomy). These accelerators are already present in various mobile devices and are suggested to be a solution to computation for the control of insect-scale drones 19. ■ Received 17 November 2014; accepted 18 March 2015. 1. Bouabdallah, S. Design and Control of Quadrotors with Applications to Autonomous Flying. PhD thesis, Ecole Polytechnique Federale de Lausanne (2007). 2. Ladson, C. L., Brooks, C. W. Jr, Hill, A. S. & Sproles, D. W. Computer Program to Obtain Ordinates for NACA Airfoils. Report No. 4741 (NASA, 1996). 3. Kumar, V. & Michael, N. Opportunities and challenges with autonomous micro aerial vehicles. Int. J. Robot. Res. 31, 1279–1291 (2012). This paper describes scaling laws for dynamics and control of quad rotors and related micro air vehicles. 4. Mellinger, D., Michael, N. & Kumar, V. Trajectory generation and control for precise aggressive maneuvers with quadrotors. Int. J. Robot. Res. 31, 664–674 (2012). 5. Brescianini, D., Hehn, M. & D’Andrea, R. Quadrocopter pole acrobatics. In Proc. International Conference on Intelligent Robots and Systems 3472–3479 (2013). 6. Shen, S., Mulgaonkar, Y., Michael, N. & Kumar, V. Vision-based state estimation and trajectory control towards aggressive flight with a quadrotor. In Proc. Robotics: Science and Systems http://www.roboticsproceedings.org/rss09/p32. html (2013). 7. Bry, A., Bachrach, A. & Roy, N. State estimation for aggressive flight in GPS- denied environments using onboard sensing. In Proc. IEEE International Conference on Robotics and Automation http://dx.doi.org/10.1109/ ICRA.2012.6225295 (2012). 8. de Croon, G. C. H. E. et al. Design, aerodynamics and autonomy of the DelFly. Bioinspir. Biomim. 7, 025003 (2012). 9. Keennon, M., Klingebiel, K. & Won, H. Development of the Nano Hummingbird: a tailless flapping wing micro air vehicle. In Proc. AIAA Aerospace Sciences Meeting http://dx.doi.org/10.2514/6.2012-588 (2012). 10. Trimmer, W. S. N. Microrobots and micromechanical systems. Sens. Actuators 19, 267–287 (1989). 11. Wood, R. J. et al. Progress on ‘pico’ air vehicles. Int. J. Robot. Res. 31, 1292– 1302 (2012). 12. Finio, B. M. & Wood, R. J. Distributed power and control actuation in the thoracic mechanics of a robotic insect. Bioinspir. Biomim. 5, 045006 (2010). 13. Ma, K., Chirarattananon, P., Fuller, S. & Wood, R. J. Controlled flight of a biologically inspired, insect-scale robot. Science 340, 603–607 (2013). This paper details the development of a flying robotic insect and the first controlled flight of this vehicle. 14. Wood, R. J., Steltz, E. & Fearing, R. S. Optimal energy density piezoelectric bending actuators. Sensors Actuators A: Physical 119, 476–488 (2005). 15. Phys.org. World’s Lightest Micro-Flying Robot Built by Epson http://phys.org/ news860.html (2004). 16. Kovac, M., Guignard, A., Nicoud, J.-D., Zufferey, J.-C. & Floreano, D. A 1.5g SMA- actuated microglider looking for the light. In Proc. International Conference on Robotics and Automation 367–372 (2007). 17. Shintake, J., Rosset, S., Schubert, B. E., Floreano, D. & Shea, H. A foldable antagonistic actuator. IEEE/ASME Trans. Mechatron. http://dx.doi.org/10.1109/ TMECH.2014.2359337 (2014). 18. Dickinson, M. H., Lehmann, F. O. & Sane, S. P. Wing rotation and the aerodynamic basis of insect flight. Science 284, 1954–1960 (1999). 19. Wood, R. J., Nagpal, R. & Wei, G.-Y. Flight of the RoboBees. Sci. Am. 308 http:// www.scientificamerican.com/article/robobee-project-building-flying-robots- insect-size/ (2013). 20. Sreetharan, P., Whitney, J. P., Strauss, M. & Wood, R. J. Monolithic fabrication of millimeter-scale machines. J. Micromech. Microeng. 22, 055027 (2012). 21. Daler, L., Klaptocz, A., Briod, A., Sitti, M. & Floreano, D. A perching mechanism for flying robots using a fibre-based adhesive. In Proc. International Conference on Robotics and Automation 4418–4423 (2013). 22. Moore, J. & Tedrake, R. Magnetic localization for perching UAVs on powerlines. In Proc. International Conference on Intelligent Robots and Systems 2700–2707 (2011). 23. Bachmann, R. J., Boria, F. J., Vaidyanathan, R. & Ifju, P. G. A biologically inspired micro-vehicle capable of aerial and terrestrial locomotion. Mechanism Mach. Theory 44, 513–526 (2009). 24. Peterson, K., Birkmeyer, P., Dudley, R. & Fearing, R. S. A wing-assisted running robot and implications for avian flight evolution. Bioinspir. Biomim. 6, 046008 (2011). 25. Gabrielli, G. & von Kármán, T. What price speed? Specific power required for propulsion of vehicles. Mech. Eng. 72, 775–781 (1950). 26. Daler, L., Mintchev, S., Stefanini, C. & Floreano, D. A bioinspired multi-modal flying and walking robot. Bioinspir. Biomim. 10, 016005 (2015). 27. Riskin, D. K. & Hermanson, J. W. Biomechanics: independent evolution of running in vampire bats. Nature 434, 292 (2005). 28. Itasse, M., Moschetta, J.-M., Ameho, Y. & Carr, R. Equilibrium transition study for a hybrid MAV. Inter. J. Micro Air Vehicles 3, 229–246 (2011). 29. Kalantari, A. & Spenko, M. Design and experimental validation of HyTAQ, a hybrid terrestrial and aerial quadrotor. In Proc. International Conference on Robotics and Automation 4445–4450 (2013). 30. Briod, A., Kornatowski, P. M., Zufferey, J.-C. & Floreano, D. A collision resilient flying robot. J. Field Robot. 31, 496–509 (2014). 31. Vidyasagar, A., Zufferey, J.-C., Floreano, D. & Kovac, M. Performance analysis of jump-gliding locomotion for miniature robotics. Bioinspir. Biomim. 10, 025006 (2015). 32. Woodward, M. A. & Sitti, M. MultiMo-Bat: a biologically inspired integrated jumping–gliding robot. Int. J. Robot. Res. 33, 1511–1529 (2014). 33. Desbiens, A. L., Pope, M. T., Christensen, D. L., Hawkes, E. W. & Cutkosky, M. R. Design principles for efficient, repeated jump gliding. Bioinspir. Biomim. 9, 025009 (2014). 34. Siddall, R. & Kovač, M. Launching the AquaMAV: bioinspired design for 28 M A Y 2015 | V O L 521 | N A T U R E | 465 REVIEW INSIGHT © 2015 Macmillan Publishers Limited. All rights reserved aerial–aquatic robotic platforms. Bioinspir. Biomim. 9, 031001 (2014). 35. Floreano, D., Zufferey, J.-C., Srinivasan, M. V. & Ellington, C. Flying Insects and Robots (Springer, 2009). This book provides an introduction to insect-inspired drones for biologists and engineers. 36. Land, M. F. & Nilsson, D.-E. Animal Eyes (Oxford Univ. Press, 2002). 37. Srinivasan, M. V. How insects infer range from visual motion. Rev. Oculomot. Res. 5, 139–156 (1993). 38. Gibson, J. J. The Perception of the Visual World (Houghton Mifflin, 1950). 39. Koenderink, J. J. Optic Flow. Vision Res. 26, 161–179 (1986). 40. Lehrer, M., Srinivasan, M. V., Zhang, S. W. & Horridge, G. A. Motion cues provide the bee’s visual world with a third dimension. Nature 332, 356–357 (1988). 41. Franceschini, N., Riehle, A. & Le Nestour, A. in Facets of Vision (eds Stavenga, D. G. & Hardie, R. C.) 360–390 (Springer, 1989). 42. Krapp, H. G. & Hengstenberg, R. Estimation of self-motion by optic flow processing in single visual interneurons. Nature 384, 463–466 (1996). 43. Tammero, L. F. & Dickinson, M. H. The influence of visual landscape on the free flight behavior of the fruit fly Drosophila melanogaster. J. Exp. Biol. 205, 327–343 (2002). 44. Barron, A. & Srinivasan, M. V. Visual regulation of ground speed and headwind compensation in freely flying honey bees (Apis mellifera L.). J. Exp. Biol. 209, 978–984 (2006). 45. Srinivasan, M. V., Zhang, S. W., Altwein, M. & Tautz, J. Honeybee navigation: nature and calibration of the “odometer”. Science 287, 851–853 (2000). 46. Serres, J., Masson, G., Ruffier, F. & Franceschini, N. A bee in the corridor: centering and wall-following. Naturwissenschaften 95, 1181–1187 (2008). 47. Portelli, G., Ruffier, F. & Franceschini, N. Honeybees change their height to restore optic flow. J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol. 196, 307–313 (2010). 48. Straw, A. D., Serin, L. & Dickinson, M. H. Visual control of altitude in flying Drosophila. Curr. Biol. 20, 1550–1556 (2010). 49. Egelhaaf, M. & Borst, A. A look into the cockpit of the fly: visual orientation, algorithms, and identified neurons. J. Neurosci. 13, 4563–4574 (1993). 50. Wagner, H. Flow-field variables trigger landing in flies. Nature 297, 147–148 (1982). 51. Baird, E., Boeddeker, N., Ibbotson, M. R. & Srinivasan, M. V. A universal strategy for visually guided landing. Proc. Natl Acad. Sci. USA 110, 18686–18691 (2013). 52. Taylor, G. K. & Krapp, H. G. Sensory systems and flight stability: what do insects measure and why? Adv. Insect Physiol. 34, 231–316 (2007). 53. Chahl, J. S., Srinivasan, M. V. & Zhang, S. W. Landing strategies in honeybees and applications to uninhabited airborne vehicles. Int. J. Robot. Res. 23, 101–110 (2004). 54. Garratt, M. A. & Chahl, J. S. Vision-based terrain following for an unmanned rotorcraft. J. Field Robot. 25, 284–301 (2008). 55. Griffiths, S. et al. Maximizing miniature aerial vehicles. IEEE Robot. Autom. Mag. 13, 34–43 (2006). 56. Zufferey, J.-C., Klaptocz, A., Beyeler, A., Nicoud, J.-D. & Floreano, D. A 10-gram vision-based flying robot. Adv. Robot. 21, 1671–1684 (2007). 57. Beyeler, A., Zufferey, J.-C. & Floreano, D. Vision-based control of near-obstacle flight. Auton. Robots 27, 201–219 (2009). 58. Chan, W. P., Prete, F. & Dickinson, M. H. Visual input to the efferent control system of a fly’s “gyroscope”. Science 280, 289–292 (1998). 59. Collett, T. S. Some operating rules for the optomotor system of a hoverfly during voluntary flight. J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol. 138, 271–282 (1980). 60. Baird, E., Srinivasan, M. V., Zhang, S. & Cowling, A. Visual control of flight speed in honeybees. J. Exp. Biol. 208, 3895–3905 (2005). 61. Ruffier, F. & Franceschini, N. Optic flow regulation: the key to aircraft automatic guidance. Robot. Auton. Syst. 50, 177–194 (2005). 62. Roubieu, F. L. et al. A biomimetic vision-based hovercraft accounts for bees’ complex behaviour in various corridors. Bioinspir. Biomim. 9, 036003 (2014). 63. Conroy, J., Gremillion, G., Ranganathan, B. & Humbert, S. J. Implementation of wide-field integration of optic flow for autonomous quadrotor navigation. Auton. Robots 27, 189–198 (2009). 64. Briod, A., Zufferey, J.-C. & Floreano, D. Optic-flow based control of a 46 g quadrotor. In Proc. Workshop on Vision-based Closed-Loop Control and Navigation of Micro Helicopters in GPS-denied Environments http://rpg.ifi.uzh.ch/IROS13_ TOC.html (2013). 65. Schuppe, H. & Hengstenberg, R. Optical properties of the ocelli of Calliphora erythrocephala and their role in the dorsal light response. J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol. 173, 143–149 (1993). 66. Fuller, S. B., Karpelson, M., Censi, A., Ma, K. Y. & Wood, R. J. Controlling free flight of a robotic fly using an onboard vision sensor inspired by insect ocelli. J. R. Soc. Interface 11, 20140281 (2014). 67. Gremillion, G., Humbert, J. S. & Krapp, H. G. Bio-inspired modeling and implementation of the ocelli visual system of flying insects. Biol. Cybern. 108, 735–746 (2014). 68. Ruffier, F. & Franceschini, N. Optic flow regulation in unsteady environments: a tethered MAV achieves terrain following and targeted landing over a moving platform. J. Intell. Robot. Syst. http://dx.doi.org/10.1007/s10846-014-0062-5 (2014). 69. Ruffier, F., Viollet, S., Amic, S. & Franceschini, N. Bio-inspired optical flow circuits for the visual guidance of micro air vehicles. In Proc. International Symposium on Circuits and Systems 3, 846–849 (2003). 70. Duhamel, P.-E. J., Pérez-Arancibia, N. O., Barrows, G. & Wood, R. J. Biologically inspired optical-flow sensing for altitude control of flapping-wing microrobots. IEEE Trans. Mechatron. 18, 556–568 (2013). 71. Floreano, D. et al. Miniature curved artificial compound eyes. Proc. Natl Acad. Sci. USA 110, 9267–9272 (2013). 72. Song, Y. M. et al. Digital cameras with designs inspired by the arthropod eye. Nature 497, 95–99 (2013). 73. Zufferey, J. C. et al. Aerial collective systems. In Handbook of Collective Robotics (ed. Kernbach, S.) 609–660 (CRC, 2013). This chapter provides an introduction and survey of collective aerial vehicles. 74. Ballerini, M. et al. Interaction ruling animal collective behavior depends on topological rather than metric distance: evidence from a field study. Proc. Natl Acad. Sci. USA 105, 1232–1237 (2008). 75. Nagy, M., Akos, Z., Biro, D. & Vicsek, T. Hierarchical group dynamics in pigeon flocks. Nature 464, 890–893 (2010). 76. Reynolds, C. W. Flocks, herds, and schools: a distributed behavioral model. Comput. Graph. 21, 25–34 (1987). 77. Couzin, I. D., Krause, J., Franks, N. R. & Levin, S. A. Effective leadership and decision-making in animal groups on the move. Nature 433, 513–516 (2005). 78. Roberts, J., Stirling, T., Zufferey, J.-C. & Floreano, D. 3-D relative positioning sensor for indoor flying robots. Auton. Robots 33, 5–20 (2012). 79. Hauert, S. et al. Reynolds flocking in reality with fixed-wing robots: communication range vs. maximum turning rate. In Proc. International Conference on Robots and Systems 5015–5020 (2011). 80. Virágh, C. et al. Flocking algorithm for autonomous flying robots. Bioinspir. Biomim. 9, 025012 (2014). 81. Basiri, M., Schill, F. S., Floreano, D. & Lima, P. Audio-based localization for swarms of micro air vehicles. In Proc. International Conference on Robotics and Automation http://infoscience.epfl.ch/record/196274 (2014). 82. Scaramuzza, D. & Fraundorfer, F. Visual odometry: part I — the first 30 years and fundamentals. IEEE Robot. Autom. Mag. 18, 80–92 (2011). 83. Fraundorfer, F. & Scaramuzza, D. Visual odometry: part II — matching, robustness, and applications. IEEE Robot. Autom. Mag. 19, 78–90 (2012). 84. Davison, A. J. & Murray, D. W. Simultaneous localization and map-building using active vision. IEEE Trans. Pattern Anal. Mach. Intell. 24, 865–880 (2002). 85. Bachrach, A., He, R. & Roy, N. Autonomous flight in unknown indoor environments. Inter. J. Micro Air Vehicles 1, 217–228 (2009). 86. Scaramuzza, D. et al. Vision-controlled micro flying robots: from system design to autonomous navigation and mapping in GPS-denied environments. IEEE Robot. Autom. Mag. 21, 26–40 (2014). This paper details the development of a drone capable of outdoor simultaneous localization and mapping without GPS. 87. de Wagter, C., Tijmons, S., Remes, B. D. W. & de Croon, G. C. H. E. Autonomous flight of a 20-gram flapping wing MAV with a 4-gram onboard stereo vision system. In Proc. International Conference on Intelligent Robots and Systems 4982–4987 (2014). 88. Heng, L. et al. Autonomous visual mapping and exploration with a micro aerial vehicle. J. Field Robot. 31, 654–675 (2014). 89. Schauwecker, K. & Zell, A. On-board dual-stereo-vision for the navigation of an autonomous MAV. J. Intell. Robot. Syst. 74, 1–16 (2014). 90. Kendoul, F., Fantoni, I. & Nonami, K. Optic flow-based vision system for autonomous 3D localization and control of small aerial vehicles. Robot. Auton. Syst. 57, 591–602 (2009). 91. US Department of Transportation. Integration of Civil Unmanned Aircraft Systems (UAS) in the National Airspace System (NAS) Roadmap (US Department of Transportation Federal Aviation Authority, 2013). 92. UK Civil Aviation Authority. Unmanned Aircraft System Operations in UK Airspace — Guidance. Report CAP 722 (UK Civil Aviation Authority, 2012). 93. Ministère de l’Ecologie, du Developpement Durable, des Transports et du Logement. Relatif à l’utilisation de l’espace aérien par les aéronefs qui circulent sans personne à bord [in French]. Report No. Texte 9 sur 308, (Ministère de l’Ecologie, du Developpement Durable, des Transports et du Logement, 2012). 94. Swiss Federal Office of Civil Aviation. Drones and aircraft models http://www. bazl.admin.ch/dienstleistungen/02658/index.html?lang=en (Swiss Federal Office of Civil Aviation, 2014). 95. European RPAS Steering Group. Roadmap for the Integration of Civil Remotely- Piloted Aircraft Systems into the European Aviation System http://ec.europa.eu/ enterprise/sectors/aerospace/uas/ (European RPAS Steering Group, 2013). 96. European Commission. A New Era for Aviation: Opening the Aviation Market to the Civil Use of Remotely Piloted Aircraft Systems in a Safe and Sustainable Manner. Report COM(2014) 207 (European Commission, 2014). 97. Haddon, D. R. & Whittaker, C. J. Aircraft airworthiness certification standards for civil UAVs. Aeronaut. J. 107, 79–86 (2003). 98. International Organization for Standardization. Robots and robotic devices — vocabulary ISO 8373:2012 (International Organization for Standardization, 2012). Acknowledgements D.F. and R.J.W. thank the Wyss Institute for Biologically Inspired Engineering at Harvard University, where this Review was written. D.F. also thanks the Swiss National Science Foundation through the National Centre of Competence in Research Robotics. Author Information Reprints and permissions information is available at www.nature.com/reprints. The authors declare no competing financial interests. Readers are welcome to comment on the online version of this paper at go.nature.com/xukalu. Correspondence should be addressed to D.F. (dario.floreano@epfl.ch). 466 | N A T U R E | V O L 521 | 28 M A Y 2015 REVIEWINSIGHT © 2015 Macmillan Publishers Limited. All rights reserved","libVersion":"0.3.2","langs":""}