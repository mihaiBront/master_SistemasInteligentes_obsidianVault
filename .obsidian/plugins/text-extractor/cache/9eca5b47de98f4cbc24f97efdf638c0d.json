{"path":"_aula_virtual/SJK001/Reading Assessments/[Pfeifer07] Self-Organization, Embodiment, and Biologically Inspired Robotics.pdf","text":"DOI: 10.1126/science.1145803 , 1088 (2007); 318Science et al.Rolf Pfeifer, Inspired Robotics Self-Organization, Embodiment, and Biologically www.sciencemag.org (this information is current as of April 3, 2008 ): The following resources related to this article are available online at http://www.sciencemag.org/cgi/content/full/318/5853/1088 version of this article at: including high-resolution figures, can be found in the onlineUpdated information and services, http://www.sciencemag.org/cgi/content/full/318/5853/1088/DC1 can be found at: Supporting Online Material found at: can berelated to this articleA list of selected additional articles on the Science Web sites http://www.sciencemag.org/cgi/content/full/318/5853/1088#related-content http://www.sciencemag.org/cgi/content/full/318/5853/1088#otherarticles , 7 of which can be accessed for free: cites 39 articlesThis article http://www.sciencemag.org/cgi/collection/comp_math Computers, Mathematics : subject collectionsThis article appears in the following http://www.sciencemag.org/about/permissions.dtl in whole or in part can be found at: this article permission to reproduce of this article or about obtaining reprintsInformation about obtaining registered trademark of AAAS. is aScience2007 by the American Association for the Advancement of Science; all rights reserved. The title CopyrightAmerican Association for the Advancement of Science, 1200 New York Avenue NW, Washington, DC 20005. (print ISSN 0036-8075; online ISSN 1095-9203) is published weekly, except the last week in December, by theScience on April 3, 2008 www.sciencemag.orgDownloaded from REVIEW Self-Organization, Embodiment, and Biologically Inspired Robotics Rolf Pfeifer,1* Max Lungarella,1 Fumiya Iida 1,2 Robotics researchers increasingly agree that ideas from biology and self-organization can strongly benefit the design of autonomous robots. Biological organisms have evolved to perform and survive in a world characterized by rapid changes, high uncertainty, indefinite richness, and limited availability of information. Industrial robots, in contrast, operate in highly controlled environments with no or very little uncertainty. Although many challenges remain, concepts from biologically inspired (bio-inspired) robotics will eventually enable researchers to engineer machines for the real world that possess at least some of the desirable properties of biological organisms, such as adaptivity, robustness, versatility, and agility. A lthough traditionally, biologically in- spired (bio-inspired) robotics has been largely about neural modeling (for exam- ple, for phonotaxis, navigation, or vision), recent developments in the field have centered on the notions of self-organization and embodiment; that is, the reciprocal and dynamical coupling among brain (control), body, and environment. We will show that most advances converge onto a set of principles that are implicitly or explicitly employed by robot designers: First, the behavior of any system is not merely the outcome of an internal control structure (such as the central ner- vous system). A system’s behavior is also affected by the ecological niche in which the system is physically embedded, by its morphology (the shape of its body and limbs, as well as the type and placement of sensors and effectors), and by the material properties of the elements composing the morphology (1). Second, physical constraints shape the dynamics of the interaction of the embodied system with its environment (for exam- ple, because of the way it is attached to the body at the hip joint, during walking a leg behaves to some extent like a pendulum) and can be exploited to achieve stability, maneuverability, andenergyefficiency(2, 3). Third, a direct link exists between embodiment and information: Coupled sensory-motor activity and body mor- phology induce statistical regularities in sensory input and within the control architecture and therefore enhance internal information processing (4). Fourth, viewing an embodied agent (5)asa complex dynamical system enables us to employ concepts such as self-organization and emergence rather than hierarchical top-down control. As we review some of the recent advances in bio-inspired robotics, it will become clear that autonomous agents display self-organization and emergence at multiple levels: at the level of induction of sensory stimulation, movement generation, exploitation of morphological and material properties, and interac- tion between individual modules and entire agents. Bio-Inspired Embodied Systems Artifacts in general and robots in particular are always designed for a particular task environ- ment in which they have to achieve certain be- haviors. In a manufacturing plant, where robots have to rapidly weld pieces together, precisely assemble motors, or neatly package chocolates into boxes, the focus is on speed, precision, con- trollability, and cost-effectiveness. In contrast, robots having to perform in the real world should be able to cope with uncertain situations and react quickly to changes in the environment. Biological systems provide an exceptional source of inspiration. The biological world is immensely diverse—roughly 1.5 million different species have so far been identified—and this richness is also, though at a much smaller scale, reflected in the different types of robots that have been de- veloped (table S1). Bio-inspiration originates from molecular and cellular reproduction (6–8); slime molds (9); walking insects (10, 11); flying insects (12, 13); spiders (14); lobsters (15); oc- topuses (16); fish (17) and other aquatic creatures; amphibious animals such as salamanders (18) and snakes (19); four-legged animals such as geckos (20), mice (21), and dogs (17, 22); and, of course, primates such as monkeys and human beings (23–25). Major goals for these robots are movement, locomotion (crawling, walking, running, climbing, swimming, and flying), nav- igation, orientation, manipulation, imitation, and cooperation. Biology contains especially rich and useful knowledge for robotics in disciplines such as neuroscience (in particular, computational neuroscience and neuroethology), biomechanics, animal physiology, and systems biology. Given the vastness of the information avail- able, the question arises as to what insights from biology could and should be exploited for design- ing robots. Simply copying a biological system is either not feasible (even a single neuron is too complicated to be synthesized artificially in every detail) or is of little interest (animals have to satis- fy multiple constraints that do not apply to robots, such as keeping their metabolism running and getting rid of parasites), or the technological solu- tion is superior to the one found in nature (for example, the biological equivalent of the wheel has yet to be discovered). Rather, the goal is to work out principles of biological systems and transfer those to robot design. This philosophy underlies, for in- stance, the rapidly expanding field of bionics, which seeks to design technology by mimicking the salient features of biological structures (26). One impor- tant lesson from bionics studies is that successful natural designs rely on effective embodiment: on clever morphology and use of material properties. If properly applied, embodiment can lead to surprising insights. Although the idea has been around for quite some time (27–29), its implica- tions for the design of autonomous adaptive sys- tems have not yet been sufficiently explored and theoretically elaborated. As a consequence, robot designers often opt for centralized solutions where there is a microprocessor responsible for control- ling the movement of all limbs and joints. Simply applying methods from control engineering to ro- bots that have to perform in the real world has not worked well in practice: many humanoid robots, for example, are still energetically inefficient and lack adaptivity when confronted with situations that animals cope with on a routine basis. An embodied perspective, because it distributes control and pro- cessing to all aspects of the agent (its central nervous system, the material properties of its musculoskeletal system, the sensor morphology, and the interaction with the environment), provides an alternative avenue for tackling the challenges faced by robotics. The tasks performed by the controller in the classical approach are now partially taken over by morphology and materials in a pro- cess of self-organization; for example, skin proper- ties support the functionality of hands: Grasping a glass with soft, compliant, slightly humid fingertips is much easier than with thimbles, because the deformation of the tissue on the fingertips, which is entirely passive, increases surface contact and friction. Clearly, the embodied view suggests that the actual behavior emerges from the interaction dynamics of agent and environment through a con- tinuous and dynamic interplay of physical and information processes (Fig. 1). Although impor- tant insights can be gained from simulations, most of this review is devoted to studies employ- ing physically embodied robots; indeed, in spite of recent advances in simulation technology, the actual dynamics of the real world are still very hard to simulate accurately (such as the interac- tion of an agent’s body with sand or water). Embedded Neural Models Historical precursors of today’s bio-inspired ro- bots were the mechanical tortoises built by Grey Robotics 1Department of Informatics, Artificial Intelligence Labora- tory, University of Zurich, Zurich, Switzerland. 2Computer Science and Artificial Intelligence Laboratory, Massachu- setts Institute of Technology, Cambridge, MA, USA. *To whom correspondence should be addressed. E-mail: pfeifer@ifi.uzh.ch 16 NOVEMBER 2007 VOL 318 SCIENCE www.sciencemag.org1088 on April 3, 2008 www.sciencemag.orgDownloaded from Walter in the 1940s; these machines displayed an impressive behavioral repertoire based solely on neurally inspired analog electronics. In the past 15 years or so, robots of all sorts have been used to study and test models of natural neural information processing [for recent surveys, see (1, 30, 31)]. Bio-inspired neural modeling has driven research on locomotion; for instance, to understand legged underwater locomotion (15), to study the switching between swimming and walk- ing observed in salamanders (18) (Fig. 2A), or to investigate adaptive dynamic walking on irregular terrain (22). Much attention has also been devoted to emulating navigation and orientation behavior. Examples abound and include visual homing inspired by how bees or wasps find their way back to their nests (12), cricket phonotaxis [how female crickets move toward the mating sounds of males in highly rugged and noisy environments (32)], and spatial memory formation by mod- eling place fields and head-direction cells which account for the sophis- ticated navigational skills of rodents (33). One of the important design principles implicitly exploited in the examples above is sensory-motor coordination (34); that is, the mutual coupling of sensing and acting. This principle supports the generation of information structure in sensory stim- ulation: spatiotemporal correlations in sensory input streams, redundancies be- tween different perceptual modalities, or regularities in sensory patterns that are invariant with respect to changes in illumination, size, or orientation. The information-theoretic implica- tions of embodiment are far-reaching. First, the induced information struc- ture represents redundancy across sensory channels, which may, given the typically staggering number of possible states that the sensory input can assume, substantially simplify per- ception. Second, information structure does not exist before the interaction occurs but emerges only when the embodied system interacts with its surroundings. However, once such structure has been induced, learning can pick up on it by forming cross- modal associations, so that next time around, the pertinent information structure is more easily reactivated, and, for example, stimulation in one sensor modality can be partially pre- dicted from another one (for instance, by looking at a glass we can partially predict what it will feel like when we grasp it). It follows that embodied interaction lies at the root of learning because it enables the creation of time- locked correlations and the discovery of regularities that transcend the individual sensory modalities (4) as necessary for concept learning, such as the grasping of a cup, which yields visual, haptic, and proprioceptive sensory information. Implications of Embodiment In the examples discussed so far, the importance of using robots lies mostly in the fact that the neural models are embedded in an embodied sys- tem equipped with sensors and actuators enabling physical interaction with the environment. The models are thus exposed to realistic sensory stimulation, rather than the idealized one typically used in simulation studies (Fig. 2B). Recently, there has been a growing interest in a more inte- grative study of biologically inspired systems, and many of the implications of embodiment have shifted toward center stage: exploitation of mor- phology and materials, sensory-motor interaction dynamics, and self-organization (or more pre- cisely, self-stabilization, which is stabilization with- out explicit feedback mechanisms; that is, without measuring the disturbances or altering the system) (3, 10, 17, 22, 35) (Fig. 3). As an illustrative example, take legged lo- comotion in insects. Insects possess dozens of degrees of freedom that need to be coordinated during walking or running, which is particularly challenging when dealing with uneven surfaces. It is plausible to assume that insects do not solve the inverse kinematics problem for all the joints at all times (a strategy often adopted in robotics, but which though being computationally exact re- quires high-bandwidth sensory feedback for fast gaits). The solution to the control problem can be found in the exploitation of embodiment and de- centralization. If the insect is pushing back with one leg, the joints of all the other legs that are on the ground are moved in the “cor- rect” direction, a movement that can be detected by angle sensors in the joints (11). This way, there is global communication between the legs that can be exploited for their co- ordination, even though at the level of the neural system no central con- troller for the legs exists. Another means to simplify the control of dynamic locomotion is through passive mechanisms alone. For instance, the rapid adaptation to small unpredictable bumps in the ground is taken over by the passive compliance of the insect’s muscle- tendon system and the slack in its joints (3, 14). Technically, it is possible to realize this principle for hexapod walkers using pneumatic linear actuators (air muscles), where the compliance is provided by com- pressed air, enabling the robots to move at impressive speeds even over rough terrain (10) (Fig. 2C). Similar feats have been achieved by employing electrical motors cou- pled to spring-damper systems in the case of quadrupeds (17, 22). These are all examples of what one might call “intelligence by mechanics” (35), which implies that the intrinsic dynamics of the nonlinear mechanics yield self- stabilizing behavior (that is, robust- ness with respect to perturbations with minimum neural sensing). Para- digmatic examples of self-stabilizing systems are the passive dynamic walkers: robots (or rather mechanical structures without microprocessors or motors) that walk down a slope without control and actuation (2). The walker’s morphology (center of Fig. 1. Implications of embodiment (the interplay of information and physical processes). Driven by motor commands, the musculoskeletal system (mechanical system) of the agent acts on the external environment (task environment or ecological niche). The action leads to rapid mechanical feedback characterized by pressure on the bones, torques in the joints, and passive deformation of skin tissue. In parallel, external stimuli (pressure, temperature, and electromagnetic fields) and internal physical stimuli (forces and torques developed in the muscles and joint-supporting ligaments, as well as accelerations) impinge on the sensory receptors (sensory system). The patterns induced thus depend on the physical characteristics and morphology of the sensory systems and on the motor commands. Especially if the interaction is sensory-motor coordinated, as in foveation, reaching, or grasping movements, information structure is generated. The effect of the motor command strongly depends on the tunable morphological and material properties of the musculoskeletal system, where by tunable we mean that properties such as shape and compliance can be changed dynamically: During the forward swing of the leg in walking, the muscles should be largely passive, whereas when hitting the ground, high stiffness is required, so that the materials can take over some of the adaptive functionality on impact, such as the damped oscillation of the knee joint. www.sciencemag.org SCIENCE VOL 318 16 NOVEMBER 2007 1089 SPECIALSECTION on April 3, 2008 www.sciencemag.orgDownloaded from mass, length of the limbs, and the shape of the feet) and its materials are carefully designed so as to exploit the physical constraints present in its ecological niche (friction, gravity, and inclination of the slope) for locomotion. Interestingly, to get the robot to learn to walk on a level surface, one can reuse the mechanical design obtained during passive dynamic walking and endow it with ac- tuators in the ankles or hips (Fig. 2D). The natural dynamics of the body/environment system can be used as a target for learning the control policy of the actuators, and it is an “easy” one because once the system is in the desired basin of attraction, it is “pulled” into a quasiperiodic limit cycle trajectory. In other words, the robot learns to walk on flat ground within a relatively short period of time. The theoretical import of this case study lies in the tight coupling of em- bodiment, self-organization, and learning. Again, the ability to walk is not localized in the controller but is fully distributed throughout the agent and its dynamics; part of the control task is “outsourced” to the physical dynamics of the agent. In all forms of locomotion, neural control can be simplified through clever morphological design and use of functional materials. A case in point is aquatic locomotion. It is known that fish, some am- phibians, and reptiles swim by producing traveling waves of neural activation transmitted along chains of coupled oscillators located in the spinal cord (36). The attempt to model and mimic the very same mechanism has inspired a host of multi- segmented undulatory robots such as fish, swim- ming salamander, and snake robots (18, 19). The key to their construction is the translation of neural Fig. 2. Self-organization, dynamics, and materials in bio-inspired robotics. (A) Smooth transition between swimming and walking (18). This amphibious salamanderlike robot (~80 cm long) embeds a spinal cord model that explains the ability of salamanders to switch between swimming and walking. The locomotion model is built by extending a primitive neural circuit for swimming by phylogenetically more recent limb oscillatory centers. (B)Richsensory stimulation through proper sensor morphology (21). This robot (~7 cm in diameter) owes its sophisticated sensory capacities to the specific arrangement, shape, and material characteristics of its whiskers. Natural whiskers from rodents (such as the ones used on this robot) are far superior to whiskers built from other materials in terms of richness of the signals relayed to the neural system. (C) Self-stabilizing rapid hexapod locomotion (10). This robot (~15 cm long) moves with a bouncing gait, achieving rapid (over 4 body lengths per second) locomotion. Its legs are built with compliant pneumatic actuators, which yield self-stabilization through mechanical feedback. (D)Passive dynamics–based walking (2). Designed to work on a slope as a dynamic walker, this robot (~45 cm tall) exploits dynamics and morphology (in particular, the shape and length of the body and feet) to achieve stable walking. The robot’s natural dynamics serves as the target dynamics for a reinforcement learning mechanism, enabling the robot to quickly learn to walk on flat ground. (E) Self-stabilizing vertical takeoff through materials and morphology (13). Inspired by flies, this ultralight (60 mg, 3-cm wingspan) ornithopter (a device that flies by flapping its wings) generates sufficient lift to take off vertically (power is supplied externally). A large part of the control is delegated to the morphological and material properties of the robot. Compliant structures are driven into resonance to produce a large wing stroke, and flexible material is used in the wing hinges to allow for passive rotations of the wings. (F) Agile wall-climbing through materials (20). The bio-inspiration for this palm-sized robot is provided by the gecko and its uncanny climbing talents. The robot’s tri-foot (three-footed wheel) is equipped with a polymer dry adhesive material, which to some extent has contact properties comparable to those of its biological analog. The robot canflexiblynavigateonsmoothverticaland even inverted surfaces.(G) Morphing through localized self-reconfiguration (7). This self-reconfigurable robot is composed of active (actuated, black) and passive (nonactuated, white) cubic modules (~400 g, ~60 to 65 mm side length). The modules connect to each other through hooks, which enables the robot to change its morphology in a large number of ways. The picture shows the metamorphosis from a four- legged (quadruped) structure to a linear (snakelike) structure. (H)Global movement through local interaction dynamics (9). The individual wheel-like modules (~10 cm in diameter) constituting this robot are equipped with spokelike parts driven by linear actuators. The wheels lie horizontally on the ground and attach to neighboring modules by Velcro. Although no module can move on its own, by using neural oscillators as drivers for the actuators and through the physical coupling between the units, a coordinated global wave of activation can be induced in clusters of more than 30 modules, which leads to forward movement, even though there is no global control. 16 NOVEMBER 2007 VOL 318 SCIENCE www.sciencemag.org1090 Robotics on April 3, 2008 www.sciencemag.orgDownloaded from activity into torques propagating through the indi- vidual segments, so that the resulting reactive forces lead to forward movement. An alternative strategy for understanding underwater locomotion attempts to exploit morphology and bio-inspired materials, as demonstrated by a recently built fishlike robot that can swim by simply moving the tail back and forth (17). The “trick” that gives rise to lifelike movements in such a strongly underactuated sys- tem is the right choice of materials in the caudal fin; materials that allow the “tuning” of the fin shape in a way that seems to optimally distribute the hydrodynamic forces over the fish’s body dur- ing propulsion and maneuvering (17). The tuning is reminiscent of the way in which biological ray- finned fish actively control the curvature of their fins to optimize the transmission of locomotor forces to the aquatic environment, maximizing propulsion while minimizing energy consumption (37). Flying is different from swimming because in addition to the thrust required to move forward, it is necessary to produce sufficient lift to stay in the air (3). Despite the impressive mastery of flight by today’s technologies, constructing bio-inspired devices capable of nontethered (free) flight re- mains a challenge. The performance gap between mechanical flapping devices (ornithopters) and their natural analogs is still large (20). As for swimming, one potential avenue might be the ex- ploitation of the morphology of bio-inspired mate- rials (13). Take an insect wing during hovering flight. Its material properties in terms of resilience, stiffness, and deformability are essential to gener- ate adequate lift in the absence of any forward velocity. For instance, the shape of the wing changes greatly when moving back and forth through the stroke plane (3). Although such change in shape could in principle be actively controlled, it is more efficient and faster if the intrinsic material characteristics are exploited and control is out- sourced to the morphological and material prop- erties of the wing. An additional advantage of this solution is that the wings can be made much lighter because less actuation is required (Fig. 2E). Finally, materials can also be exploited for climbing, as beautifully showcased by the un- canny climbing skills of geckos, which can dash up smooth walls and walk across ceilings with great ease. The geckos owe their sticky feet to the structural properties of their toes, which are cov- ered with millions of nanoscale hairlike stalks branching into hundreds of tiny endings (38). The use of micropatterned fibrillar dry adhesives inspired by gecko foot morphology is bound to lead to impressive advances in the construction of robots that can climb vertical or inverted surfaces of all kinds (20) (Fig. 2F and supporting online material). Scaling Up Complexity Over the past decade or so, with the advent of aging societies and the concurrent advancement of technology, substantial research efforts have been directed toward engineering robots capable of performing a large variety of tasks such as assisting the elderly (by ensuring their quality of life and health care), doing household chores (washing the dishes, cooking dinner, and ironing), helping workers on assembly lines, surveillance, and entertainment. Much progress has been made in the study of basic abilities such as locomotion (2, 25); manipulation (39); understanding the surrounding environment, including the recognition of objects, people, and other robots; and social interaction (23, 40, 41). Because such robots need to operate in environ- ments built for humans, the morphology of choice is humanoid or anthropomorphic. Humanoid robots often have highly sophis- ticated sensory-motor systems (24, 25), which implies that they are confronted with the hard problem of processing potentially large amounts of information in real time. Although much re- search has been conducted on learning in the real world, especially in the fields of artificial intelligence and cognitive robotics (42), the tasks and environments, for the most part, have been of relatively limited complexity. One potential reason might be that the size of the search spaces for learning optimal decision policies in realistic scenarios makes the direct transfer of traditional algorithm-based machine-learning techniques to robots not straightforward; more so, if such robots need to operate in real time. Again, exploiting the agent/environment interaction might provide at least part of the solution. As demonstrated by experiments with robots (4), the notion of em- bodiment actively supports and promotes intelli- gent information processing, greatly simplifying the challenge posed by the need to process large amounts of sensory information (Fig. 4). Consider Fig. 3. Self-stabilization. (A) Picture of a two-dimensional underactuated monoped hopping robot attached to a central rod with a rotational joint (courtesy of A. Seyfarth and A. Karguth). (B)A schematic representation of the hopping robot in the different phases of locomotion: flight, touchdown (TD) [with angle of attack (AOA)], and takeoff (TO). Only the joint depicted by the black circle (hip joint) is actuated, the knee (white circle) is passive, and the lower limb is attached to the upper limb with a simple spring. (C) Output of a simulation of the robot. The upper part of the panel shows the trajectory of the model over time as a sequence of stick figures; in the lower part, the angle of attack (the angle at which the leg hits the ground) is plotted. The model exhibits a stable hopping gait with a periodic hip motor oscillation, as indicated by the constant AOA at every step in the left side of the panel. At distance d = 0 m, there is a step in the ground that disturbs the robot’s movement but to which the robot adapts without the need for any changes in the control. This purely mechanical phenomenon is called self-stabilization. [Figure adapted from (35)] www.sciencemag.org SCIENCE VOL 318 16 NOVEMBER 2007 1091 SPECIALSECTION on April 3, 2008 www.sciencemag.orgDownloaded from a loosely swinging arm: Although the trajectory of the hand is highly complex, the neural control for it is comparatively simple, as coordination is achieved primarily through peripheral mechanical feedback loops and the biomechanical constraints provided by the musculoskeletal system. The be- havior that emerges from the synergistic coupling of the arm’s morphology, its natural dynamics, and the coupling with the environment yields an ef- fective exploration strategy because it increases the probability that something interesting happens: that the hand encounters and grasps an object and brings it into the visual field or into the mouth. This way, sensory stimulation is not only induced but it also tends to contain information structure, which then strongly simplifies perception and learning (Fig. 4). Research on bio-inspired cognitive robots that has received considerable attention is imitation learning (23, 24), in which robots learn from hu- mans or other robots. This idea has a special appeal because imitation is a powerful mecha- nism for reducing the search spaces associated with learning in the real world, which might eventually lead to robots that will need only a minimal amount of programming (40). The hope that the imitation problem can soon be resolved has been fueled by the discovery in the mid-1990s of the mirror neuron system (a net- work of brain areas in the premotor and parietal cortices activated by both recognition and production of object-oriented movements) and its purported link to imitation (43). An important challenge in robotic imitation learning is that robots, in spite of their superficial resemblance, have entirely different morphologies from hu- mans. A similar problem is faced by babies trying to imitate adults. Although no generally accepted answer seems to be in sight, it is clear that a biomimetic solution has to take into account the morphological and material constraints to generate the proper imitative dynamics (24). Designing Morphologies Working in parallel with sensory-motor coordi- nation, the specific body morphology (as well as the materials employed) is crucial in shaping the resulting information structure (2, 4). In other words, the design of the controller and that of the morphology are inseparable from each other, because both affect information processing. Yet, although some progress has been made to op- timize the design of robot controllers, robot mor- phology still largely remains a matter of heuristics. In evolutionary robotics, the most widespread ap- proach is to start with a fixed morphology and evolve the robot controller, typically a neural network (44). In nature, however, there is never an “empty” organism, but brain (controller) and body (morphology) coevolve. By subjecting the mor- phology to evolutionary optimization as well, one can not only more fully exploit its power but also make the approach more plausible from a bio- logical perspective. Technically, the robot’smor- phology is either encoded in the artificial genome in terms of parameters standing for length, diam- eter, types of joints, and material properties of the basic building blocks that can be used by evolution to build organisms (45), or results from a process of ontogenetic development (46)ofbody and brain based on models of genetic regulatory networks (1). If it is indeed the case, as we have argued earlier, that much of the functionality of a robot is due to its particular morphology, then it would be desirable to have robots that, depending on the task at hand, can alter their shape. The term “morphofunctional machines” has been coined to designate devices that can change their function- ality not only by a change in control but by modifying their morphology (47). Some modular self-reconfigurable robots can “morph,” for exam- ple, from a snakelike structure into a quadruped walker or vice versa (7, 48) (Fig. 2G), which can be very helpful if the robot needs to move through a narrow space to accomplish its task. Incorporat- ing change of shape into the design considerations is crucial and bears enormous potential for increased adaptivity, versatility, and resilience, an idea that has not been substantially exploited yet. Fig. 4. Information self-structuring. (A) Picture of the robot, a small humanoid with a pan-tilt head equipped with a charge-coupled device camera [adapted from (4)]. In this experiment, there are two conditions: foveation (fov), where the camera in the robot head tracks an orange ball that moves in the robot’s visual field (sensory-motor coupling is undisrupted), and random (rnd), where the movement of the camera is unrelated to the movement of the ball (sensory-motor coupling is disrupted). (B)Schematic representation of the experimental setup. The ball is connected to the tip of the most distal link of a robot arm. The arm’s movement is preprogrammed and is independent of the head’s movement. The movement of the ball results in a displacement of the ball relative to the head and leads to physical stimulation in the head-mounted camera. Sensory feedback is induced, entailing motor commands from the controller. The motor commands entail a movement of the head, which in turn leads to physical stimulation of the camera, thereby inducing information structure. (C) Various measures to capture information structure: entropy (the amount of disorder in the system), mutual information (the extent to which the activity of one pixel can be predicted from the combined activities of neighboring pixels), integration (a measure of global coherence), and complexity (a measure that captures global coherence and local variation). The measures are applied to the camera image in the case of the foveation condition (top) and random condition (bottom). As can be seen, there is more information structure in the case of the foveation condition for all measures; for example, the dark region in the center of the entropy panel indicates that entropy is clearly diminished in the center of the visual field, (disorder has been reduced, or in other words, information structure has been induced), which is due to foveation being a sensory-motor coordinated behavior. This example illustrates information self-structuring because through its behavior, the robot is structuring its own sensory input. [Adapted from (4)] 16 NOVEMBER 2007 VOL 318 SCIENCE www.sciencemag.org1092 Robotics on April 3, 2008 www.sciencemag.orgDownloaded from To date, much of the work in modular robotics is based on macroscopic modules (with sizes ranging from centimeters to tens of centimeters) composed of microprocessors, communication links, sensors, actuators, and mechanical or magnetic docking interfaces (48). The size of the modules imposes severe constraints on the kinds of shapes that can be built and the functionality that can be achieved. At micrometer scales, these constraints are less critical, but conventional robotics technol- ogy can no longer be applied; it is thus essential to rely on processes of self-assembly—the autono- mous organization of patterns or structures with little (or ideally, without) human intervention (49). The combination of self-assembly with modular robotics might offer an important strategy for fab- ricating arbitrary morphologies with specific material properties and for engineering robots dis- playing truly emergent functionalities (Fig. 2H). Rather than studying how individual modules aggregate into an organism to perform some functionality, collective robotics investigates how groups of robots cooperate to accomplish a par- ticular task (50). Nature provides a wealth of collective phenomena that emerge through pro- cesses of self-organization from the local inter- action of individual agents (the formation of trails and bridges; sorting, flocking and school- ing behaviors; communication; and dominance interactions), which have provided much inspi- ration for robotics. With some notable exceptions (50, 51), much of the research in collective robotics is still conducted in simulation. More- over, morphological and material considerations are typically not taken into account. Self-Replication The ultimate challenge, self-replicating robots (machines that can autonomously construct a functional copy of themselves), has a lot of romantic appeal but conjures up images of a runaway technological cataclysm. Nonetheless, many approaches to self-replication have been suggested since John von Neumann’s seminal work on self-replicating cellular automata almost 60 years ago. Physical self-replicating machines have recently been realized with manually sup- plied 10-cm cubes that can connect to form arbitrary arrangements (8), as well as with elec- tromechanical units randomly floating on an air table, which first grow into a mechanical five-bit string and then self-replicate (6). Self-replication is not yet a well-defined subject and different notions of the term “self-replication” exist. Al- though von Neumann’s cellular automaton con- sisted of more than 150,000 cells, each capable of assuming 29 different states, more recent sys- tems contain just a small number of cells, with fewer states and little reliance on self-organization. It has thus been hypothesized that self-replication is not a clear-cut binary property but a con- tinuous one (8). Moreover, we might be more inclined to accept a machine as self-reproducing if it not merely recruits existing modules but as- sembles them from materials available in its sur- rounding environment. Although the latter is the goal of some projects (52), actual self-reproduction (as observed in biological life) in artificially built systems still needs to be achieved. Conclusion Recent work on bio-inspired robots suggests that self-organization and embodiment are power- ful concepts in the development of adaptive autonomous systems. Exploiting the dynamics provided by materials and morphological prop- erties as well as the interaction between phys- ical and information processes promises to extend the capabilities of established control- based robot design methodologies. Although bridging the gap between artificial and natural systems will require addressing many concep- tual and technological challenges, we believe that a first important step is the abstraction of a set of design principles. Such principles will not only yield a deeper understanding of biological structures and processes but will also guide the construction of novel types of robots of unprec- edented diversity and behavioral characteristics. Exciting times are ahead of us. References and Notes 1. R. Pfeifer, J. C. Bongard, How the Body Shapes the Way We Think—A New View of Intelligence (MIT Press, Cambridge, MA, 2007). 2. S. Collins, A. Ruina, R. Tedrake, M. Wisse, Science 307, 1082 (2005). 3. M. H. Dickinson et al., Science 288, 100 (2000). 4. M. Lungarella, O. Sporns, PLoS Comp. Biol. 2, e144 (2006). 5. We use the term “agent” whenever we do not want to make a distinction between humans, animals, and robots. 6. S. Griffith, D. Goldwater, J. M. Jacobson, Nature 437, 636 (2005). 7. S. Murata, H. Kurokawa, H. IEEE Robot. Autom. Mag. 14, 71 (2007). 8. V. Zykov, M. Efstathios, M. Desnoyer, H. Lipson, IEEE Trans. Robot. 23, 308 (2007). 9. A. Ishiguro, M. Shimizu, T. Kawakatsu, Robot. Auton. Syst. 54, 641 (2006). 10. J. G. Cham, J. K. Karpick, M. R. Cutkosky, Int. J. Robot. Res. 23, 141 (2004). 11. H. Cruse, V. Duerr, J. Schmitz, Philos. Trans. R. Soc. London Ser. A 365, 221 (2007). 12. A. Vardy, R. Moller, Connect. Sci. 17, 47 (2005). 13. R. J. Wood, in Proceedings of the International Conference on Intelligent Robots and Systems (San Diego, CA, 2007), pp. 1576–1581. 14. J. C. Spagna, D. I. Goldman, P.-C. Lin, D. E. Koditschek, R. J. Full, Bioinspiration Biomimetics 2, 9 (2007). 15. J. Ayers, J. Witting, Philos. Trans. R. Soc. London Ser. A 365, 273 (2007). 16. B. Jones, I. D. Walker, IEEE Trans. Robot. 22, 45 (2006). 17. R. Pfeifer, F. Iida, G. Gomez, Int. Congress Ser. 1291,22 (2006). 18. A. J. Ijspeert, A. Crespi, D. Ryczko, J.-M. Cabelguen, Science 315, 1416 (2007). 19. S. Hirose, E. F. Fukushima, Int. J. Robot. Res. 23, 341 (2004). 20. M. Sitti, IEEE Robot. Autom. Mag. 14, 53 (2007). 21. M. Fend, S. Bovet, R. Pfeifer, Robot. Auton. Syst. 54, 686 (2006). 22. H. Kimura, Y. Fukuoka, A.-H. Cohen, Int. J. Robot. Res. 26, 475 (2007). 23. K. Dautenhahn, Philos. Trans. R. Soc. London Ser. B 362, 679 (2007). 24. Y. Kuniyoshi et al., in Embodied Artificial Intelligence, F. Iida, R. Pfeifer, L. Steels, Y. Kuniyoshi, Eds. (Springer- Verlag, Berlin, 2004), pp. 202–218. 25. F. Pfeiffer, H. Inoue, Eds., Philos. Trans. R. Soc. London Ser. A 365, 3 (2007). 26. J. F. V. Vincent, O. A. Bogatyreva, N. R. Bogatyrev, A. Bowyer, A.-K. Pahl, J. R. Soc. Interface 3, 471 (2006). 27. R. A. Brooks, Science 253, 1227 (1991). 28. M. Merleau-Ponty, Phenomenology of Perception, C. Smith, Transl. (Routledge and Kegan Paul, London, 1962). 29. F. J. Varela, E. Thompson, E. Rosch, The Embodied Mind (MIT Press, Cambridge, MA, 1991). 30. G. A. Bekey, Autonomous Robots—From Biological Inspiration to Implementation and Control (MIT Press, Cambridge, MA, 2005). 31. J.-A. Meyer, A. Guillot, in Springer Handbook of Robotics, B. Siciliano, O. Khatib, Eds. (Springer-Verlag, Berlin, 2008), chap. 60. 32. R. Reeve, B. Webb, A. Horchler, G. Indiveri, R. Quinn, Robot. Auton. Syst. 51, 41 (2005). 33. J. L. Krichmar, D. A. Nitz, J. A. Gally, G. M. Edelman, Proc. Natl. Acad. Sci. U.S.A. 102, 2111 (2005). 34. The term “sensory-motor coordination” goes back to John Dewey, who pointed out in 1896 that perception results from the coupling of acting and sensing; for applications to robotics, see (53). 35. R. Blickhan et al., Philos. Trans. R. Soc. London Ser. A 365, 199 (2007). 36. S. Grillner, Neuron 52, 751 (2006). 37. S. Alben, P. G. Madden, G. V. Lauder, J. R. Soc. Interface 4, 243 (2007). 38. K. Autumn, Am. Sci. 94, 124 (2006). 39. C. C. Kemp, A. Edsinger, E. Torres-Jara, IEEE Robot. Autom. Mag. 14, 20 (2007). 40. A. Billard, S. Schaal, Eds., Neural Netw. 19, 251 (2006). 41. M. Lungarella, G. Metta, R. Pfeifer, G. Sandini, Connect. Sci. 15, 151 (2003). 42. S. Thrun, W. Burgard, D. Fox, Probabilistic Robotics (MIT Press, Cambridge, MA, 2005). 43. M. Arbib, G. Metta, P. van der Smagt, in Springer Handbook of Robotics, B. Siciliano, O. Khatib, Eds. (Springer-Verlag, Berlin, 2008), chap. 62. 44. S. Nolfi, D. Floreano, Evolutionary Robotics: The Biology, Intelligence, and Technology of Self-Organizing Machines (MIT Press, Cambridge, MA, 2000). 45. H. Lipson, J. Pollack, Nature 406, 974 (2000). 46. The level of abstraction at which ontogenetic development is studied here is the cellular and gene-based communication networks, whereas in the field of cognitive robotics, it is the entire individual or the interaction between individuals. 47. F. Hara, R. Pfeifer, Morpho-Functional Machines—The New Species: Designing Embodied Intelligence (Springer-Verlag, Tokyo, 2003). 48. M. Yim et al., IEEE Robot. Autom. Mag. 14, 43 (2007). 49. G. Whitesides, B. Grzybowski, Science 295, 2418 (2002). 50. E. Tuci et al., ACM Trans. Auton. Adaptive Syst. 1, 115 (2006). 51. D. Floreano, S. Mitri, S. Magnenat, L. Keller, Curr. Biol. 17, 514 (2007). 52. S. Rasmussen et al., Science 303, 963 (2004). 53. R. Pfeifer, C. Scheier, Robot. Auton. Syst. 20, 157 (1997). 54. R.P. and M.L. thank the European Union (EU) project no. IST-2004-004370 (RobotCub), the EU Future Emerging Technologies (FET) project FP6-002035 (PACE), and the Swiss National Science Foundation (SNF) (grant 200021- 109210/1). F.I. was supported by a Swiss SNF Fellowship for Prospective Researchers (grant PBZH2-114461). Supporting Online Material www.sciencemag.org/cgi/content/full/318/5853/1088/DC1 Table S1 References 10.1126/science.1145803 www.sciencemag.org SCIENCE VOL 318 16 NOVEMBER 2007 1093 SPECIALSECTION on April 3, 2008 www.sciencemag.orgDownloaded from","libVersion":"0.3.2","langs":""}