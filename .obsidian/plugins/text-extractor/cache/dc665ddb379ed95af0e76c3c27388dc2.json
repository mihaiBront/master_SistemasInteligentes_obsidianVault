{"path":"_aula_virtual/SJK006/4. Prompt Engineering for Data Science.pdf","text":"PROMPT DATA ENGINEERING SJK006 - Master in Intelligent Systems Learning goals ‚óè What natural language processing (NLP) is? ‚óè What a language model is? ‚óè Transformers: Encoders and Decoders ‚óè Automatic generation of texts and code ‚óè Instructed large language models ‚óè Practice with chatGPT over Data Science problems 2 CHATBOTS Natural Language Processing Tasks Named Entity Recognition (NER) Textual Entailment Text ClassiÔ¨Åcation Sentiment Analysis Coreference Resolution Machine Translation Natural Language Understanding (NLU) Natural Language Generation (NLG) Word Sense Disambiguation Question Answering (QA) Summarization Discourse Analysis Part Of Speech PoS Segmentation Parsing SYNTAX SEMANTIC-RELATED TASKS DISCOURSE Speech to text Language models (GPT-family) GPT is a Transformer decoder aimed at completing word sequences: GPT training ‚Üí p(w i| w 0, ... , w i-1 ) ‚Üí discrete conditional distribution of tokens REPEAT Predict the next token with the learnt model, add it to the current sequence STOP if the sequence has a given length or if the sequence probability drops notably. How tokens are chosen to generate a highly probable sequence? ‚óè Greedy strategy: get always the most likely next token ‚óè Beam Search : at each step keep the most likely k partial sequences and return the most likely one when the prediction stops ‚óè Softmax temperature : we can add a hyperparameter (ùûΩ) to the output discrete distribution to smooth it (creativity/hallucination). 4 Beam Search Figure from: https://medium.com/voice-tech-podcast/visualising-beam-search-and-other-decoding-algorithms-for-natural-language-generation-fbba7cba2c5b score(y 1...y t) = ‚àë i=1‚Ä¶t log P(y i|y 1‚Ä¶y i-1, x) 5 Large language models (LLM) ‚óè Enormous pre-trained models with masking task (decoder-only) ‚óã GPT-2, GPT-3, GPT-3.5, GPT4 (Open AI) ‚óã LLAMA 3 (Meta, open source) ‚óã Gemini, Gemma (Google) ‚óã Claude (Antrhopic) ‚óã Falcon (Open source) ‚óè All of them have more than 109 parameters (billions), the size usually is included in the name of the model (e.g. Falcon-7B, Falcon-13B). ‚óè This models capture a lot of semantic and causality patterns of the common sense and specialised domains. ‚óè The main task/purpose of these models is to ‚Äúcomplete‚Äù an initial text, which is called PROMPT. ‚óè Instruct models have been trained to guide the completion according to a series of orders about the length, content, constraints, etc. ‚óè The PROMPT can include a few examples of what we want to get (few shot learning) 6 https://lmarena.ai/ https://openlm.ai/chatbot-arena/ 7 Instructed LLMs ‚óè Instructed models are LLMs that have been trained to complete instructions (PROMPT) ‚óè chatGPT, Llama-2 and Bard are instructed models. ‚óè Outputs of these models have been supervised by humans through a mechanism called Reinforcement Learning from Human Feedback (RLHF). ‚óè Instructed LLMs are aimed at reduce hallucinations (false predictions) and maximise the alignment with the ethical and legal principles of humans. ‚óè The main limitation of some LLMs are the prompt and output sizes. (~ 4K-8K tokens) ‚óã We are forced to retrieve the relevant information to be included in the PROMPT ‚óã We need to integrate LLMs with other existing tools (LANGUAGE CHAINS and Plugins) to complement each other 8 Basic principles of prompting (chatGPT) 9 C I O R V Context: describe without ambiguities the scenario and intent of the prompt Input: what is being used as input Output: which is the desired output format (text, JSON, CSV, etc.) Few shot: write some few examples of input/ouput Rephrase: adjust the prompt to be more precise about the intent and the output (errors in the output). Validate: detect errors, show them to the agent and find alternative outputs. Identify parameters to re-use the prompt at scale! Ways to use prompting for data science PROMPT CODE PROMPT REPORT DATA PROMPT CODE SCHEMA PROMPT TASKS SCHEMA CODE PROMPT DESCRIBE SCHEMA SCHEMA PROMPT Enriched Data DATA PROMPT CODE SCHEMA PROMPT DATA REPORT (ETLing) 10 PROMPT DATA Prompt beyond QA: explain & problem solving 11 PROMPT ANSWER PROMPT (step by step) Chain of Thought ANSWER PROMPT (step by step) Chain of Thought ANSWER Validate PROMPT (step by step) Tree of Thought (Tree Search) ANSWER Tree of ThoughtsChain of Thoughts (step-by-step) https://lmql.ai/ PROMPT LMQL (Query) ANSWER 12 LET‚ÄôS PRACTICE PROMPTING FOR DATA SCIENCE!","libVersion":"0.3.2","langs":""}