{"path":"_aula_virtual/SJK002/SJK002-U8-InterestPoints-Bow.pdf","text":"SJK002 Computer VisionMaster in Intelligent Systems2U8. Interest Points. BoWIndexInterestpointsInterestpoints. CornersCorners. Harris detectorCorners. Scaleinvariance: DoGPatchdescriptorsSIFT descriptorBag of visual Words(BoW)BoW. Object/Imagerecognition3Interest pointsU8. Interest Points. BoWInterest points extracted with Harris detector (~ 500 points)4Interest pointsExtract interest points.Characterize interest points.U8. Interest Points. BoWHow can we find corresponding interest points?5Interest pointsSuppose you click on some points.Look now at the deformed image.Try to select the same points.Which points would you choose?U8. Interest Points. BoWdeformed6Interest points. CornersRecognize points from neighborhood (window)Shifting a window in any direction should give large changes in intensity.U8. Interest Points. BoW“edge”:no change along the edge direction“corner”:significant change in all directions“flat”region:no change in all directions7Interest points. CornersGradient distributionsU8. Interest Points. BoW8Interest points. CornersU8. Interest Points. BoWPrincipal component is the direction of highest variance.PCA components:1.Subtract off the mean for each data point.2.Compute the covariance matrix.3.Compute eigenvectors and eigenvalues.4.The components are the eigenvectors ranked by the eigenvalues.9Interest points. CornersU8. Interest Points. BoWBotheigenvaluesare large10Corners. Harris detectorHarris matrix: second moment matrixU8. Interest Points. BoW2 x 2 matrix of image derivatives smoothed by Gaussian weights.=w(x,y)x,yåIxIxIxIyIxIyIyIyéêùûúúxIIx∂∂⇔yIIy∂∂⇔yIxIIIyx∂∂∂∂⇔First compute Ix, Iy, and IxIyas 3 images; then apply Gaussian to each.H11Corners. Harris detectorCompute the Harris matrix over a window:Compute eigenvalues of HU8. Interest Points. BoWTypicallyGaussianweigths12Corners. Harris detectorComputing eigenvalues are computationally expensive.Alternative, approximation.Response function R (Harris and Stephens, 1988) :Simpler Response function:U8. Interest Points. BoWf=11λ1+1λ2=Det(H)Tr(H)13Corners. Harris detectorHarris detector algorithm:•Compute derivatives Ix, Iyand IxIyat each pixel and smooth them with a Gaussian.•Compute the Harris matrix H in a window around each pixel •Compute corner response function R•Threshold R•Find local maxima of response function (non-maximum suppression)U8. Interest Points. BoW14Corners. Harris detectorOriginal imagesU8. Interest Points. BoW15Corners. Harris detectorCorner response function RU8. Interest Points. BoW16Corners. Harris detectorCorner response threshold: R>ThresholdU8. Interest Points. BoW17Corners. Harris detectorLocal maxima of RU8. Interest Points. BoW18Corners. Harris detectorResultsU8. Interest Points. BoW19Corners. Harris detectorProperties:•Translation invariant•Rotation invariant•Noscale invariant !U8. Interest Points. BoWCorner cannot be detected at this window scaleCorner at this window scaleAll points will be classified as edges20Corners. Scale invariance: DoGDetecting interest points independently from scales.Use the Lapacianoperator across different scales.U8. Interest Points. BoW)),(( )),((11σσ′′=xIfxIfmmiiiiKK21Corners. Scale invariance: DoGThe LapacianoperatorU8. Interest Points. BoWCharacterizes difference between inside and outside the target circle at a given scale σ22Corners. Scale invariance: DoGScale characterization:•Use of a Gaussian•It is invariant to scale change,•Other properties (Lindeberg, 1994).In practice:•The Lapaciancan be approximated by a Difference of Gaussians (DoG)U8. Interest Points. BoW23Corners. Scale invariance: DoGDifference-of-Gaussians (DoG)U8. Interest Points. BoW-=G1 G2 DoG24Corners. Scale invariance: DoGDoGU8. Interest Points. BoWσ = 1σ = 66ApplyGaussiansat multiplescalesand use DoG25Corners. Scale invariance: DoGU8. Interest Points. BoWσ1σ1σ1σ1σ2σ2σ2σ2σ3σ3σ3σ3σ4σ4σ4σ4σ5σ5σ5σ5List of (x, y, σ)scaleApply Gaussians with different σ’sLook for local maxima in DoGInterestpointsare local máxima in bothposition and scale26Corners. Scale invariance: DoGIn practice the image is down-sampled for larger σ’sU8. Interest Points. BoW(Lowe, 2004)s+2DoGimagess+2 Gaussian filterss+3 images, including original27Corners. Scale invariance: DoGDetect maxima and minima of DoGin scale-spaceEach point is compared to its 8 neighbors in the current image,and 9 neighbors each in the scales above and belowU8. Interest Points. BoWFor each max or min found, output is the location and the scale.s+2 difference images.top and bottom ignored.s planes searched.28Corners. Scale invariance: DoGInterest points detected with its corresponding scale.U8. Interest Points. BoW29Corners. Scale invariance: DoGApplication example: finding correspondences.U8. Interest Points. BoWSimilarity transformNeedinterestpointscharacterizationComputepatchdescriptors30Patch descriptorsPatches with similar content should have similar descriptor values.U8. Interest Points. BoW31Raw patches descriptorSimplest way to describe the neighborhood around an interest point is to use the neighbor/patch intensities to form a feature vector.Drawbacks, very sensitive:•Change of scale, rotation, shifts, intensity changes, …U8. Interest Points. BoW32SIFT descriptorDivide the 16x16 window into a 4x4 grid of cells(2x2 in figure below)Compute an orientation histogram for each cell16 cells * 8 orientations = 128 dimensional descriptorU8. Interest Points. BoW33SIFT descriptorU8. Interest Points. BoW8 8 . . . 8 Divide the 16x16 window into a 4x4 grid of cellsCompute an orientation histogram for each cell16 cells * 8 orientations = 128 dimensional descriptorOrientations in each pixel of the cell11 orientations in one bin, 5 in the other bin.34SIFT descriptorU8. Interest Points. BoW0.2such thatDivide the 16x16 window into a 4x4 grid of cells(256 pixels)Compute an orientation histogram for each cell16 cells * 8 orientations = 128 dimensional descriptorThreshold and normalize the descriptor35SIFT descriptorProperties:•Very robust to perform matching•Can handle changes in viewpoint•Up to about 30 degree out of plane rotation•Can handle significant changes in illumination•Fast and efficient. Can run in real timehttp://www.cs.ubc.ca/~lowe/keypoints/U8. Interest Points. BoW36SIFT descriptorExample: interest points for image stitching.U8. Interest Points. BoWDetectinterestpointsin bothimages37SIFT descriptorU8. Interest Points. BoWFindpairsof correspondingpointsFromcorrespondingpointscalculatetransformation(e.g. homography) and alignimages.38Other interest point descriptorsDaisy(Winder et al, 2009): circular gradient binningSURF(Bay et al, 2006): 4-bins gradient histogramU8. Interest Points. BoW39Other interest point descriptorsTexture features of a patch can be considered a descriptor.Example: Local Binary Pattern (LBP) histogram is a texture descriptor for a patch/image.U8. Interest Points. BoW40Descriptors and matchingMatchingimage patches:Distance(similarity) measure between patches:•Sum of square differences•Ratio distance: f’2is 2ndbest SSD match of f1 Avoid false matches: use distance thresholdU8. Interest Points. BoW\u0000\u0000\u0000\u0000\u0000\u0000,\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000,\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000,\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000,\u0000\u0000\u0000\u0000 41Bag of visual wordsImage representation.U8. Interest Points. BoWBag of visual words representing an image ...... for detection or recognition tasks.42Origin: Bag of Words (BoW)Order-lessdocument representation: frequencies of wordsfrom a dictionary (Salton & McGill , 1983)U8. Interest Points. BoW Frequency…Vocabulary43Origin: texture recognitionTexture characterized by repetition of basic elements or textonsFor stochastic textures, it is the identity of the textons, not their spatial arrangement, that mattersU8. Interest Points. BoW44Origin: texture recognitionU8. Interest Points. BoW45Bag of visual wordsExtract feature patchesLearn vocabularyU8. Interest Points. BoW46Bag of visual wordsQuantize features using visual vocabularyRepresent images by frequencies of “visual words”U8. Interest Points. BoWVisual vocabulary47BoW. Feature extractionU8. Interest Points. BoWRegular grid(Vogel & Schiele, 2003) (Fei-Fei& Perona, 2005)Interest point detector (Csurkaet al. 2004)(Fei-Fei& Perona, 2005)(Sivicet al. 2005)Other methodsRandom sampling (Vidal-Naquet& Ullman, 2002)Segmentation-based patches (Barnard et al. 2003)48BoW. Feature extractionU8. Interest Points. BoWNormalize patchDetect patches(Mikojaczykand Schmid, 2002)(Mata, Chum, Urban & Pajdla, 2002)(Sivic& Zisserman, 2003)Compute SIFT descriptor(Lowe, 1999)49BoW. Feature extractionU8. Interest Points. BoW…FeaturesShowing only 2x2 here but is 4x4(Lowe, 1999)50BoW. Learning the visual vocabularyU8. Interest Points. BoW…Features51BoW. Learning the visual vocabularyU8. Interest Points. BoW…FeaturesClustering52BoW. Learning the visual vocabularyU8. Interest Points. BoWClusteringVisual vocabulary…Features53BoW. Learning the visual vocabularyk-means•Minimize sum of squared Euclidean distances between points xiand their nearest cluster centers mkRandomly initialize kcluster centersIterate until convergence:•Assign each data point to the nearest center•Re-compute each cluster center as the mean of all points assigned to itU8. Interest Points. BoWåå−=kkikimxMXDclusterclusterinpoint2)(),(54BoW. Learning the visual vocabularyClustering is a common method for learning a visual vocabulary or codebook•Unsupervised learning process•Each cluster center produced by k-means becomes a codevector•Codebook can be learned on separate training set•Provided the training set is sufficiently representative, the codebook will general enough.The codebook is used for quantizing features•A vector quantizertakes a feature vector and maps it to the index of the nearest codevectorin a codebook•Codebook = visual vocabulary•Codevector= visual wordU8. Interest Points. BoW55BoW. Learning the visual vocabularyU8. Interest Points. BoW…Image training setSet of image patches: featuresVisual vocabulary: appearance codebook Visual words56BoW. Image representationU8. Interest Points. BoW….. frequencyVisual words57BoW. Vocabulary sizeHow to choose vocabulary size?•Too small: visual words not representative of all patches•Too large: quantization artifacts, overfittingComputational efficiency•Vocabulary trees (Nister& Stewenius, 2006)U8. Interest Points. BoW58BoWextesions. Spatial layoutU8. Interest Points. BoWAll of these images have the same color histogram59BoWextesions. Spatial layoutU8. Interest Points. BoWCompute histogram in each spatial bin60BoW. Spatial pyramid representationExtension of a bag of featuresLocally order-less representation at several levels of resolutionU8. Interest Points. BoWlevel 0(Lazebnik, Schmid& Ponce, 2006)61BoW. Spatial pyramid representationU8. Interest Points. BoWlevel 0level 1(Lazebnik, Schmid & Ponce, 2006)Extension of a bag of featuresLocally order-less representation at several levels of resolution62BoW. Spatial pyramid representationU8. Interest Points. BoWlevel 2level 0level 1(Lazebnik, Schmid& Ponce, 2006)Extension of a bag of featuresLocally order-less representation at several levels of resolution63BoW. Object/Image recognitionGiven the BoWrepresentations of images from different classes:•How do we learn a model for distinguishing them?U8. Interest Points. BoWFace imageBike imageViolin image64BoW. Object/Image recognitionU8. Interest Points. BoW65BoW. Object/Image recognitionU8. Interest Points. BoWZebraNon-zebra66BoW. Object/Image recognitionLearn a decision rule (classifier) assigning BoWrepresentations of images to different classes:•SVM, k-NN, decision trees, …U8. Interest Points. BoWZebraNon-zebraDecisionboundary67BoW. Other applicationsHuman action recognitionU8. Interest Points. BoWSpace-time interest points(Niebles, Wang and Fei-Fei, 2008)","libVersion":"0.3.2","langs":""}