{"path":"_aula_virtual/SJK001/Reading Assessments/[Jian21].pdf","text":"Signal Processing: Image Communication 91 (2021) 116088 Contents lists available at ScienceDirect Signal Processing: Image Communication journal homepage: www.elsevier.com/locate/image Underwater image processing and analysis: A review Muwei Jian a,b,c,∗, Xiangyu Liu a, Hanjiang Luo d, Xiangwei Lu a, Hui Yu c,∗∗, Junyu Dong e a School of Computer Science and Technology, Shandong University of Finance and Economics, Jinan, China b School of Information Science and Engineering, Linyi University, Linyi, China c School of Creative Technologies, University of Portsmouth, Portsmouth, UK d School of Computer Science and Technology, Shandong University of Science and Technology, Qingdao, China e Department of Computer Science and Technology, Ocean University of China, Qingdao, China A R T I C L E I N F O Keywords: Underwater image Marine environment Underwater saliency detection Color constancy A B S T R A C T With increasing attentions being drawn to the underwater observation and utilization of marine resources in recent years, underwater image processing and analysis have become an active research hotspot. Different from the general images, marine environment is usually faced with some complicated situations such as underwater turbulence and diffusion, severe absorption and scattering of water body, various noises, low contrast, uniform illumination, monotonous color, complex underwater-background. In response to these typical challenges, a large body of works in underwater image processing has been exploited in recent years. This survey introduces a review of existing relatively mature and representative underwater image processing models, which are classified into seven categories including enhancement, fog removal, noise reduction, segmentation, salient object detection, color constancy and restoration. We then objectively evaluate the current situations and future development trend of underwater image processing, and provide some insights into the prospective research directions to promote the development of underwater vision and beyond. 1. Introduction Ocean occupies for 70 percent of the earth and contains rich natural resources, which has been a long-term and enduring concern for human development. With the rapid progresses of the marine exploitation and observation, there is increasing interests in the exploring this mysterious area of the ocean. However, confronted with relatively hash and unconstrained marine scenes, many severe adverse factors, include water with high turbidity, uneven illumination, monotonous color, complicated underwater-background, which seriously affect the integrity and availability of underwater image in practical application. In order to tackle with these issues, many relevant underwater- vision researches have been conducted on exploring mature and effec- tive underwater image processing (UIP) models in recent decades. In this review, we will discuss the processing and analyzing methods of underwater images, containing both traditional methods and recently emerged models of deep-learning. Especially, underwater image - en- hancement, - fog removal, - segmentation, - noise reduction, - saliency detection and - color constancy under marine environment will be discussed in detail. The cardinal contents of this review are summarized in the below: ∗ Corresponding author at: School of Computer Science and Technology, Shandong University of Finance and Economics, Jinan, China. ∗∗ Corresponding author. E-mail addresses: jianmuweihk@163.com (M. Jian), hui.yu@port.ac.uk (H. Yu). • A relatively comprehensive review of underwater image process- ing is conducted to categorized off-the-shelf models into seven sub-classes; • Some publicly accessible underwater-image data sets used in the literatures are presented; • The main problems and challenges in the underwater vision field are discussed along with some suggestions for future investigation of underwater image processing. The reminder of this survey is presented as below. Section 2 in- troduces the representative frameworks on different underwater image processing (UIP) and analysis approaches. Section 3 introduces the designed system at length. Then the challenges and future suggestions are presented in Section 4. Finally, a conclusion will be given in Section 5. 2. Review of underwater image processing and analysis models In the past, various underwater vision systems have been designed to handle and ameliorate the visual quality of underwater images. Gen- erally, underwater image processing (UIP) and analysis frameworks can be classified into seven representative types in terms of the respective target. Fig. 1 illustrates the diagram of the underwater image processing https://doi.org/10.1016/j.image.2020.116088 Received 26 March 2020; Received in revised form 12 October 2020; Accepted 27 November 2020 Available online 1 December 2020 0923-5965/© 2020 Elsevier B.V. All rights reserved. M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 and analysis framework. In the following sections, we will describe the details of each individual category. 2.1. Underwater image enhancement Underwater image enhancement aims to improve visual perception and the applicability of an underwater image according to peculiar or specific application occasions. More specifically, the ultimate purpose is to strengthen the visual appearance of the original underwater images so as to emphasize the whole or partial related image characteristics based on the tangible application goal [1]. For instance, disposing of blurred images under a water body condition with serious turbidity becomes clearer or highlighting the underwater image characteristics of the targeted object under a poor lighting condition to satisfy some special analysis purposes. By modeling the image enhancement as a process of distortion, Liu et al. [2] proposed a reliable image-enhancement method based on adversarial deep networks for underwater images. In [3], Zhang et al. presented a real-time underwater image enhancement procedure via a color constancy-based scheme. They utilized the integration of bilateral as well as trilateral filters to achieve enhancement, which extended the retinex framework for a higher performance. Compared with re- cent deep learning-based solutions, that approach demonstrates a high performance in both stability and generalization with a minimized computation cost. Through combining an improved retinal algorithm with a neural network, an underwater image enhancement algorithm was developed to improve the reconstruction effect of object edges along with texture details [4]. In [5], He et al. presented an image enhancement model according to the color transfer theory, as well as an efficient pulse-coupled neural network (PCNN) was applied to simul- taneously ameliorate the visual appearances in the darker regions, with the aim of improving the contrastive effect in the original underwater image. Faced with the underwater environment, when light spreads in the water, the effect of absorption and scattering usually leads to nega- tive influences on underwater imaging, such as under-exposure, short- tempered color distortion [6]. To tackle these problems, Fu et al. [7] designed a helpful image enhancement model in terms of correction strategies focusing on the color distortion problem, and then em- ployed a neural network to improve the reflectivity and intensity of illumination for generating the final enhanced underwater image. Lu et al. [8] devised a guided triangular bilateral filter enhancement model to remedy the major reduction with the purpose of solving the image degradation attributed to the color distortion, absorption and scattering of water. This automatic color enhancement algorithm can significantly reduce the noise level and better exposes the dark area in underwater scene. Later, Lu et al. [9] designed a contrastive underwater enhancement framework by exploiting a color correction scheme with a local adaptive filtering for spectral features to recover the distorted color. This framework can generate underwater images with a holistic enhancement while maintaining the local characteristics of the target. In [10], in light of maximum information-retention mechanism, Li et al. exploited a contrast enhancement algorithm for underwater images via restoring their intrinsic visibility. It implied a transcendentally contrastive enhancement procedure in view of histogram distribution to highlight the shadows and brightness of the underwater image. By adapting color balance to the basis of biasness rectification and the mean luminance, Park et al. [11] introduced an effective model for improving the visual effects so as to decrease noises in the enhanced images while intending to keep color fidelity. To adjust the under- water camera images clearer, Li et al. [12] developed an underwater image enhancement framework, with the aid of an adaptive light color channel and a de-noising method to alleviate noise and thus improve low-illumination image to produce clearer visual appearance. In [13], Khan et al. described a restoration enhancement approach for degraded underwater images by reducing blurring effects and enhances color and brightness of the underwater images. Recently, Li et al. [14] proposed a reliable underwater image enhancement network (water-net) and an Underwater Image Enhancement Benchmark for promoting underwater vision development. In the recent past, Liu et al. [15] developed a credible under- water image enhancement framework in accordance with an itera- tive scheme by generating hybrid image layer propagation. In that depth model, the priors of multiple depth training were integrated into the task. In [16], Hou et al. developed an effective depth-oriented model for underwater image enhancement with the assistance of resid- ual structure estimation and lighting equilibrium. Similar to [17], Zhang et al. [18] presented an underwater image enhancement so- lution through a color constancy-based scheme, which extended the retinex framework for a higher performance. Compared with recent deep learning-based solutions their approach still demonstrates a high performance in both stability and generalization with a minimized com- putation cost. More recently, with the assistance of underwater scene prior, a video and image enhancement framework [19] was designed to generate clear underwater frame/video rather than reckoning the parameters of underwater attenuation model. 2.2. Underwater image noise reduction Various noises are commonly emerged in the process of underwa- ter image capturing and transmitting, which are often caused by the camera/sensor equipment and the different severe underwater environ- ments. Due to the influence of image/video acquisition devices, poor illumination quality, serious optical wavelength scattering/absorption and high water turbidity, the noises of the underwater image are always more complex than normal natural images, therefore noise reduction for underwater images is a very important category in underwater image processing. For the sake of ameliorating the visual appearance of underwater images as well as reducing the background noises, many effective noise reduction models for underwater images have been explored in last several decades. Corrigan et al. [20] presented a mosaicing procedure for underwater videos, which used a time smoothing prior in motion parameters to reduce noise to max the posterior homography assessment calcula- tion method, so as to obtain a small amount texture details. Anwer et al. [21] proposed a prime refraction rectification model, which is able to effectively reduce the noises and eliminate distortions in the acquired underwater image. In the interest of conquering the limitation of the underwater imaging due to absorption and scattering, Zhou, etc. [22] proposed a combinational model on the strength of cosine similarity to tackle the problem of water turbidity of uncertainty. On the other hand, refraction, uneven homogeneity of light sources and objects’ shade are also the fundamental causes of underwater image noises. Therefore, reducing or eliminating their impact has become a primary task for the noise reduction of underwater images. Elnashef and Filin [23] described a model by separating non-refraction sets to reduce the adverse effects of refraction in underwater images. Lu et al. [24] developed a noise reduction framework in terms of self- similarity for underwater noise reduction and super-resolution. In this framework, they proposed a super-resolution algorithm to dispel noise of underwater images with high turbidity, which has indicated that the reconstructed high resolution (HR) image after denoising processing with reasonable noise level can be generated. Sun et al. [25] introduced a rapid underwater image enhancement algorithm according to the depth-pixel network framework through employing the skip connection to prevent visual details erosion during the enhancing process. 2.3. Underwater images defogging The excellency of underwater images is seriously under the in- fluence of the underwater light propagation mechanism and imaging devices, such as light absorption, attenuation and backscatter. Light 2 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 Fig. 1. Diagram of underwater image processing (UIP) and analysis. scattering is the main cause of generating blurry and fuzzy image [26– 28], with a goal of guaranteeing the sharpness of the underwater image, it is very important to dispose of such images. Currently, defogging methods are not effective due to poor under- standing of its underlying light transmission mechanisms. Emberton et al. [26] presented an efficient fog-removing algorithm for underwa- ter images, which exploits a type of target estimation with cover light and transmission light to cope with defogging problem. In [27], Skinner and Matthew introduced an underwater image dehazing method to capture the spatial distribution and the angle of images by using light field camera. In this method, each sub-aperture input is initially de- fogged into two dimensions and then combined together to generate a smooth central view output in the controlled underwater circumstance. In [29], Ancuti et al. designed an underwater image defogging model by correcting contrast and sharpening the white balance to alleviate the defogging effect. In practice, it is still a challenge for present underwater processing techniques to tackle illumination dispersion and chrominance distor- tions [17,30]. In view of this issue, Chiang et al. [30] proposed a systematic framework to improve the visual quality via applying a dehazing procedure which compensates the decay during the propa- gation process. In their scheme, the foreground and background in the input are separated. And then an artificial light source is adopted to compensate and enhanced the image in the dehazing procedure. Deng et al. [31] exploited a useful underwater image enhancement approach through combining color removal of the light source with fog removal. By considering the attenuation in various illumination circumstances, the initial image could be defogged with scene depth estimation. In or- der to enhance the appearance of underwater images, Chiang et al. [32] introduced an effective defogging approach based on dark channel clue, which was used to eliminate the haze effect in the original underwater image. Li et al. [33] designed an efficient framework based on an integrated regression model for underwater image dehazing by integrating chrominance rectification and defogging scheme together to strengthen the contrastive effect of the original input. More recently, Liu et al. [34] designed a new residual architecture that combined the original residual architecture (i.e., domain knowledge) and transmitted information for scene brightness estimation for haze removal with a flexible optimization scheme. 2.4. Underwater image segmentation Underwater image segmentation concentrates on separating the source input into individual and non-overlapping portions, which is a fundamental and critical step for image analysis and understanding. In recent years, plenty of underwater image segmentation models have been investigated. Although these general image segmentation technologies have been widely exploited, these models may be unsuitable or inapplicable to the underwater environment. This is one of the main reasons that un- derwater image segmentation technologies lag behind the conventional segmentation. When traditional methods are applied to underwater im- age processing, the object area generally cannot be precisely located, so that the details and shapes of the object will be lost and distorted [35, 36]. To address this deficiency, Chen et al. [35] constructed a new method for underwater target segmentation by modeling the effect of fog haze of underwater image, in which edge level transmission characteristics and regional level significant clues are mixed together with the formula of level set. Based on the statistical property of gray image histogram, Wang et al. [37] proposed an effective fuzzy C- means approach based on particle swarm optimization for underwater optical division. Zhang et al. [36] combined the characteristics of underwater images according to fractal theory, and then proposed an underwater segmentation method assisted by the Brownian random field. Li et al. [38] proposed an efficacious framework to cope with separating large-scale underwater images. In this method, an iterative MapReduce procedure is designed to enhance the efficiency of the algo- rithm. In accordance with the principle of minimum entropy loss, Wang et al. [39] devised a deep neural network framework in order to divide underwater images into several regions via a gradient optimization algorithm. 3 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 The refraction and scattering of light in water affect all aspects of underwater image processing, and also cause serious obstacles to underwater image segmentation. Therefore, it is always a formidable challenge to weaken or even eliminate the adverse effects of light. Based on the level set method, Chen et al. [40] proposed a feature- extraction oriented model through removing background noises and highlighting the outline of underwater objects. This method can pre- serve the contour of underwater objects during underwater image segmentation. Zhu et al. [41] designed a detection algorithm based on clustering to highlight significant areas in underwater images. On this basis, a statistical active contour approach on the basis of regional level set has proposed to segment underwater images. This model is capable of generating satisfactory effects on underwater image segmentation in terms of efficiency and quality. Rai et al. [42] presented a rapid underwater segmentation approach to separate the object of interest, while the global visual effect was improved via a contrastive histogram flattening algorithm. 2.5. Underwater image saliency detection The human perception system has the congenital capability to effi- ciently distinguish and perceive salient objects in images or videos [14, 43,44]. This visual attention mechanism is effective and intelligent by focusing on useful information of the visual scene understanding in natural environments as humans automatically process the areas of interest and selectively ignore the areas not concerned. In the underwater computer vision and image processing domain, saliency detection is intended to equip computers with the ability of human beings to comprehend underwater scenes, which also plays a crucial role in exploring marine resources. Therefore, plenty of underwater saliency detection models have been designed recently. Because of the uncertainty of underwater environment, it is a chal- lenge to detect the salient objects from underwater images via tra- ditional saliency detection methods. The diversity and complexity of underwater environment has been induced widespread research in- terest lately. Xu et al. [45] developed a novel approach for under- water target recognition in view of the generalized robust principal component analysis (GRPCA), which could extract the visual feature information from underwater images and was of great significance to the recognition and representation of subordinate images. Shen et al. [46] explored a useful underwater target layered background framework on account of a frog eye visual information perception and processing scheme, which is able to separate salient objects from the image background with object contour. Based on underwater image feature extraction and matching, Zhang et al. [47] developed a visual saliency detection model using a dark channel to remove haze. This modal is capable of ameliorating the visibility of underwater images with the aid of dark feature extraction. Chen et al. [48] proposed an effective knowledge-based weighted integration strategy for salient region detection by using underwater target extraction, which was propitious to the dispersibility of the illumination characteristics. Later, Chen et al. [49] also devised an underwater saliency detection model by considering both 2D and 3D depth clues together. In [50], Li et al. exploited an underwater image saliency detection framework in light of foreground extraction to solve the problems evoked by the low quality image with low contrast. By locating the geometric center using the Harris corner detection operator, a simple linear iterative clustering based procedure was devised via protruding the foreground object and weakening the background areas for underwater image saliency detection [51]. Chen et al. [52] designed a salient object detection approach with aid of a monocular vision sensor to identify underwater objects. In this approach, background noises were removed to refine the detection accuracy in underwater scenes. In [53], Chen et al. devised an efficient model by exploiting a super-resolution generative adversarial network to improve the visual effect of image for detecting and recognizing underwater objects. Sun et al. [54] proposed a convo- lutional neural network based model for underwater target recognition. Among their model, a weighted probability decision mechanism is applied to distinguish objects from low-contrast underwater images. In [55], Jian et al. developed a saliency-detection method through combining Quaternionic features and object contrastive cues. Experi- ments performed on the partial of the publicly available underwater image database [56] demonstrated the effectiveness of the method. With the aid of removing color aberration and enhancing contrast of underwater images, Zhang et al. [57] presented an underwater image saliency detection framework by using deformable convolutional networks. Softmax was applied to regress the feature information of each salient object so that the spatial location could be estimated. 2.6. Color constancy and color correction for underwater images Color constancy is a type of perceptual constancy, which tends to re- main relatively stable even for individual perception of familiar objects under different changes in illumination, lighting intensity and other conditions. Therefore, keeping color constancy is helpful for vision- based applications and is an important topic of underwater image processing. Since underwater vision is seriously affected by the optical wave attenuation and dispersion in water medium, the application and gener- alization of visual models are normally impaired. Li et al. [58] designed a supervised learning based color conversion algorithm for rectifying distortion of underwater images, which was assisted by a cyclically consistent network by relaxing the requirement for the training sets. To tackle the instability of the underwater color reconstruction model, Akkaynak and Treibitz [59] described a color correction model by controlling direct transmission coefficients of the underwater color reconstruction. To solve the problem of the local variable underwa- ter scene, Codruta et al. [60] exploited a framework to utilize color conversion and adjust color correction locally via the light attenuation level function of red channel estimation. And then, they applied the dark channel prior inversion to recover chrominance compensation. In [61], Nomura et al. depicted an effective color correction approach for underwater images in the basis of grayscale linear regression to capture different exposure time for color correction in underwater scene. To address the color conversion problem, Zhang et al. developed a helpful underwater image color correction framework in accordance with the retinex algorithm via light adjustment as well as gamma cor- rection [62]. Considering the absorption of various wavelengths often leads to color distortion in practice, Li and Cavallaro [63] proposed a color restoration method by compensating color wastage caused by the scene-to-camera interval so as to estimate the non-uniform background illumination [64] in underwater scene, which contributes to the progress of underwater vision 2.7. Underwater image recovery/restoration The purpose of underwater image restoration is the process of reconstructing or recovering degraded images caused by the adverse factors in the complex underwater environment, including camera and object relative motion, the optical imaging mechanism of underwater scattering, turbulence, distortion, spectral absorption and attenuation, etc. To eliminate the interference of medium light transmission radia- tion, Barros et al. [67] presented an efficient method to restore details of underwater images with aid of a light propagation physical model. In this model, they aimed to reduce the attenuation and degradation of the backward scattering field since scattering and water fluidity frequently cause severe influences on underwater imaging. Meanwhile, Chen et al. [68] established a degradation approach through estimating the turbulent degradation transfer factors during image recovery and reconstruction, the effect of the final outputs can be improved. Different from these underwater image recovery algorithms based on physi- cal models which contain several parameters, a biologically inspired 4 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 Table 1 Some publicly accessible databases for underwater image processing. Database name Introduction Provider Underwater image enhancement benchmark (UIEB) [65] UIEB contains 950 authentic underwater images, in which 890 include related references, while the remaining 60 have not provided ground-truth references. City university of Hong Kong Academic aim: Especially for underwater image enhancement. Marine underwater environment database (MUED) [56] MUED includes 8600 underwater images of 430 distinct categories of salient objects under complicated backgrounds and noises, diverse variety in pose, position, lighting, turbidity of water, etc. Shandong University of Finance and Economics; & Ocean University of China, Qingdao. Academic aim: Especially for underwater image saliency detection and object recognition. Real-time underwater image enhancement (RUIE) dataset [66] RUIE contains more than 4000 underwater real images, which is categorized into three subsets: Underwater Image Quality Subaggregate, Underwater Color Cast Subaggregate and Underwater higher-level task-driven Subaggregate. Dalian University of Technology Academic aim: especially for underwater image enhancement and object detection. image-restoration method is proposed in [69]. Halimi et al. [70] devel- oped an efficient strategy to enhance the quality of underwater images by jointly reconstructing depth and reflectivity of the original image via maximum marginal likelihood estimation. In [71], Ancuti et al. pro- posed an effective framework to strengthen the underwater visibility, which is in accordance with weight graphs to distinguish the areas with poor visibility so as to relieve the defects existing in the degraded input image. Based on polarimetric imaging, Hu et al. [72] developed an underwater image recovery method via estimating the backscatter in- tensity at different spatial positions. Although polarization mechanism can enhance visual quality in water medium, these existing models are prone to facing problems in obtaining the true distribution of polarization. In order to overcome the issue, Tian et al. [73] proposed a combined framework with aperture with polarimetric imaging to calculate radiation of underwater targets. To address the limitations of the priority-based approach, Wang et al. [74] proposed a transmission- estimation model by employing cross-layer connection to eliminate underwater artifacts as well to recover textural characteristics. In [75], Barbosa et al. also proposed a deep neural image-recovery method to improve the visual effect of underwater images via preserving local characteristics (e.g. edges and contours) of the images. To conquer the limitations of the complexity of underwater environment, Zhang and Peng [76] proposed an underwater medium transmission method via modeling the characteristics of underwater imaging and light source for image restoration. By transforming the underwater propagation mechanism into a transmission model, Wang et al. [77] designed a maximum attenuation identification framework through extracting the depth map from the degraded underwater image to realize underwater image restoration. According to the expansion and correction of dark channel clue, Li et al. [78] developed an underwater image recovery framework based on chrominance channel defogging to solve the prob- lem that the partially recovered image area is too dark or too bright. In [79], Li et al. also exploited an underwater image recovery model by estimating the global background light to enhance the brightness as well as visibility of underwater images. Recently, Fan et al. [80] presented a flat refraction model for underwater optical imaging to describe the geometric relation between the refracted image and the actual object, which can rebuild underwater 3-D shapes in laser trian- gulation and photometric stereo and thus can effectively correct the distortion in underwater 3D reconstruction. 3. Data sets for underwater image processing and analysis Because of underwater image processing is a newly emerging re- search direction in recent years, there are only a few data sets dedicated to underwater computer vision [56]. The fundamental reasons for this are listed below: (1) The scientific research of underwater image processing started relatively late, so the relevant underwater image data sets have not been paid enough attention. (2) Although academic researchers have currently noticed the im- portance of the underwater image database, it takes time to develop these kinds of dataset owing to the complicacy of the underwater circumstances and the high workload. (3) Owing to the diversity of underwater environment, the ground truths of various underwater images are very difficult to obtain and label manually. Table 1 summarized some existing typical databases, which can be publicly available for underwater image processing and analysis in detail. In particular, Underwater Image Enhancement Benchmark (UIEB) [65] contains a couple of corresponding subclasses with 890 pairs of original underwater images and reference images on a one-for-one basis, as shown in Fig. 2. Fig. 3 shows some samples of underwater images with high turbid- ity, uneven illumination, monotonous color, and complicated underwater-background from MUED [56], which seriously affect the integrity and availability of underwater image in practical application. Fig. 4 displays some images from Real-time Underwater Image Enhancement (RUIE) Dataset which is constructed via an underwater optical imaging and capturing system [66]. RUIE includes a triple of subclasses of underwater images with Underwater Image Quality Subaggregate, Underwater Color Cast Subaggregate and Underwater higher-level task-driven Subaggregate. 4. Challenges and future suggestions • The main purpose of this review is to summarize recent research, identify the problems and challenges in the related underwater image field and then intend to provide some insights and sugges- tions for the future direction. The following is a brief summary of the open problems and challenges, which will be conducive to the promotion of the progress of underwater image processing and thus attract attention to researchers in signal processing and computational intelligence. • Turbidity of underwater quality, light refraction, absorption and scattering in underwater environments are still the core factors affecting the effect of underwater image quality. Currently, most of the existing models are focused on one single factor listed above. In future research, multiple influencing factors can be considered comprehensively to enhance the quality of underwater images. 5 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 Fig. 2. Some examples from UIEB [65] with a couple of subclasses : (a) original underwater images, (b) corresponding reference images. Fig. 3. Some samples of adverse factors in the marine environment for underwater vision applications [56]. (a) Water with high turbidity, (b) uneven illumination, (c) low contrast, (d) complicated underwater-background, and (e) monotonous color.. Fig. 4. Some images from RUIE Dataset [66] with a triple of subclasses of underwater images: (a) Underwater Image Quality Subaggregate, (b) Underwater Color Cast Subaggregate, (c) Underwater higher-level task-driven Subaggregate. • Low-contrast objects with complicated seabed scene, changeable underwater environmental illumination conditions, and severe turbidity resulting in blurred images and monochrome underwa- ter objects without abundant color information jointly constitute a major obstacle to promotion on underwater saliency detection and object recognition. • Although the captured underwater image influenced by the imag- ing equipment itself, the interference of the absorption and scat- tering of the optical wave propagation in turbulent underwater also frequently leads to image distortion with a distinct differ- ence between the final image acquisition and the real scene. Light-propagation based the physical model is still worth further investigating thoroughly to address the intrinsic effects of these factors, which likely needs a long time to grope for underwater computer-vision research. • Research on deep-learning methods for underwater image pro- cessing is only at the early stage. Currently, the lack of large-scale underwater database limits and impedes the deep-learning based models on the application to underwater image processing. As more underwater image datasets with labeled ground truth are re- leased availably, deep-learning based frameworks for underwater image processing will be increased tremendously in the future. 5. Conclusions In this article, we have summarized a brief review of recent research related to the underwater image processing and analysis. Previously representative methods are divided into seven distinct categories: Un- derwater image, enhancement, noise reduction, defogging, segmenta- tion, saliency detection, color constancy and recovery/restoration. Fur- thermore, we have also presented the datasets applied in underwater image processing. Finally, we systematically analyze the challenges in the underwater image processing domain and provide some suggestions for the future development of underwater image processing. CRediT authorship contribution statement Muwei Jian: Writing-Conceptualization, Methodology, Writing - review & editing. Xiangyu Liu: Software, Visualization. Hanjiang Luo: Software, Visualization. Xiangwei Lu: Software, Validation. Hui Yu: Supervision, Writing - review & editing, Methodology. Junyu Dong: Formal analysis, Data curation. 6 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment This work was supported by National Natural Science Foundation of China (NSFC) (61976123, 61601427, 61876098); the Taishan Young Scholars Program of Shandong Province; and Royal Society - K. C. Wong International Fellowship (NIF\\R1\\180909). References [1] Miao Yang, Ke Hu, YixiangDu, Zhiqiang Wei, Zhibin Sheng, Jintong Hu, Underwater image enhancement based on conditional generative adversarial network, Signal Process., Image Commun. 81 (2020) 115723. [2] Peng Liu, Guoyu Wang, Hao Qi, Chufeng Zhang, Haiyong Zheng, Zhibin Yu, Underwater image Enhancement with a deep Residual framework, IEEE Access 7 (2019) 94614–94629. [3] S. Zhang, T. Wang, J. Dong, H. Yu, Underwater image enhancement via extended multi-scale retinex, Neurocomputing 245 (2017) 1–9. [4] Yujie Li, Chunyan Ma, Tingting Zhang, Jianru Li, Zongyuan Ge, Yun Li, Seiichi Serikawa, Underwater image High Definition display using the multilayer perceptron and Color feature-based SRCNN, IEEE Access 7 (2019) 83721–83728. [5] Kangjian He, Ruxin Wang, Dapeng Tao, Jun Cheng, Weifeng Liu, Color transfer pulse-coupled neural networks for underwater robotic visual systems, IEEE Access 6 (2018) 32850–32860. [6] Chunle Guo, Chongyi Li, Jichang Guo, Runmin Cong, Huazhu Fu, Ping Han, Hierarchical features driven residual learning for depth map super-resolution, IEEE Trans. Image Process. 28 (5) (2019) 2545–2557. [7] Xueyang Fu, Peixian Zhuang, Yue Huang, Yinghao Liao, Xiao-Ping Zhang, Xinghao Ding, A retinex-based enhancing approach for single underwater image, in: 2014 IEEE International Conference on Image Processing (ICIP), IEEE, 2014, pp. 4572–4576. [8] Huimin Lu, Yujie Li, Seiichi Serikawa, Underwater image enhancement using guided trigonometric bilateral filter and fast automatic color correction, in: 2013 IEEE International Conference on Image Processing, IEEE, 2013, pp. 3412–3416. [9] Huimin Lu, Yujie Li, Lifeng Zhang, Seiichi Serikawa, Contrast enhancement for images in turbid water, J. Opt. Soc. Amer. A 32 (5) (2015) 886–893. [10] Chongyi Li, Jichang Guo, Runmin Cong, Yanwei Pang, Bo Wang, Underwater image enhancement by dehazing with minimum information loss and histogram distribution prior, IEEE Trans. Image Process. 25 (12) (2016) 5664–5677. [11] Park Dubok, David K. Han, Hanseok Ko, Enhancing Underwater Color Images via optical imaging model and non-local means denoising, IEICE Trans. Inf. Syst. 100 (7) (2017) 1475–1483. [12] Yujie Li, Jianru Li, Yun Li, Hyoungseop Kim, Seiichi Serikawa, Low-light Underwater Image Enhancement for Deep-Sea tripod, IEEE Access 7 (2019) 44080–44086. [13] Amjad Khan, Syed Saad Azhar Ali, Atif Anwer, Syed Hasan Adil, Fabrice Meriaudeau, Subsea pipeline corrosion estimation by restoring and enhancing degraded underwater images, IEEE Access 6 (2018) 40585–40601. [14] Muwei Jian, Kin-Man Lam, Junyu Dong, Linlin Shen, Visual-patch-attention -aware Saliency Detection, IEEE Trans. Cybern. 45 (2015) 1575–1586. [15] Risheng Liu, Minjun Hou, Jinyuan Liu, Xin Fan, Zhongxuan Luo, Compounded layer-Prior Unrolling: A unified transmission-based image enhancement frame- work, in: 2019 IEEE International Conference on Multimedia and Expo (ICME), IEEE, 2019, pp. 538–543. [16] Minjun Hou, Risheng Liu, Xin Fan, Zhongxuan Luo, Joint residual learning for underwater image enhancement, in: 2018 25th IEEE International Conference on Image Processing (ICIP), IEEE, 2018, pp. 4043–4047. [17] Muwei Jian, Kin-Man Lam, Junyu Dong, Illumination-insensitive Texture Dis- crimination based on Illumination Compensation and Enhancement, Inform. Sci. 269 (2014) 60–72. [18] S. Zhang, T. Wang, J. Dong, H. Yu, Underwater image enhancement via extended multi-scale retinex, Neurocomputing 245 (2017) 1–9. [19] Chongyi Li, Saeed Anwar, Fatih Porikli, Underwater scene prior inspired deep underwater image and video enhancement, Pattern Recognit. 98 (2020). [20] David Corrigan, Ken Sooknanan, Jennifer Doyle, Colm Lordan, Anil Kokaram, A low-complexity Mosaicing algorithm for stock assessment of seabed-burrowing species, IEEE J. Ocean. Eng. 44 (2) (2018) 386–400. [21] Atif Anwer, Syed Saad Azhar Ali, Amjad Khan, Fabrice Meriaudeau, Underwater 3-d scene reconstruction using kinect v2 based on physical models for refraction and time of flight correction, IEEE Access 5 (2017) 15960–15970. [22] Lina Zhou, Yin Xiao, Wen Chen, Imaging through turbid media with vague concentrations based on cosine similarity and convolutional neural network, IEEE Photonics J. 11 (4) (2019) 1–15. [23] Bashar Elnashef, Sagi Filin, Direct linear and refraction-invariant pose estimation and calibration model for underwater imaging, ISPRS J. Photogramm. Remote Sens. 154 (2019) 259–271. [24] Huimin Lu, Yujie Li, Shota Nakashima, Hyongseop Kim, Seiichi Serikawa, Underwater image super-resolution by descattering and fusion, IEEE Access 5 (2017) 670–679. [25] Xin Sun, Lipeng Liu, Qiong Li, Junyu Dong, Estanislau Lima, Ruiying Yin, Deep pixel-to-pixel network for underwater image enhancement and restoration, IET Image Process. 13 (3) (2018) 469–474. [26] Emberton Simon, Lars Chittka, Andrea Cavallaro, Hierarchical rank-based veiling light estimation for underwater dehazing, 2015. [27] Katherine A. Skinner, Johnson-Roberson Matthew, Underwater image dehazing with a light field camera, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017, pp. 62–69. [28] Chongyi Li, Chunle Guo, Jichang Guo, Ping Han, Huazhu Fu, Runmin Cong, PPDR-Net: Perception-inspired single image dehazing network with refinement, IEEE Trans. Multimed. 22 (3) (2020) 704–716. [29] Codruta O. Ancuti, Cosmin Ancuti, Christophe De Vleeschouwer, Philippe Bekaert, Color balance and fusion for underwater image enhancement, IEEE Trans. Image Process. 27 (1) (2017) 379–393. [30] John Y. Chiang, Ying-Ching Chen, Underwater image enhancement by wave- length compensation and dehazing, IEEE Trans. Image Process. 21 (4) (2011) 1756–1769. [31] Xiangyu Deng, Huigang Wang, Xing Liu, Underwater image enhancement based on removing light source color and dehazing, IEEE Access 7 (2019) 114297–114309. [32] JohnY Chiang, YingChing Chen, YungFu Chen, Underwater image enhancement: using wavelength compensation and image dehazing (WCID), in: International Conference on Advanced Concepts for Intelligent Vision Systems, Springer, Berlin, Heidelberg, 2011, pp. 372–383. [33] Chongyi Li, Jichang Guo, Chunle Guo, Runmin Cong, Jiachang Gong, A hybrid method for underwater image correction, Pattern Recognit. Lett. 94 (2017) 62–67. [34] Risheng Liu, Xin Fan, Minjun Hou, Zhiying Jiang, Zhongxuan Luo, Lei Zhang, Learning aggregated transmission propagation networks for haze removal and beyond, IEEE Trans. Neural Netw. Learn. Syst. (2018). [35] Zhe Chen, Yang Sun, Yupeng Gu, Huibin Wang, Hao Qian, Hao Zheng, Under- water object segmentation integrating transmission and saliency features, IEEE Access 7 (2019). [36] Tiedong Zhang, Lei Wan, Zaibai Qin, Lu Yu, A method of underwater image segmentation based on discrete Fractional Brownian Random Field, in: 2008 3rd IEEE Conference on Industrial Electronics and Applications, 2008, pp. 2507–2511. [37] Shilong Wang, Yuru Xu, Yongjie Pang, A fast underwater optical image segmen- tation algorithm based on a histogram weighted fuzzy C-means improved by PSO, J. Mar. Sci. Appl. 10 (1) (2011) 70–75. [38] Xiu Li, Jingdong Song, Fan Zhang, Xiaogang Ouyang, Samee U. Khan, Mapreduce-based fast fuzzy c-means algorithm for large-scale underwater image segmentation, Future Gener. Comput. Syst. 65 (2016) 90–101. [39] Bo Wang, Lei Wan, Ye Li, Saliency motivated pulse coupled neural network for underwater laser image segmentation, J. Shanghai Jiaotong Univ. (Sci.) 21 (3) (2016) 289–296. [40] Zhe Chen, Zhen Zhang, Yang Bu, Fengzhao Dai, Tanghuai Fan, Huibin Wang, Underwater object segmentation based on optical features, Sensors 18 (1) (2018) 196. [41] Yue Zhu, Baochen Hao, Baohua Jiang, RuiNian, Bo He, Xinmin Ren, Underwater image segmentation with co-saliency detection and local statistical active contour model, in: OCEANS 2017-Aberdeen, IEEE, 2017, pp. 1–5. [42] Kumar Rai, Rajesh, Puran Gour, Balvant Singh, Underwater image segmentation using clahe enhancement and thresholding, Int. J. Emerg. Technol. Adv. Eng. 2 (1) (2012) 118–123. [43] Muwei Jian, Wenyin Zhang, Hui Yu, Chaoran Cui, Xiushan Nie, Huaxiang Zhang, Yilong Yin, Saliency detection based on directional patches extraction and principal local color contrast, J. Vis. Commun. Image Represent. 57 (2018) 1–11. [44] Chongyi Li, Runmin Cong, Junhui Hou, Sanyi Zhang, Yue Qian, Sam Kwong, Nested network with two-stream pyramid for salient object detection in optical remote sensing images, IEEE Trans. Geosci. Remote Sens. 57 (11) (2019) 9156–9166. [45] Jian Xu, Pengfei Bi, Xue Du, Juan Li, Dong Chen, Generalized robust PCA: A new Distance Metric Method for underwater target recognition, IEEE Access 7 (2019) 51952–51964. [46] Jie Shen, Tanghuai Fan, Min Tang, Qian Zhang, Zhen Sun, Fengchen Huang, A biological hierarchical model based underwater moving object detection, Comput. Math. Methods Med. (2014). [47] Lunjuan Zhang, Bo He, Yan Song, Tianhong Yan, Underwater image feature extraction and matching based on visual saliency detection, in: IEEE OCEANS 2016-Shanghai, 2016, pp. 1–4. [48] Zhe Chen, Huibin Wang, Lizhong Xu, Jie Shen, Visual-adaptation-mechanism based underwater object extraction, Opt. Laser Technol. 56 (2014) 119–130. 7 M. Jian, X. Liu, H. Luo et al. Signal Processing: Image Communication 91 (2021) 116088 [49] Zhe Chen, Hongmin Gao, Zhen Zhang, Helen Zhou, Xun Wang, Yan Tian, Underwater salient object detection by combining 2D and 3D visual features, Neurocomputing (2019). [50] Xiu Li, Jing Hao, Min Shang, Zhixiong Yang, Saliency segmentation and foreground extraction of underwater image based on localization, in: OCEANS 2016-Shanghai, IEEE, 2016, pp. 1–4. [51] Li Mou, Xuewu Zhang, Jingjing Zhang, Xiaohai Shen, Xiaolong Xu, Saliency de- tection of Underwater Target based on spatial probability, in: 2017 International Conference on Computer Systems, Electronics and Control (ICCSEC), IEEE, 2017, pp. 630–632. [52] Zhe Chen, Zhen Zhang, Fengzhao Dai, Yang Bu, Huibin Wang, Monocular vision-based underwater object detection, Sensors 17 (8) (2017) 1784. [53] Zhengyu Chen, Tongtong Zhao, Na Cheng, Xundong Sun, Xianping Fu, To- wards Underwater Object Recognition based on supervised learning, in: 2018 OCEANS-MTS/IEEE Kobe Techno-Oceans (OTO), IEEE, 2018, pp. 1–4. [54] Xin Sun, Junyu Shi, Lipeng Liu, Junyu Dong, Claudia Plant, Xinhua Wang, Huiyu Zhou, Transferring deep knowledge for object recognition in Low-quality underwater videos, Neurocomputing 275 (2018) 897–908. [55] Muwei Jian, Qiang Qi, Junyu Dong, Yilong Yin, Kin-Man Lam, Integrating QDWD with pattern distinctness and local contrast for underwater saliency detection, J. Vis. Commun. Image Represent. 53 (2018) 31–41. [56] Muwei Jian, Qiang Qi, Hui Yu, Junyu Dong, Chaoran Cui, Xiushan Nie, Huaxiang Zhang, Yilong Yin, Kin-Man Lam, The extended marine underwater environment database and baseline evaluations, Appl. Soft Comput. 80 (2019) 425–437. [57] Dong Zhang, Lan Li, Zizhong Zhu, Shangang Jin, Weizhe Gao, Ce Li, Object Detection Algorithm based on deformable convolutional networks for Underwater Images, in: 2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI), IEEE, 2019, pp. 274–279. [58] Chongyi Li, Chunle Guo, Jichang Guo, Emerging from water: Underwater image color correction based on weakly supervised color transfer, IEEE Signal Process. Lett. 25 (3) (2018) 323–327. [59] Akkaynak Derya, Tali Treibitz, A revised underwater image formation model, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 6723–6732. [60] Codruta O. Ancuti, Cosmin Ancuti, Christophe De Vleeschouwer, Rafael Garcia, Locally adaptive color correction for underwater image dehazing and match- ing, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017, pp. 1–9. [61] Nomura Kohei, Daisuke Sugimura, Takayuki Hamamoto, Underwater image color correction using exposure-bracketing imaging, IEEE Signal Process. Lett. 25 (6) (2018) 893–897. [62] Wenhao Zhang, Ge Li, Zhenqiang Ying, A new underwater image enhancing method via color correction and illumination adjustment, in: 2017 IEEE Visual Communications and Image Processing (VCIP), IEEE, 2017, pp. 1–4. [63] Chau Yi Li, Andrea Cavallaro, Background light estimation for depth-dependent underwater image restoration, in: 2018 25th IEEE International Conference on Image Processing (ICIP), IEEE, 2018, pp. 1528–1532. [64] Muwei Jian, et al., Comprehensive assessment of non-uniform illumination for 3D heightmap reconstruction in outdoor environments, Comput. Ind. 99 (2018) 110–118. [65] Chongyi Li, Chunle Guo, Wenqi Ren, Runmin Cong, Junhui Hou, Sam Kwong, Dacheng Tao, An underwater image enhancement benchmark dataset and beyond, IEEE Trans. Image Process. 29 (2019) 4376–4389. [66] Risheng Liu, Xin Fan, Ming Zhu, Minjun Hou, Zhongxuan Luo, Real-world Underwater enhancement: Challenges, Benchmarks, and solutions under natural light, IEEE Trans. Circuits Syst. Video Technol. (2020). [67] Wagner Barros, Erickson Nascimento, Walysson V. Barbosa, Mario F.M. Campos, Single-shot underwater image restoration: A visual quality-aware method based on light propagation model, J. Vis. Commun. Image Represent. 55 (2018) 363–373. [68] Yuzhang Chen, Zhangfan Zeng, Yongcai Pan, A new degradation model for imaging in natural water and validation through image recovery, IEEE Access 7 (2019) 123244–123254. [69] C. S´anchez-Ferreira, L.S. Coelho, H.V.H. Ayala, M.C.Q. Farias, C.H. Llanos, Bio- inspired optimization algorithms for real underwater image restoration, Signal Process., Image Commun. (2019). [70] Abderrahim Halimi, Aurora Maccarone, Aongus McCarthy, Steve McLaughlin, Gerald S. Buller, Object depth profile and reflectivity restoration from sparse single-photon data acquired in underwater environments, IEEE Trans. Comput. Imaging 3 (3) (2017) 472–484. [71] Codruta Orniana Ancuti, Cosmin Ancuti, Tom Haber, Philippe Bekaert, Fusion- based restoration of the underwater images, in: 2011 18th IEEE International Conference on Image Processing, IEEE, 2011, pp. 1557–1560. [72] Haofeng Hu, Lin Zhao, Xiaobo Li, Hui Wang, Tiegen Liu, Underwater image recovery under the nonuniform optical field based on polarimetric imaging, IEEE Photonics J. 10 (1) (2018) 1–9. [73] Yu Tian, Bin Liu, Xinyan Su, Lipeng Wang, Ke Li, Underwater imaging based on LF and Polarization, IEEE Photonics J. 11 (1) (2019) 1–9. [74] Keyan Wang, Yan Hu, Jun Chen, Xianyun Wu, Xi Zhao, Yunsong Li, Underwater image restoration based on a parallel convolutional neural network, Remote Sens. 11 (13) (2019) 1591. [75] Walysson V. Barbosa, Henrique G.B. Amaral, Thiago L. Rocha, Erickson R. Nascimento, Visual-quality-driven learning for underwater vision enhancement, in: 2018 25th IEEE International Conference on Image Processing (ICIP), IEEE, 2018, pp. 3933–3937. [76] Mohua Zhang, Jianhua Peng, Underwater image restoration based on a new Underwater image formation model, IEEE Access 6 (2018) 58634–58644. [77] Nan Wang, Haiyong Zheng, Bing Zheng, Underwater image restoration via maximum attenuation identification, IEEE Access 5 (2017) 18941–18952. [78] Chongyi Li, Jichang Guo, Yanwei Pang, Shanji Chen, Jian Wang, Single un- derwater image restoration by blue–green channels dehazing and red channel correction, in: 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2016, pp. 1731–1735. [79] Chongyi Li, Jichang Guo, Shanji Chen, Yibin Tang, Yanwei Pang, Jian Wang, Underwater image restoration based on minimum information loss principle and optical properties of underwater imaging, in: 2016 IEEE International Conference on Image Processing (ICIP), IEEE, 2016, pp. 1993–1997. [80] H. Fan, L. Qi, J.H. Yu, Refractive laser triangulation and photometric stereo in underwater environment, Opt. Eng. 56 (11) (2017) 113101. 8","libVersion":"0.3.2","langs":""}